<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>插值与拟合</title>
      <link href="/2024/08/25/%E6%8F%92%E5%80%BC%E4%B8%8E%E6%8B%9F%E5%90%88/"/>
      <url>/2024/08/25/%E6%8F%92%E5%80%BC%E4%B8%8E%E6%8B%9F%E5%90%88/</url>
      
        <content type="html"><![CDATA[<h1 id="插值与拟合"><a href="#插值与拟合" class="headerlink" title="插值与拟合"></a>插值与拟合</h1><p>什么是插值？插值是一种用于填补数据中缺失值或者对数据进行平滑处理的技术。当我们在一组已知数据点之间寻找未知数据点时，可以使用插值方法来估计这些未知点的数值，而拟合是一种通过构建数学模型来逼近已有数据的方法。</p><h2 id="线性插值"><a href="#线性插值" class="headerlink" title="线性插值"></a>线性插值</h2><p>线性插值是拉格朗日插值的特殊情况，即n=1的情形，假设我们有两点，$A(x_0,f(x_0),B(x_1,f(x_1))$，那么根据我们学过的两点法，可以得到函数关系式：</p><script type="math/tex; mode=display">p(x) = y_0 + \frac{y_1-y_0}{x_1-x_0}(x-x_0)</script><p>之后稍加变形，就可以得到：</p><script type="math/tex; mode=display">p(x) = \frac{x-x_1}{x_0-x_1}y_0+\frac{x-x_0}{x_1-x_0}y_1</script><p>我们设:</p><script type="math/tex; mode=display">l_0(x) = \frac{x-x_1}{x_0-x_1},l_1(x)=\frac{x-x_0}{x_1-x_0}</script><p>故可以得到:</p><script type="math/tex; mode=display">p(x) = l_0(x)y_0+l_1(x)y_1</script><h2 id="抛物线插值"><a href="#抛物线插值" class="headerlink" title="抛物线插值"></a>抛物线插值</h2><p>如果说线性插值是对于两点内进行线性插值，那么抛物线插值就是在两点内用抛物线进行插值，也就是二次插值。通过3个已知点的抛物线来拟合$f(x)$，所以这里我们可以发现，随着点的数量越多，拟合的精度也就越高，更容易贴近于原函数。</p><p>假设我们有三点，$A(x_0,f(x_0),B(x_1,f(x_1)),C(x_2,f(x_2))$，我们用多项式$f(x)=a_2x^2+a_1x+a_0$来进行插值，通过解方程：</p><script type="math/tex; mode=display">a_0+a_1x_0+a_2x_0^2 = y_0</script><script type="math/tex; mode=display">a_0+a_1x_1+a_2x_1^2 = y_1</script><script type="math/tex; mode=display">a_0+a_1x_2+a_2x_2^2 = y_2</script><p>我们将其转换为一个线性方程组：</p><script type="math/tex; mode=display">\begin{pmatrix}1 & x_0 & x_0^2 \\1 & x_1 & x_1^2 \\1 & x_2 & x_2^2 \\\end{pmatrix}\begin{pmatrix}a_0 \\a_1 \\a_2 \\\end{pmatrix}=\begin{pmatrix}y_0 \\y_1 \\y_2 \\\end{pmatrix}</script><p>这里可以通过范德蒙德行列式去求解，最后得到结果：</p><script type="math/tex; mode=display">p(x) = y_0 \cdot \frac{(x - x_1)(x - x_2)}{(x_0 - x_1)(x_0 - x_2)} + y_1 \cdot \frac{(x - x_0)(x - x_2)}{(x_1 - x_0)(x_1 - x_2)} + y_2 \cdot \frac{(x - x_0)(x - x_1)}{(x_2 - x_0)(x_2 - x_1)}</script><p>其中：</p><script type="math/tex; mode=display">l_0(x) = \frac{(x - x_1)(x - x_2)}{(x_0 - x_1)(x_0 - x_2)}</script><script type="math/tex; mode=display">l_1(x)=\frac{(x - x_0)(x - x_2)}{(x_1 - x_0)(x_1 - x_2)}</script><script type="math/tex; mode=display">l_2(x)=\frac{(x - x_0)(x - x_1)}{(x_2 - x_0)(x_2 - x_1)}</script><h2 id="拉格朗日插值法"><a href="#拉格朗日插值法" class="headerlink" title="拉格朗日插值法"></a>拉格朗日插值法</h2><p>根据一次插值和二次插值，我们很容易想出如果有n个点，那么我们可以进行n次插值，这就是拉格朗日插值法。</p><p>给定一组数据点 (x0,y0),(x1,y1),…,(xn,yn)，拉格朗日插值法通过构造一个多项式 P(x)，使得 P(xi)=yi 对每个 i 都成立。这个多项式可以表示为：</p><script type="math/tex; mode=display">P(x) = \sum_{i=0}^{n} y_i L_i(x)</script><p>其中 Li(x) 是称为拉格朗日基函数（Lagrange Basis Polynomial）的多项式，定义为：</p><script type="math/tex; mode=display">L_i(x) = \prod_{\substack{0 \leq j \leq n \\ j \neq i}} \frac{x - x_j}{x_i - x_j}</script><p>基函数 Li(x)的特点是它在 x=xi时取值为 1，而在其他所有的xj处（j≠i）取值为 0。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">y_interp</span> = <span class="title">lagrange_interpolation</span><span class="params">(x_values, y_values, x)</span></span></span><br><span class="line">    n = <span class="built_in">length</span>(x_values);  <span class="comment">% 获得数据点的个数</span></span><br><span class="line">    y_interp = <span class="number">0</span>;  <span class="comment">% 初始化</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:n</span><br><span class="line">        L_i = <span class="number">1</span>; <span class="comment">% 计算拉格朗日基函数 L_i(x)</span></span><br><span class="line">        <span class="keyword">for</span> <span class="built_in">j</span> = <span class="number">1</span>:n</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">i</span> ~= <span class="built_in">j</span> <span class="comment">%确保了只在 𝑗≠𝑖 时，才会计算当前的乘积项。</span></span><br><span class="line">                L_i = L_i * (x - x_values(<span class="built_in">j</span>)) / (x_values(<span class="built_in">i</span>) - x_values(<span class="built_in">j</span>));</span><br><span class="line">            <span class="keyword">end</span></span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">        <span class="comment">% 计算插值对应的 y 值</span></span><br><span class="line">        y_interp = y_interp + L_i * y_values(<span class="built_in">i</span>);</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">x_values = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>];<span class="comment">% 假设已知的点</span></span><br><span class="line">y_values = [<span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>];</span><br><span class="line">x = <span class="number">2.5</span>;<span class="comment">% 要插值的点</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% 拉格朗日插值函数调用</span></span><br><span class="line">y_interp_manual = lagrange_interpolation(x_values, y_values, x);</span><br><span class="line"></span><br><span class="line"><span class="comment">% 使用MATLAB内置的函数进行多项式拟合并插值来验证函数的正确性</span></span><br><span class="line">coeffs = polyfit(x_values, y_values, <span class="number">2</span>); <span class="comment">% 用二次多项式拟合</span></span><br><span class="line">y_interp_builtin = polyval(coeffs, x);</span><br><span class="line"></span><br><span class="line">fprintf(<span class="string">&#x27;拉格朗日插值结果: y(%.2f) = %.2f\n&#x27;</span>, x, y_interp_manual);</span><br><span class="line">fprintf(<span class="string">&#x27;MATLAB函数插值结果: y(%.2f) = %.2f\n&#x27;</span>, x, y_interp_builtin);</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">abs</span>(y_interp_manual - y_interp_builtin) &lt; <span class="number">1e-6</span></span><br><span class="line">    <span class="built_in">disp</span>(<span class="string">&#x27;验证通过：函数与MATLAB内置函数结果一致&#x27;</span>);</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    <span class="built_in">disp</span>(<span class="string">&#x27;验证失败：函数与MATLAB内置函数结果不一致&#x27;</span>);</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><p>从公式可以看到，对于基函数的计算运算量为$O(n)$，然后叠加的运算量又是$O(n)$，所以最后总的计算复杂度为$O(n^2)$，所以拉格朗日插值法更适合小样本的计算，大样本计算效率低下，应该选用其他方法。</p><h2 id="牛顿插值法"><a href="#牛顿插值法" class="headerlink" title="牛顿插值法"></a>牛顿插值法</h2><p>牛顿插值法是一种用于构造多项式插值的数学方法，特别适用于逐步增加插值点的情况。它的基本思想是利用差商（finite difference）构建插值多项式。</p><script type="math/tex; mode=display">p(x) = f[x_0] + f[x_0, x_1] (x - x_0) + f[x_0, x_1, x_2] (x - x_0) (x - x_1) + \cdots + f[x_0, x_1, \ldots, x_{n-1}] \prod_{k=0}^{n-2} (x - x_k)</script><p>其中，$f[x<em>0], f[x_0, x_1], \ldots, f[x_0, x_1, \ldots, x</em>{n-1}]$ 是差商。</p><script type="math/tex; mode=display">f[x_i] = y_i</script><script type="math/tex; mode=display">f[x_i, x_{i+1}] = \frac{f[x_{i+1}] - f[x_i]}{x_{i+1} - x_i}</script><script type="math/tex; mode=display">f[x_i, x_{i+1}, x_{i+2}] = \frac{f[x_{i+1}, x_{i+2}] - f[x_i, x_{i+1}]}{x_{i+2} - x_i}</script><script type="math/tex; mode=display">f[x_i, x_{i+1}, \ldots, x_{i+k}] = \frac{f[x_{i+1}, \ldots, x_{i+k}] - f[x_i, \ldots, x_{i+k-1}]}{x_{i+k} - x_i}</script><p>通过观察差分公式，我们可以发现牛顿插值法的主要优点是每当新增一个插值点时，可以在不重新计算所有系数的情况下只更新部分系数，这样可以大大减少计算量。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">p</span> = <span class="title">newton_interpolation</span><span class="params">(x_values, y_values, x)</span></span></span><br><span class="line">    n = <span class="built_in">length</span>(x_values);  </span><br><span class="line">    </span><br><span class="line">    <span class="comment">% 计算差商</span></span><br><span class="line">    F = <span class="built_in">zeros</span>(n, n);  <span class="comment">% 差商表</span></span><br><span class="line">    F(:,<span class="number">1</span>) = y_values&#x27;;  <span class="comment">% 0阶差商</span></span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">j</span> = <span class="number">2</span>:n</span><br><span class="line">        <span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:n-<span class="built_in">j</span>+<span class="number">1</span></span><br><span class="line">            F(<span class="built_in">i</span>,<span class="built_in">j</span>) = (F(<span class="built_in">i</span>+<span class="number">1</span>,<span class="built_in">j</span><span class="number">-1</span>) - F(<span class="built_in">i</span>,<span class="built_in">j</span><span class="number">-1</span>)) / (x_values(<span class="built_in">i</span>+<span class="built_in">j</span><span class="number">-1</span>) - x_values(<span class="built_in">i</span>));</span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">% 计算牛顿插值多项式的值</span></span><br><span class="line">    p = F(<span class="number">1</span>,<span class="number">1</span>);  <span class="comment">% 初始化为第一个差商</span></span><br><span class="line">    term = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">for</span> k = <span class="number">2</span>:n</span><br><span class="line">        term = term * (x - x_values(k<span class="number">-1</span>));  <span class="comment">% 计算 (x - x_0)(x - x_1)...(x - x_&#123;k-2&#125;)</span></span><br><span class="line">        p = p + F(<span class="number">1</span>,k) * term;  <span class="comment">% 累加每一项</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">x_values = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">4</span>];</span><br><span class="line">y_values = [<span class="number">1</span>, <span class="number">4</span>, <span class="number">16</span>];</span><br><span class="line">x = <span class="number">3</span>;</span><br><span class="line">p = newton_interpolation(x_values, y_values, x);</span><br><span class="line"><span class="built_in">disp</span>([<span class="string">&#x27;插值多项式在 x = &#x27;</span> num2str(x) <span class="string">&#x27; 处的值为: &#x27;</span> num2str(p)]);</span><br></pre></td></tr></table></figure><h2 id="Hermite插值法"><a href="#Hermite插值法" class="headerlink" title="Hermite插值法"></a>Hermite插值法</h2><p>Hermite插值是一种在给定数据点的同时，还包括数据点处的一阶导数（或更高阶导数）信息的插值方法。相比于拉格朗日插值，Hermite插值能更好地逼近函数的曲线特性，尤其是在给定点处的斜率（导数）已知时。</p><p>设我们有一组数据点 $x_0, x_1, \dots, x_n$，并且给定了函数在这些点上的值 $f(x_0), f(x_1), \dots, f(x_n)$ 以及导数值<script type="math/tex">f'(x_0), f'(x_1), \dots, f'(x_n)</script>​。Hermite 插值法的目标是构造一个多项式 H(x)，使得：</p><script type="math/tex; mode=display">H(x_i) = f(x_i), \quad H'(x_i) = f'(x_i), \quad i = 0, 1, \dots, n</script><p>Hermite 插值多项式可表示为：</p><script type="math/tex; mode=display">H(x) = \sum_{i=0}^n \left[ f(x_i) h_i(x) + f'(x_i) h_i^*(x) \right]</script><p>并满足：</p><script type="math/tex; mode=display">h_i(x_j) = \delta_{ij}, \quad h_i'(x_j) = 0, \quad h_i^*(x_j) = 0, \quad h_i^{*'}(x_j) = \delta_{ij}</script><p>最后得到：</p><script type="math/tex; mode=display">H(x) = \sum_{i=0}^n \left[ f(x_i) \left(1 - 2(x - x_i) \frac{L_i'(x_i)}{L_i(x_i)}\right) \left(\frac{L_i(x)}{L_i(x_i)}\right)^2 + f'(x_i) (x - x_i) \left(\frac{L_i(x)}{L_i(x_i)}\right)^2 \right]</script><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">H</span> = <span class="title">hermite_interpolation</span><span class="params">(x_values, y_values, dy_values, x)</span></span></span><br><span class="line">    n = <span class="built_in">length</span>(x_values);  </span><br><span class="line">    H = <span class="built_in">zeros</span>(<span class="built_in">size</span>(x));   </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:n</span><br><span class="line">        <span class="comment">% 构造 L_i(x)</span></span><br><span class="line">        L_i = <span class="built_in">ones</span>(<span class="built_in">size</span>(x));   <span class="comment">% 初始化为 1</span></span><br><span class="line">        <span class="keyword">for</span> <span class="built_in">j</span> = <span class="number">1</span>:n</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">i</span> ~= <span class="built_in">j</span></span><br><span class="line">                L_i = L_i .* (x - x_values(<span class="built_in">j</span>)) / (x_values(<span class="built_in">i</span>) - x_values(<span class="built_in">j</span>));</span><br><span class="line">            <span class="keyword">end</span></span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">% 计算 L_i(x_i) 和 L_i&#x27;(x_i)</span></span><br><span class="line">        L_i_xi = <span class="number">1</span>;   <span class="comment">% L_i(x_i)</span></span><br><span class="line">        L_i_prime_xi = <span class="number">0</span>;  <span class="comment">% L_i&#x27;(x_i)</span></span><br><span class="line">        <span class="keyword">for</span> <span class="built_in">j</span> = <span class="number">1</span>:n</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">i</span> ~= <span class="built_in">j</span></span><br><span class="line">                L_i_xi = L_i_xi * (x_values(<span class="built_in">i</span>) - x_values(<span class="built_in">j</span>));</span><br><span class="line">                L_i_prime_xi = L_i_prime_xi + <span class="number">1</span> / (x_values(<span class="built_in">i</span>) - x_values(<span class="built_in">j</span>));</span><br><span class="line">            <span class="keyword">end</span></span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">        L_i_prime_xi = L_i_prime_xi * L_i_xi;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">% 计算 Hermite 基函数 h_i(x) 和 h_i^*(x)</span></span><br><span class="line">        h_i = (<span class="number">1</span> - <span class="number">2</span> * (x - x_values(<span class="built_in">i</span>)) * L_i_prime_xi / L_i_xi) .* (L_i.^<span class="number">2</span>);</span><br><span class="line">        h_i_star = (x - x_values(<span class="built_in">i</span>)) .* (L_i.^<span class="number">2</span>);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">% 叠加到最终的 Hermite 插值多项式 H(x)</span></span><br><span class="line">        H = H + y_values(<span class="built_in">i</span>) * h_i + dy_values(<span class="built_in">i</span>) * h_i_star;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">x_values = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>];</span><br><span class="line">y_values = [<span class="number">1</span>, <span class="number">4</span>, <span class="number">9</span>];</span><br><span class="line">dy_values = [<span class="number">0</span>, <span class="number">4</span>, <span class="number">6</span>];</span><br><span class="line">x = <span class="number">2.5</span>;</span><br><span class="line"></span><br><span class="line">H = hermite_interpolation(x_values, y_values, dy_values, x);</span><br><span class="line"><span class="built_in">disp</span>(H);</span><br></pre></td></tr></table></figure><h2 id="Python的插值与拟合函数"><a href="#Python的插值与拟合函数" class="headerlink" title="Python的插值与拟合函数"></a>Python的插值与拟合函数</h2><h3 id="插值函数"><a href="#插值函数" class="headerlink" title="插值函数"></a>插值函数</h3><p>插值有多种方法，在python，scipy.interpolate模块有一维插值函数interp1d、二维插值函数interp2d、多维插值函数interpn, interpnd。</p><p>线性插值（Linear Interpolation）和三次样条插值（Cubic Spline Interpolation）都是常用的插值方法，用于在给定的一组数据点之间插值得到未知数据点的数值。它们都可以用于平滑数据、补全数据或者预测中间值，但线性插值过于简单，以至于有些时候不适合非线性的数据，这时就要用更加平滑自然的三次曲线样条来插值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> scipy.interpolate <span class="keyword">import</span> interp1d</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="comment"># 插值节点</span></span><br><span class="line">x = np.arange(<span class="number">0</span>, <span class="number">25</span>, <span class="number">2</span>)</span><br><span class="line">y = np.array([<span class="number">12</span>, <span class="number">9</span>, <span class="number">9</span>, <span class="number">10</span>, <span class="number">18</span>, <span class="number">24</span>, <span class="number">28</span>, <span class="number">27</span>, <span class="number">25</span>, <span class="number">20</span>, <span class="number">18</span>, <span class="number">15</span>, <span class="number">13</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 插值点</span></span><br><span class="line">xnew = np.linspace(<span class="number">0</span>, <span class="number">24</span>, <span class="number">500</span>)</span><br><span class="line">fun1 = interp1d(x, y)</span><br><span class="line">fun2 = interp1d(x, y, <span class="string">&#x27;cubic&#x27;</span>)</span><br><span class="line">y1 = fun1(xnew)</span><br><span class="line">y2 = fun2(xnew)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>,<span class="number">10</span>))</span><br><span class="line">plt.rc(<span class="string">&#x27;font&#x27;</span>, size=<span class="number">16</span>)</span><br><span class="line">plt.rc(<span class="string">&#x27;font&#x27;</span>, family=<span class="string">&#x27;SimHei&#x27;</span>)</span><br><span class="line">plt.subplot(<span class="number">121</span>)</span><br><span class="line">plt.plot(xnew, y1, x, y, <span class="string">&#x27;ro&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;分段线性插值&quot;</span>)</span><br><span class="line">plt.subplot(<span class="number">122</span>)</span><br><span class="line">plt.plot(xnew, y2, x, y, <span class="string">&#x27;ro&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;三次样条插值&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>多维插值：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy.interpolate <span class="keyword">import</span> interpn</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D</span><br><span class="line"></span><br><span class="line">x = np.linspace(<span class="number">0</span>, <span class="number">1</span>, <span class="number">10</span>)  </span><br><span class="line">y = np.linspace(<span class="number">0</span>, <span class="number">1</span>, <span class="number">10</span>)  </span><br><span class="line">z = np.linspace(<span class="number">0</span>, <span class="number">1</span>, <span class="number">10</span>)  </span><br><span class="line"></span><br><span class="line">X, Y, Z = np.meshgrid(x, y, z, indexing=<span class="string">&#x27;ij&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义复杂函数值 (f(x, y, z) = sin(πx) * cos(πy) * sin(πz))</span></span><br><span class="line">values = np.sin(np.pi * X) * np.cos(np.pi * Y) * np.sin(np.pi * Z)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义需要插值的点</span></span><br><span class="line">points_to_interpolate = np.array([[<span class="number">0.15</span>, <span class="number">0.15</span>, <span class="number">0.15</span>],</span><br><span class="line">                                  [<span class="number">0.35</span>, <span class="number">0.45</span>, <span class="number">0.55</span>],</span><br><span class="line">                                  [<span class="number">0.75</span>, <span class="number">0.85</span>, <span class="number">0.95</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 多维插值</span></span><br><span class="line">interpolated_values = interpn((x, y, z), values, points_to_interpolate, method=<span class="string">&#x27;linear&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, point <span class="keyword">in</span> <span class="built_in">enumerate</span>(points_to_interpolate):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Point <span class="subst">&#123;point&#125;</span> has interpolated value <span class="subst">&#123;interpolated_values[i]&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化原始网格数据的一个切片</span></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">12</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在 (z=0.5) 处切片</span></span><br><span class="line">ax1 = fig.add_subplot(<span class="number">121</span>, projection=<span class="string">&#x27;3d&#x27;</span>)</span><br><span class="line">ax1.plot_surface(X[:, :, <span class="number">5</span>], Y[:, :, <span class="number">5</span>], values[:, :, <span class="number">5</span>], cmap=<span class="string">&#x27;viridis&#x27;</span>)</span><br><span class="line">ax1.set_title(<span class="string">&quot;Original Function Slice at z=0.5&quot;</span>)</span><br><span class="line">ax1.set_xlabel(<span class="string">&#x27;X&#x27;</span>)</span><br><span class="line">ax1.set_ylabel(<span class="string">&#x27;Y&#x27;</span>)</span><br><span class="line">ax1.set_zlabel(<span class="string">&#x27;f(X,Y,Z)&#x27;</span>)</span><br><span class="line"></span><br><span class="line">ax2 = fig.add_subplot(<span class="number">122</span>, projection=<span class="string">&#x27;3d&#x27;</span>)</span><br><span class="line">ax2.scatter(points_to_interpolate[:, <span class="number">0</span>], points_to_interpolate[:, <span class="number">1</span>], points_to_interpolate[:, <span class="number">2</span>], color=<span class="string">&#x27;red&#x27;</span>, label=<span class="string">&#x27;Interpolation Points&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> i, point <span class="keyword">in</span> <span class="built_in">enumerate</span>(points_to_interpolate):</span><br><span class="line">    ax2.text(point[<span class="number">0</span>], point[<span class="number">1</span>], point[<span class="number">2</span>], <span class="string">f&quot;<span class="subst">&#123;interpolated_values[i]:<span class="number">.2</span>f&#125;</span>&quot;</span>, color=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line"></span><br><span class="line">ax2.set_title(<span class="string">&quot;Interpolation Points&quot;</span>)</span><br><span class="line">ax2.set_xlabel(<span class="string">&#x27;X&#x27;</span>)</span><br><span class="line">ax2.set_ylabel(<span class="string">&#x27;Y&#x27;</span>)</span><br><span class="line">ax2.set_zlabel(<span class="string">&#x27;Z&#x27;</span>)</span><br><span class="line">ax2.legend()</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h3 id="拟合函数"><a href="#拟合函数" class="headerlink" title="拟合函数"></a>拟合函数</h3><p>假设我们有一些带有噪声的二维数据点，并且我们认为这些数据可以用一个二次函数来描述。我们将使用最小二乘法来拟合这些数据，并找出拟合的二次函数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> scipy.optimize <span class="keyword">import</span> curve_fit</span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">x_data = np.linspace(-<span class="number">10</span>, <span class="number">10</span>, <span class="number">50</span>)</span><br><span class="line"></span><br><span class="line">a, b, c = <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成y数据并添加噪声</span></span><br><span class="line">y_data = a * x_data**<span class="number">2</span> + b * x_data + c + np.random.normal(scale=<span class="number">5</span>, size=x_data.shape)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">quadratic_function</span>(<span class="params">x, a, b, c</span>):</span><br><span class="line">    <span class="keyword">return</span> a * x**<span class="number">2</span> + b * x + c</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用curve_fit进行拟合</span></span><br><span class="line">popt, pcov = curve_fit(quadratic_function, x_data, y_data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 拟合参数</span></span><br><span class="line">a_fit, b_fit, c_fit = popt</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Fitted parameters: a = <span class="subst">&#123;a_fit:<span class="number">.3</span>f&#125;</span>, b = <span class="subst">&#123;b_fit:<span class="number">.3</span>f&#125;</span>, c = <span class="subst">&#123;c_fit:<span class="number">.3</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">y_fit = quadratic_function(x_data, *popt)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">plt.scatter(x_data, y_data, label=<span class="string">&quot;Data with noise&quot;</span>, color=<span class="string">&quot;red&quot;</span>)</span><br><span class="line">plt.plot(x_data, quadratic_function(x_data, a, b, c), label=<span class="string">&quot;True function&quot;</span>, color=<span class="string">&quot;green&quot;</span>, linestyle=<span class="string">&quot;--&quot;</span>)</span><br><span class="line">plt.plot(x_data, y_fit, label=<span class="string">&quot;Fitted function&quot;</span>, color=<span class="string">&quot;blue&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;x&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;y&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.title(<span class="string">&quot;Quadratic Function Fitting&quot;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"></span><br><span class="line">mse = mean_squared_error(y_data, y_fit)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Mean Squared Error of the fit: <span class="subst">&#123;mse:<span class="number">.3</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 数值分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Matlab的绘图方法</title>
      <link href="/2024/08/24/Matlab%E7%9A%84%E7%BB%98%E5%9B%BE%E6%96%B9%E6%B3%95/"/>
      <url>/2024/08/24/Matlab%E7%9A%84%E7%BB%98%E5%9B%BE%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h1 id="如何用Matlab进行绘图？"><a href="#如何用Matlab进行绘图？" class="headerlink" title="如何用Matlab进行绘图？"></a>如何用Matlab进行绘图？</h1><p>Matlab内置有许多基础的绘图函数，加上一些指令就能让图形变得更加美观，事实上，Matlab和Python在绘图这里的语法结构基本上是相同的，所以如果有Python的语法基础，那么可以快速掌握Matlab的绘图部分。</p><h2 id="Matlab的数据导入"><a href="#Matlab的数据导入" class="headerlink" title="Matlab的数据导入"></a>Matlab的数据导入</h2><p>假如我们有一个Excel文件想要导入到Matlab，有没有与Pandas内的Dataframe相似的数据结构呢？Matlab提供了table结构。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">% 读取 Excel 文件</span></span><br><span class="line">data = <span class="built_in">readtable</span>(<span class="string">&#x27;data.xlsx&#x27;</span>);</span><br><span class="line"><span class="comment">% 提取数据</span></span><br><span class="line">dataArray = table2array(data);</span><br><span class="line"><span class="comment">% 提取列标签</span></span><br><span class="line">columnLabels = data.Properties.VariableNames;</span><br></pre></td></tr></table></figure><h2 id="曲线图"><a href="#曲线图" class="headerlink" title="曲线图"></a>曲线图</h2><p>绘制曲线我们可以用plot函数来实现，假如我们想画一条余弦函数：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x = <span class="built_in">linspace</span>(<span class="number">0</span>,<span class="number">2</span>*<span class="built_in">pi</span>,<span class="number">100</span>);</span><br></pre></td></tr></table></figure><p><code>linspace</code> 是 MATLAB 和 Python（通过 NumPy 库）中的一个函数，用于生成在指定范围内的均匀分布的数值序列。<code>linspace(a, b, n)</code> 会在 <code>[a, b]</code> 区间内生成 <code>n</code> 个等间距的点。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">x = <span class="built_in">linspace</span>(<span class="number">0</span>, <span class="number">2</span>*<span class="built_in">pi</span>);</span><br><span class="line">y1 = <span class="built_in">sin</span>(x);</span><br><span class="line">y2 = <span class="built_in">cos</span>(x);</span><br><span class="line"><span class="built_in">plot</span>(x, y1, <span class="string">&#x27;r--o&#x27;</span>, <span class="string">&#x27;LineWidth&#x27;</span>, <span class="number">2</span>);</span><br><span class="line"><span class="built_in">hold</span> on;</span><br><span class="line"><span class="built_in">plot</span>(x, y2, <span class="string">&#x27;b-.s&#x27;</span>, <span class="string">&#x27;LineWidth&#x27;</span>, <span class="number">1.5</span>);</span><br><span class="line"><span class="built_in">legend</span>(<span class="string">&#x27;sin(x)&#x27;</span>, <span class="string">&#x27;cos(x)&#x27;</span>);</span><br></pre></td></tr></table></figure><p>其中</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lengend(<span class="string">&#x27;sin(x)&#x27;</span>,<span class="string">&#x27;cos(x)&#x27;</span>);</span><br></pre></td></tr></table></figure><p>是图例，按照之前曲线里面的顺序来标定的。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot(x, y2, &#x27;b-.s&#x27;, &#x27;LineWidth&#x27;, 1.5);</span><br></pre></td></tr></table></figure><p><strong><code>&#39;b&#39;</code></strong>指定线条颜色为蓝色（blue）,<strong><code>&#39;-.&#39;</code></strong>指定线型为点划线（dash-dot）,<strong><code>&#39;s&#39;</code></strong>指定标记形状为方形（square）。指定线条的宽度为 1.5 点（默认宽度为 0.5 点）。</p><p><strong>颜色</strong>:</p><ul><li><code>&#39;r&#39;</code>：红色（red）</li><li><code>&#39;g&#39;</code>：绿色（green）</li><li><code>&#39;b&#39;</code>：蓝色（blue）</li><li><code>&#39;c&#39;</code>：青色（cyan）</li><li><code>&#39;m&#39;</code>：品红色（magenta）</li><li><code>&#39;y&#39;</code>：黄色（yellow）</li><li><code>&#39;k&#39;</code>：黑色（black）</li><li><code>&#39;w&#39;</code>：白色（white）</li></ul><p><strong>线型</strong>:</p><ul><li><code>&#39;-&#39;</code>：实线（solid）</li><li><code>&#39;--&#39;</code>：虚线（dashed）</li><li><code>&#39;:&#39;</code>：点线（dotted）</li><li><code>&#39;-.&#39;</code>：点划线（dash-dot）</li></ul><p><strong>标记形状</strong>:</p><ul><li><code>&#39;+&#39;</code>：加号</li><li><code>&#39;o&#39;</code>：圆形</li><li><code>&#39;*&#39;</code>：星号</li><li><code>&#39;.&#39;</code>：点</li><li><code>&#39;x&#39;</code>：叉号</li><li><code>&#39;s&#39;</code>：方形</li><li><code>&#39;d&#39;</code>：菱形</li><li><code>&#39;^&#39;</code>：上三角</li><li><code>&#39;v&#39;</code>：下三角</li><li><code>&#39;&gt;&#39;</code>：右三角</li><li><code>&#39;&lt;&#39;</code>：左三角</li><li><code>&#39;p&#39;</code>：五边形</li><li><code>&#39;h&#39;</code>：六边形</li></ul><h2 id="三维曲面图"><a href="#三维曲面图" class="headerlink" title="三维曲面图"></a>三维曲面图</h2><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[X, Y] = <span class="built_in">meshgrid</span>(x, y)</span><br></pre></td></tr></table></figure><p><strong><code>x</code></strong>定义网格的 x 轴方向的向量。<strong><code>y</code></strong>定义网格的 y 轴方向的向量。<strong>X, Y</strong>生成的矩阵，其中 X的每一行是x向量的复制，而 <code>Y</code> 的每一列是y向量的复制。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[X,Y] = <span class="built_in">meshgrid</span>(<span class="number">-2</span>:<span class="number">0.1</span>:<span class="number">2</span>, <span class="number">-2</span>:<span class="number">0.1</span>:<span class="number">2</span>); <span class="comment">% 网格点坐标</span></span><br><span class="line">Z = <span class="built_in">exp</span>(-X.^<span class="number">2</span> - Y.^<span class="number">2</span>); </span><br><span class="line">surf(X,Y,Z); <span class="comment">% 绘制曲面图</span></span><br><span class="line">xlabel(<span class="string">&#x27;X&#x27;</span>); </span><br><span class="line">ylabel(<span class="string">&#x27;Y&#x27;</span>); </span><br><span class="line">zlabel(<span class="string">&#x27;Z&#x27;</span>);</span><br><span class="line">title(<span class="string">&#x27;三维曲面图&#x27;</span>);</span><br></pre></td></tr></table></figure><p>实际上<code>meshgrid</code>函数不仅是用来绘制三维曲面图的，它更多的是作为一个网格坐标点的生成函数。</p><p>假如有：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = <span class="number">1</span>:<span class="number">3</span>;</span><br><span class="line">y = <span class="number">4</span>:<span class="number">6</span>;</span><br><span class="line">[X, Y] = <span class="built_in">meshgrid</span>(x, y)</span><br></pre></td></tr></table></figure><p>输出为：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">X =</span><br><span class="line">     <span class="number">1</span>     <span class="number">2</span>     <span class="number">3</span></span><br><span class="line">     <span class="number">1</span>     <span class="number">2</span>     <span class="number">3</span></span><br><span class="line">     <span class="number">1</span>     <span class="number">2</span>     <span class="number">3</span></span><br><span class="line"></span><br><span class="line">Y =</span><br><span class="line">     <span class="number">4</span>     <span class="number">4</span>     <span class="number">4</span></span><br><span class="line">     <span class="number">5</span>     <span class="number">5</span>     <span class="number">5</span></span><br><span class="line">     <span class="number">6</span>     <span class="number">6</span>     <span class="number">6</span></span><br></pre></td></tr></table></figure><h2 id="热力图"><a href="#热力图" class="headerlink" title="热力图"></a>热力图</h2><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data = <span class="built_in">rand</span>(<span class="number">5</span>,<span class="number">5</span>); </span><br><span class="line">heatmap(data);</span><br><span class="line">title(<span class="string">&#x27;Heat-map&#x27;</span>);</span><br></pre></td></tr></table></figure><p>其中：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">h = heatmap(data, <span class="string">&#x27;Title&#x27;</span>, <span class="string">&#x27;Heatmap Example&#x27;</span>, <span class="string">&#x27;XLabel&#x27;</span>, <span class="string">&#x27;X Axis&#x27;</span>, <span class="string">&#x27;YLabel&#x27;</span>, <span class="string">&#x27;Y Axis&#x27;</span>, <span class="string">&#x27;Colormap&#x27;</span>, <span class="string">&#x27;jet&#x27;</span>);</span><br></pre></td></tr></table></figure><p><strong><code>&#39;Colormap&#39;</code></strong>可以设置颜色映射方案，有<code>&#39;jet&#39;</code>、<code>&#39;hot&#39;</code>、<code>&#39;cool&#39;</code> 等。</p><p>实际上我们没必要非得搁一个热力图里面把所有属性都写好，那样太过繁杂，不如分开写。</p><h2 id="柱状图"><a href="#柱状图" class="headerlink" title="柱状图"></a>柱状图</h2><p>基本用法是：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y = [<span class="number">5</span>, <span class="number">10</span>, <span class="number">15</span>, <span class="number">20</span>];</span><br><span class="line">bar(y);</span><br></pre></td></tr></table></figure><p>如果想要绘制分组柱状图，只需要把y改为：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y = [<span class="number">5</span>, <span class="number">10</span>, <span class="number">15</span>; <span class="number">7</span>, <span class="number">14</span>, <span class="number">21</span>; <span class="number">6</span>, <span class="number">12</span>, <span class="number">18</span>];</span><br></pre></td></tr></table></figure><p>堆叠柱状图只需要在上面有y的基础上，加一个参数：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bar(y, <span class="string">&#x27;stacked&#x27;</span>);</span><br></pre></td></tr></table></figure><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">y = [<span class="number">5</span>, <span class="number">10</span>, <span class="number">15</span>, <span class="number">20</span>];</span><br><span class="line">bar(y, <span class="string">&#x27;FaceColor&#x27;</span>, <span class="string">&#x27;blue&#x27;</span>);<span class="comment">% 设置柱子颜色</span></span><br><span class="line">title(<span class="string">&#x27;Bar Chart&#x27;</span>);</span><br><span class="line">xlabel(<span class="string">&#x27;X&#x27;</span>);</span><br><span class="line">ylabel(<span class="string">&#x27;Y&#x27;</span>);</span><br><span class="line">bar(y, <span class="string">&#x27;BarWidth&#x27;</span>, <span class="number">0.5</span>);<span class="comment">% 设置柱子的宽度</span></span><br></pre></td></tr></table></figure><p>3D柱状图可以这么绘制：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y = <span class="built_in">rand</span>(<span class="number">5</span>);</span><br><span class="line">bar3(y);</span><br></pre></td></tr></table></figure><h2 id="散点图"><a href="#散点图" class="headerlink" title="散点图"></a>散点图</h2><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>];</span><br><span class="line">y = [<span class="number">10</span>, <span class="number">15</span>, <span class="number">9</span>, <span class="number">25</span>, <span class="number">30</span>];</span><br><span class="line"><span class="built_in">scatter</span>(x, y);</span><br></pre></td></tr></table></figure><p>如果想要更加高级一点，可以添加色彩选项：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">x = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>];</span><br><span class="line">y = [<span class="number">10</span>, <span class="number">15</span>, <span class="number">9</span>, <span class="number">25</span>, <span class="number">30</span>];</span><br><span class="line">colors = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>];</span><br><span class="line"><span class="built_in">scatter</span>(x, y, <span class="number">100</span>, colors, <span class="string">&#x27;filled&#x27;</span>);</span><br><span class="line"><span class="comment">% 其中的第三项100为size，是点的大小</span></span><br><span class="line"><span class="comment">% 颜色映射</span></span><br><span class="line">colormap(jet);</span><br><span class="line">colorbar; <span class="comment">% 添加颜色条</span></span><br></pre></td></tr></table></figure><p>三维散点图为：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>];</span><br><span class="line">y = [<span class="number">10</span>, <span class="number">15</span>, <span class="number">9</span>, <span class="number">25</span>, <span class="number">30</span>];</span><br><span class="line">z = [<span class="number">2</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">8</span>, <span class="number">10</span>];</span><br><span class="line"></span><br><span class="line"><span class="built_in">scatter3</span>(x, y, z, <span class="number">100</span>, <span class="string">&#x27;MarkerEdgeColor&#x27;</span>, <span class="string">&#x27;k&#x27;</span>, <span class="string">&#x27;MarkerFaceColor&#x27;</span>, <span class="string">&#x27;g&#x27;</span>);</span><br></pre></td></tr></table></figure><h2 id="饼图"><a href="#饼图" class="headerlink" title="饼图"></a>饼图</h2><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data = [<span class="number">10</span>, <span class="number">20</span>, <span class="number">30</span>, <span class="number">40</span>];</span><br><span class="line">labels = &#123;<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;C&#x27;</span>, <span class="string">&#x27;D&#x27;</span>&#125;;</span><br><span class="line">pie(data, labels);</span><br></pre></td></tr></table></figure><p>如果你想要突出某一个切片，可以这么写：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data = [<span class="number">10</span>, <span class="number">20</span>, <span class="number">30</span>, <span class="number">40</span>];</span><br><span class="line">explode = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>]; <span class="comment">% 第二个切片突出显示</span></span><br><span class="line">pie(data, explode);</span><br></pre></td></tr></table></figure><h2 id="直方图"><a href="#直方图" class="headerlink" title="直方图"></a>直方图</h2><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">data = <span class="built_in">randn</span>(<span class="number">1000</span>, <span class="number">1</span>);</span><br><span class="line">histogram(data, <span class="string">&#x27;Normalization&#x27;</span>, <span class="string">&#x27;pdf&#x27;</span>); <span class="comment">% 绘制概率密度函数归一化的直方图</span></span><br><span class="line">title(<span class="string">&#x27;Histogram&#x27;</span>); </span><br><span class="line">xlabel(<span class="string">&#x27;Value&#x27;</span>);</span><br><span class="line">ylabel(<span class="string">&#x27;Probability Density&#x27;</span>); </span><br></pre></td></tr></table></figure><h2 id="添加文本"><a href="#添加文本" class="headerlink" title="添加文本"></a>添加文本</h2><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x = <span class="built_in">linspace</span>(<span class="number">0</span>, <span class="number">2</span>*<span class="built_in">pi</span>, <span class="number">100</span>);</span><br><span class="line">y = <span class="built_in">sin</span>(x);</span><br><span class="line"><span class="built_in">plot</span>(x, y);</span><br><span class="line">text(<span class="number">3</span>, <span class="number">0.5</span>, <span class="string">&#x27;Peak&#x27;</span>, <span class="string">&#x27;FontSize&#x27;</span>, <span class="number">12</span>); <span class="comment">% 在指定位置添加文本</span></span><br><span class="line">annotation(<span class="string">&#x27;arrow&#x27;</span>, [<span class="number">0.2</span>, <span class="number">0.3</span>], [<span class="number">0.6</span>, <span class="number">0.8</span>]); <span class="comment">% 添加箭头</span></span><br></pre></td></tr></table></figure><p>用法为：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">text(X, Y, <span class="string">&#x27;String&#x27;</span>, <span class="string">&#x27;PropertyName&#x27;</span>, PropertyValue, ...)</span><br><span class="line">annotation(<span class="string">&#x27;Type&#x27;</span>, <span class="string">&#x27;PropertyName&#x27;</span>, PropertyValue, ...)</span><br></pre></td></tr></table></figure><p>比如：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">% 在坐标 (3, 0.5) 添加文本 &quot;Peak&quot;</span></span><br><span class="line">text(<span class="number">3</span>, <span class="number">0.5</span>, <span class="string">&#x27;Peak&#x27;</span>, <span class="string">&#x27;FontSize&#x27;</span>, <span class="number">12</span>, <span class="string">&#x27;FontWeight&#x27;</span>, <span class="string">&#x27;bold&#x27;</span>, <span class="string">&#x27;Color&#x27;</span>, <span class="string">&#x27;red&#x27;</span>);</span><br><span class="line"><span class="comment">% 添加一个箭头，起点 (0.2, 0.6)，终点 (0.3, 0.8)</span></span><br><span class="line">annotation(<span class="string">&#x27;arrow&#x27;</span>, [<span class="number">0.2</span>, <span class="number">0.3</span>], [<span class="number">0.6</span>, <span class="number">0.8</span>], <span class="string">&#x27;LineWidth&#x27;</span>, <span class="number">2</span>, <span class="string">&#x27;Color&#x27;</span>, <span class="string">&#x27;blue&#x27;</span>);</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Matlab </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>用Matlab实现偏微分方程的有限差分法</title>
      <link href="/2024/08/23/%E5%81%8F%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B%E7%9A%84%E6%9C%89%E9%99%90%E5%B7%AE%E5%88%86%E6%B3%95-Matlab%E5%AE%9E%E7%8E%B0/"/>
      <url>/2024/08/23/%E5%81%8F%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B%E7%9A%84%E6%9C%89%E9%99%90%E5%B7%AE%E5%88%86%E6%B3%95-Matlab%E5%AE%9E%E7%8E%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="偏微分方程-PDE"><a href="#偏微分方程-PDE" class="headerlink" title="偏微分方程(PDE)"></a>偏微分方程(PDE)</h1><p>偏微分方程是包含未知函数的偏导数的方程，根据未知函数偏导数的最高阶数，可以分为线性和非线性偏微分方程。工程上很多问题都与多个变量相关，而偏微分方程的解析解很难求出来，所以我们也想通过离散化来将其求出数值解，而有限差分法就能解决这个问题。</p><h2 id="一维热传导方程的有限差分求法"><a href="#一维热传导方程的有限差分求法" class="headerlink" title="一维热传导方程的有限差分求法"></a>一维热传导方程的有限差分求法</h2><p>假设温度为$u(x,t)$，其温度分布只和时间与一维x有关，具体公式为：</p><script type="math/tex; mode=display">\frac{\partial u}{\partial t}(x,t) = a^2\frac{\partial^2}{\partial x^2}u(x,t)+f(x,t)</script><script type="math/tex; mode=display">u(x,0)=\varphi(x)</script><script type="math/tex; mode=display">u(a,t) = \mu_1(t) , u(b,t)=\mu_2(t)</script><p>其中，第一个式子为一维热传导在网格[a+1,b-1]x[0,t]的温度分布方程，第二个方程与第三个方程都是边界条件，其中第二个方程告诉我们初始时刻的温度分布是什么样的，第三个方程告诉我们在a与b左右两条边界线上的温度分布是什么样的。</p><p>我们先设想一个网格：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">t</span><br><span class="line">|_|_ _ _ _ _ _|_ _</span><br><span class="line">|_|_ _ _ _ _ _|_ _</span><br><span class="line">|_|_ _ _ _ _ _|_ _ </span><br><span class="line">|_|_ _ _ _ _ _|_ _ </span><br><span class="line">|_|_/_\_ _ _ _|_ _  x t=0</span><br><span class="line">   a c d     b</span><br><span class="line">   1         N+1</span><br></pre></td></tr></table></figure><p>由于Matlab是没有零索引的，所以为方便编程，我们从1开始，切割成N个网格，所以有：</p><script type="math/tex; mode=display">t_n = 0 + (n-1)\Delta t</script><script type="math/tex; mode=display">x_j = a + (j-1)\Delta x</script><script type="math/tex; mode=display">\Delta x = \frac{b-a}{N}</script><p>我们假设$u_j^n$代表在x=j，t=n的温度，根据泰勒展开公式，对时间进行向前离散化：</p><script type="math/tex; mode=display">u(x_j,t_n+\Delta t)\approx u(x_j,t_n)+\frac{\partial u}{\partial t}(x_j,t_n)\Delta t</script><p>由于$\frac{\partial u}{\partial t}(x_j,t_n)$这个方程已知，所以接着对x离散：</p><script type="math/tex; mode=display">u(x_j+\Delta x,t_n)\approx u(x_j,t_n)+\frac{\partial u}{\partial x}(x_j,t_n)\Delta x + \frac{1}{2}\frac{\partial^2 u}{\partial x^2}(x_j,t_n)\Delta x^2</script><script type="math/tex; mode=display">u(x_j-\Delta x,t_n)\approx u(x_j,t_n)-\frac{\partial u}{\partial x}(x_j,t_n)\Delta x + \frac{1}{2}\frac{\partial^2 u}{\partial x^2}(x_j,t_n)\Delta x^2</script><p>将两式相加，得到中心离散化：</p><script type="math/tex; mode=display">\frac{\partial^2 u}{\partial x^2}(x_j,t_n) =\frac{u(x_j+\Delta x,t_n) - 2u(x_j,t_n)+u(x_j-\Delta x,t_n)}{\Delta x^2}</script><p>最后有：</p><script type="math/tex; mode=display">u_j^{n+1} = u_j^n + [a^2\frac{u_{j+1}^n+u_{j-1}^n-2u_j^n}{\Delta x^2}+f_j^n]</script><p>我们可以发现，假如想求出[a+1,b-1]的温度，需要上一时刻j位置的温度，与上一时刻j+1和j-1的温度，但是a点和b已经没有向左或向右的位置了，这时候边界条件就起作用了。</p><p>我们可以先把矩阵形式写出来，切记，对于下一时刻的u来说，，为了编程的易实现性，我们用三对角矩阵来计算，计算得到的1和N+1不管，索引1和索引N+1的值需要通过边界条件来算。</p><script type="math/tex; mode=display">\begin{pmatrix}u_{fake1}^{n+1} \\u_2^{n+1} \\u_3^{n+1} \\\vdots \\u_{fake_N+1}^{n+1} \\\end{pmatrix}\begin{pmatrix}-2 & 1 & 0 & \cdots & 0 \\1 & -2 & 1 & \cdots & 0 \\0 & 1 & -2 & \cdots & 0 \\\vdots & \vdots & \vdots & \ddots & \vdots \\0 & 0 & 0 & \cdots & -2\end{pmatrix} \begin{pmatrix}u_1^n \\u_2^n \\u_3^n \\\vdots \\u_{N+1}^n \\\end{pmatrix}</script><script type="math/tex; mode=display">u_1^{n+1} = \mu_1^{n+1}</script><script type="math/tex; mode=display">u_{N+1}^{n+1} = \mu_2^{n+1}</script><script type="math/tex; mode=display">u(x,0)=\varphi(x)</script><p>那如何用Matlab来实现仿真呢？以下是一个简单无热源的例子：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">clear,clc;</span><br><span class="line">a = <span class="number">1</span>;<span class="comment">% 如果dx比较小，那么误差较大</span></span><br><span class="line">dx = <span class="number">0.04</span>;</span><br><span class="line">x = <span class="number">0</span>:dx:<span class="number">1</span>;</span><br><span class="line">dt = <span class="number">0.00001</span>;</span><br><span class="line">t = <span class="number">0</span>:dt:<span class="number">1</span>;</span><br><span class="line">u = <span class="built_in">zeros</span>(<span class="built_in">length</span>(x),<span class="built_in">length</span>(t));</span><br><span class="line"><span class="comment">% 初始条件</span></span><br><span class="line">u(:,<span class="number">1</span>) = <span class="built_in">sin</span>(<span class="built_in">pi</span>*x);</span><br><span class="line">m1 = <span class="number">1</span> + <span class="number">0.1</span>*<span class="built_in">sin</span>(t);</span><br><span class="line">m2 = <span class="number">1</span> - <span class="number">0.1</span>*<span class="built_in">sin</span>(t);</span><br><span class="line"><span class="comment">% 构造三对角矩阵</span></span><br><span class="line">A = <span class="number">-2</span>*<span class="built_in">eye</span>(<span class="built_in">length</span>(x))+<span class="built_in">diag</span>(<span class="built_in">ones</span>(<span class="number">1</span>,<span class="built_in">length</span>(x)<span class="number">-1</span>),<span class="number">1</span>)+<span class="built_in">diag</span>(<span class="built_in">ones</span>(<span class="number">1</span>,<span class="built_in">length</span>(x)<span class="number">-1</span>),<span class="number">-1</span>);</span><br><span class="line"><span class="keyword">for</span> n = <span class="number">1</span>:<span class="built_in">length</span>(t)<span class="number">-1</span></span><br><span class="line">    u(:,n+<span class="number">1</span>) = u(:,n) + a^<span class="number">2</span>*dt/dx^<span class="number">2</span>*A*u(:,n);</span><br><span class="line">    u(<span class="number">1</span>,n+<span class="number">1</span>) = m1(n+<span class="number">1</span>);</span><br><span class="line">    u(<span class="keyword">end</span>,n+<span class="number">1</span>) = m2(n+<span class="number">1</span>);</span><br><span class="line">    <span class="built_in">plot</span>(x,u(:,n+<span class="number">1</span>))</span><br><span class="line">    axis([x(<span class="number">1</span>) x(<span class="keyword">end</span>) <span class="number">0</span> <span class="number">1</span>])</span><br><span class="line">    getframe;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"># 最终时刻</span><br><span class="line"><span class="built_in">plot</span>(x,u(:,<span class="keyword">end</span>))</span><br><span class="line">[T,X]=<span class="built_in">meshgrid</span>(t,x);</span><br><span class="line">surf(X,T,u)</span><br><span class="line">shading interp</span><br></pre></td></tr></table></figure><p><code>meshgrid(t,x)</code> 生成时间和空间的网格。<code>surf(X,T,u)</code> 绘制三维曲面图，展示温度随时间和空间的变化。<code>shading interp</code> 设置曲面的阴影效果，使图像更加平滑。</p><p>那么有热源应该怎么办呢？</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">clear,clc;</span><br><span class="line">a = <span class="number">1</span>;<span class="comment">% 如果dx比较小，那么误差较大</span></span><br><span class="line">dx = <span class="number">0.04</span>;</span><br><span class="line">x = <span class="number">0</span>:dx:<span class="number">1</span>;</span><br><span class="line">dt = <span class="number">0.00001</span>;</span><br><span class="line">t = <span class="number">0</span>:dt:<span class="number">1</span>;</span><br><span class="line">u = <span class="built_in">zeros</span>(<span class="built_in">length</span>(x),<span class="built_in">length</span>(t));</span><br><span class="line"><span class="comment">% 初始条件</span></span><br><span class="line">u(:,<span class="number">1</span>) = <span class="number">0.2</span>*<span class="built_in">sin</span>(x);</span><br><span class="line">f = <span class="number">7</span>*<span class="built_in">exp</span>(<span class="number">-20</span>*(x<span class="number">-1</span>/<span class="number">2</span>).^<span class="number">2</span>);</span><br><span class="line">m1 = <span class="number">0</span> + <span class="number">0.5</span>*<span class="built_in">sin</span>(t);</span><br><span class="line">m2 = <span class="number">0</span> - <span class="number">0.5</span>*<span class="built_in">sin</span>(t);</span><br><span class="line"><span class="comment">% 构造三对角矩阵</span></span><br><span class="line">A = <span class="number">-2</span>*<span class="built_in">eye</span>(<span class="built_in">length</span>(x))+<span class="built_in">diag</span>(<span class="built_in">ones</span>(<span class="number">1</span>,<span class="built_in">length</span>(x)<span class="number">-1</span>),<span class="number">1</span>)+<span class="built_in">diag</span>(<span class="built_in">ones</span>(<span class="number">1</span>,<span class="built_in">length</span>(x)<span class="number">-1</span>),<span class="number">-1</span>);</span><br><span class="line"><span class="keyword">for</span> n = <span class="number">1</span>:<span class="built_in">length</span>(t)<span class="number">-1</span></span><br><span class="line">    u(:,n+<span class="number">1</span>) = u(:,n) + a^<span class="number">2</span>*dt/dx^<span class="number">2</span>*A*u(:,n) + f&#x27;*dt;<span class="comment">% 由于u是x为列，而f是行，所以要转置</span></span><br><span class="line">    u(<span class="number">1</span>,n+<span class="number">1</span>) = m1(n+<span class="number">1</span>);</span><br><span class="line">    u(<span class="keyword">end</span>,n+<span class="number">1</span>) = m2(n+<span class="number">1</span>);</span><br><span class="line">    <span class="built_in">plot</span>(x,u(:,n+<span class="number">1</span>))</span><br><span class="line">    axis([x(<span class="number">1</span>) x(<span class="keyword">end</span>) <span class="number">0</span> <span class="number">1</span>])</span><br><span class="line">    getframe;</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><p>事实上，热传导方程的边界条件不仅是这种，还有另外两种，这里举例的是<strong>第一类边界条件</strong>，而<strong>第二类边界条件</strong>是这样的：</p><script type="math/tex; mode=display">\frac{\partial u}{\partial x}|_{x=a} = \mu_1(t)</script><script type="math/tex; mode=display">\frac{\partial u}{\partial x}|_{x=b} = \mu_2(t)</script><p>进行处理，得到：</p><script type="math/tex; mode=display">\frac{u_2^{n+1}-u_1^{n+1}}{\Delta x} = \mu_1^{n+1}</script><script type="math/tex; mode=display">\frac{u_{N+1}^{n+1}-u_N^{n+1}}{\Delta x} = \mu_2^{n+1}</script><p>由于$u_2^{n+1}$是已知的，所以可以反推边界条件：</p><script type="math/tex; mode=display">u_1^{n+1} = u_2^{n+1} - \mu_1^{n+1}\Delta x</script><script type="math/tex; mode=display">u_{N+1}^{n+1} = u_N^{n+1} + \mu_2^{n+1}\Delta x</script><p>故可以编写代码：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">clear,clc;</span><br><span class="line">a = <span class="number">1</span>;</span><br><span class="line">dx = <span class="number">0.04</span>;</span><br><span class="line">x = <span class="number">0</span>:dx:<span class="number">1</span>;</span><br><span class="line">dt = <span class="number">0.00001</span>;</span><br><span class="line">t = <span class="number">0</span>:dt:<span class="number">1</span>;</span><br><span class="line">u = <span class="built_in">zeros</span>(<span class="built_in">length</span>(x),<span class="built_in">length</span>(t));</span><br><span class="line">u(:,<span class="number">1</span>) = <span class="number">0.2</span>*<span class="built_in">sin</span>(x);</span><br><span class="line">f = <span class="number">7</span>*<span class="built_in">exp</span>(<span class="number">-20</span>*(x<span class="number">-1</span>/<span class="number">2</span>).^<span class="number">2</span>);</span><br><span class="line">m1 = <span class="number">0</span> + <span class="number">0.5</span>*<span class="built_in">sin</span>(t);</span><br><span class="line">m2 = <span class="number">0</span> - <span class="number">0.5</span>*<span class="built_in">sin</span>(t);</span><br><span class="line">A = <span class="number">-2</span>*<span class="built_in">eye</span>(<span class="built_in">length</span>(x))+<span class="built_in">diag</span>(<span class="built_in">ones</span>(<span class="number">1</span>,<span class="built_in">length</span>(x)<span class="number">-1</span>),<span class="number">1</span>)+<span class="built_in">diag</span>(<span class="built_in">ones</span>(<span class="number">1</span>,<span class="built_in">length</span>(x)<span class="number">-1</span>),<span class="number">-1</span>);</span><br><span class="line"><span class="keyword">for</span> n = <span class="number">1</span>:<span class="built_in">length</span>(t)<span class="number">-1</span></span><br><span class="line">    u(:,n+<span class="number">1</span>) = u(:,n) + a^<span class="number">2</span>*dt/dx^<span class="number">2</span>*A*u(:,n) + f&#x27;*dt;</span><br><span class="line">    u(<span class="number">1</span>,n+<span class="number">1</span>) = u(<span class="number">2</span>,n+<span class="number">1</span>) - m1(n+<span class="number">1</span>)*dx;<span class="comment">% 修改地方</span></span><br><span class="line">    u(<span class="keyword">end</span>,n+<span class="number">1</span>) = u(<span class="keyword">end</span><span class="number">-1</span>,n+<span class="number">1</span>) + m2(n+<span class="number">1</span>)*dx;</span><br><span class="line">    <span class="built_in">plot</span>(x,u(:,n+<span class="number">1</span>))</span><br><span class="line">    axis([x(<span class="number">1</span>) x(<span class="keyword">end</span>) <span class="number">0</span> <span class="number">1</span>])</span><br><span class="line">    getframe;</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><p><strong>第三类边界条件</strong>为：</p><script type="math/tex; mode=display">u+c\frac{\partial u}{\partial x}|_{x=a} = \mu_1(t)</script><p>如何离散化呢？其实根据前两类就能很快的写出来：</p><script type="math/tex; mode=display">u_1^{n+1} + c\frac{u_2^{n+1}-u_1^{n+1}}{\Delta x} = \mu_1^{n+1}</script><h2 id="一维薛定谔方程的有限差分求法"><a href="#一维薛定谔方程的有限差分求法" class="headerlink" title="一维薛定谔方程的有限差分求法"></a>一维薛定谔方程的有限差分求法</h2><p>量子的波函数$\psi(x,t)$可以描述量子分布的概率密度，通过$|\psi(x,t)|^2$​来计算，我们现在要模拟粒子运动随时间变化。</p><script type="math/tex; mode=display">i\hbar \frac{\partial \psi(x, t)}{\partial t} = -\frac{\hbar^2}{2m} \frac{\partial^2 \psi(x, t)}{\partial x^2} + V(x) \psi(x, t)</script><p>其中，$\hbar$是约化普朗克常数，$V(x)$是位置x的使能，$E$是粒子的能量，$i$是虚数。</p><p>事实上，计算机不可能模拟无穷远处的粒子，所以我们设定一个固定的边界条件：</p><script type="math/tex; mode=display">\psi(L,t) = \psi(-L,t) = 0</script><script type="math/tex; mode=display">\psi(x,0) = \psi_0(x)</script><p>根据一阶泰勒，我们可以得到：</p><script type="math/tex; mode=display">\psi^{n+1} = \psi^n + (\frac{i\hbar}{2m \Delta x^2}A\psi^n+\frac{1}{i\hbar}V\psi^n)\Delta t</script><p>构造哈密顿算符$H$：</p><script type="math/tex; mode=display">H = -\frac{\hbar^2}{2m\Delta x^2}A+V</script><p>所以有：</p><script type="math/tex; mode=display">\psi^{n+1} = \psi^n + \frac{1}{i\hbar}H\psi^n\Delta t</script><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">clear,clc;</span><br><span class="line">m =<span class="number">1</span> ;</span><br><span class="line">hb = <span class="number">1</span>;</span><br><span class="line">L = <span class="number">10</span>;</span><br><span class="line">dx = <span class="number">0.1</span>;</span><br><span class="line">x = -L:dx:L;</span><br><span class="line">dt = <span class="number">0.0001</span>;</span><br><span class="line">t = <span class="number">0</span>:dt:<span class="number">10</span>;</span><br><span class="line"><span class="built_in">psi</span> = <span class="built_in">zeros</span>(<span class="built_in">length</span>(x),<span class="built_in">length</span>(t));</span><br><span class="line">x0 = <span class="number">0</span>;</span><br><span class="line">Dx = <span class="number">1</span>;</span><br><span class="line">k0 = <span class="number">5</span>;</span><br><span class="line">psi0 = <span class="built_in">exp</span>(-x&#x27;.^<span class="number">2</span>/Dx^<span class="number">2</span>).*<span class="built_in">exp</span>(<span class="number">1</span><span class="built_in">i</span>*k0*x&#x27;);<span class="comment">% 开始移动，碰到边界后反弹</span></span><br><span class="line"><span class="built_in">psi</span>(:,<span class="number">1</span>) = psi0;</span><br><span class="line">A = <span class="number">-2</span>*<span class="built_in">eye</span>(<span class="built_in">length</span>(x))+<span class="built_in">diag</span>(<span class="built_in">ones</span>(<span class="number">1</span>,<span class="built_in">length</span>(x)<span class="number">-1</span>),<span class="number">1</span>)+<span class="built_in">diag</span>(<span class="built_in">ones</span>(<span class="number">1</span>,<span class="built_in">length</span>(x)<span class="number">-1</span>),<span class="number">-1</span>);</span><br><span class="line"><span class="comment">% 如果想要变成周期性边界条件可以改成：A(1,end) = 1,A(end,1)=1;</span></span><br><span class="line">w = <span class="number">1</span>;</span><br><span class="line">v = <span class="number">1</span>/<span class="number">2</span>*w^<span class="number">2</span>*x.^<span class="number">2</span>;</span><br><span class="line">V = <span class="built_in">diag</span>(v);</span><br><span class="line">H= -hb^<span class="number">2</span>/<span class="number">2</span>/m/dx^<span class="number">2</span>*A+V;</span><br><span class="line"><span class="keyword">for</span> n = <span class="number">1</span>:<span class="built_in">length</span>(t)<span class="number">-1</span></span><br><span class="line">    <span class="built_in">psi</span>(:,n+<span class="number">1</span>) = <span class="built_in">psi</span>(:,n) + <span class="number">1</span>/<span class="number">1</span><span class="built_in">i</span>/hb*H*<span class="built_in">psi</span>(:,n)*dt;</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">mod</span>(n,<span class="number">100</span>)==<span class="number">0</span></span><br><span class="line">        <span class="built_in">plot</span>(x,<span class="built_in">real</span>(<span class="built_in">psi</span>(:,n+<span class="number">1</span>)),x,<span class="built_in">imag</span>(<span class="built_in">psi</span>(:,n+<span class="number">1</span>)))</span><br><span class="line">        axis([x(<span class="number">1</span>) x(<span class="keyword">end</span>) <span class="number">-1</span> <span class="number">1</span>])</span><br><span class="line">        getframe;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p><code>x0 = 0;</code> 设置初始波包的中心位置,<code>Dx = 1;</code> 设置初始波包的宽度。</p><p>当然要是发散，也可以过程中使用龙格库塔算法：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">k1 = <span class="number">1</span>/<span class="number">1</span><span class="built_in">i</span>/hb * H * <span class="built_in">psi</span>(:,n);</span><br><span class="line">k2 = <span class="number">1</span>/<span class="number">1</span><span class="built_in">i</span>/hb * H * (<span class="built_in">psi</span>(:,n) + <span class="number">0.5</span>*dt*k1);</span><br><span class="line">k3 = <span class="number">1</span>/<span class="number">1</span><span class="built_in">i</span>/hb * H * (<span class="built_in">psi</span>(:,n) + <span class="number">0.5</span>*dt*k2);</span><br><span class="line">k4 = <span class="number">1</span>/<span class="number">1</span><span class="built_in">i</span>/hb * H * (<span class="built_in">psi</span>(:,n) + dt*k3);</span><br><span class="line"><span class="built_in">psi</span>(:,n+<span class="number">1</span>) = <span class="built_in">psi</span>(:,n) + (dt/<span class="number">6</span>) * (k1 + <span class="number">2</span>*k2 + <span class="number">2</span>*k3 + k4);</span><br></pre></td></tr></table></figure><h2 id="二维热传导方程的有限差分求法"><a href="#二维热传导方程的有限差分求法" class="headerlink" title="二维热传导方程的有限差分求法"></a>二维热传导方程的有限差分求法</h2><p>我们这里假设范围是$[0,l_x]\times [0,l_y]$的矩形面积。</p><script type="math/tex; mode=display">\frac{\partial u}{\partial t}(x,y,t) = a^2(\frac{\partial^2}{\partial x^2}u(x,y,t)+\frac{\partial^2}{\partial y^2}u(x,y,t))+f(x,y,t)</script><script type="math/tex; mode=display">u|_{x=0} = \mu_1(y,t) \quad, \quad u|_{x=L_x} = \mu_2(y,t)</script><script type="math/tex; mode=display">u|_{y=0} = \mu_3(x,t) \quad, \quad u|_{x=L_y} = \mu_4(x,t)</script><script type="math/tex; mode=display">u|_{t=0} = u_0(x,y)</script><p>首先依旧对x,y进行离散化处理：</p><script type="math/tex; mode=display">x = 0 + (i-1)\Delta x</script><script type="math/tex; mode=display">y = 0 + (i-1)\Delta y</script><script type="math/tex; mode=display">i = 1,2,...,N_x + 1</script><script type="math/tex; mode=display">j = 1,2,...,N_y + 1</script><script type="math/tex; mode=display">l_x = N_x\Delta x</script><script type="math/tex; mode=display">l_y = N_y\Delta y</script><p>得到：</p><script type="math/tex; mode=display">\frac{u_{i,j}^{n+1} - u_{i,j}^n}{\Delta t} = a^2 \left( \frac{u_{i+1,j}^n - 2u_{i,j}^n + u_{i-1,j}^n}{\Delta x^2} + \frac{u_{i,j+1}^n - 2u_{i,j}^n + u_{i,j-1}^n}{\Delta y^2} \right)</script><p>由于$U^n$是一个(x,y)的矩阵，所以$U^n$的每一列都可以认为前一列x、中间一列x与最后一列x的中心差分公式，同样，对$U^n$进行转置来计算y方向的，由于A是对称矩阵，所以A的转置还是A。</p><script type="math/tex; mode=display">\frac{\partial^2 u}{\partial x^2} = \frac{1}{\Delta x^2}AU^{n}</script><script type="math/tex; mode=display">\frac{\partial^2 u}{\partial y^2} = \frac{1}{\Delta y^2}U^nA</script><p>则有显式差分格式：</p><script type="math/tex; mode=display">U^{n+1} = U^n + a^2(\frac{1}{\Delta x^2}AU^{n}+\frac{1}{\Delta x^2}U^nA)\Delta t+F^n\Delta t</script><p>这里也要忽略A的第一行与最后一行，通过边界条件来计算。</p><p>先以边界条件为0的简单情况举例，这样就不要考虑边界的计算，直接赋值U0即可：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">clear,clc;</span><br><span class="line">dx = <span class="number">0.05</span>;</span><br><span class="line">Lx = <span class="number">1</span>;</span><br><span class="line">x = <span class="number">0</span>:dx:Lx;</span><br><span class="line">dy = <span class="number">0.05</span>;</span><br><span class="line">Ly = <span class="number">1</span>;</span><br><span class="line">y = <span class="number">0</span>:dy:Ly;</span><br><span class="line">A1 = <span class="number">-2</span>*<span class="built_in">eye</span>(<span class="built_in">length</span>(x))+<span class="built_in">diag</span>(<span class="built_in">ones</span>(<span class="number">1</span>,<span class="built_in">length</span>(x)<span class="number">-1</span>),<span class="number">1</span>)+<span class="built_in">diag</span>(<span class="built_in">ones</span>(<span class="number">1</span>,<span class="built_in">length</span>(x)<span class="number">-1</span>),<span class="number">-1</span>);</span><br><span class="line">A2 = <span class="number">-2</span>*<span class="built_in">eye</span>(<span class="built_in">length</span>(y))+<span class="built_in">diag</span>(<span class="built_in">ones</span>(<span class="number">1</span>,<span class="built_in">length</span>(y)<span class="number">-1</span>),<span class="number">1</span>)+<span class="built_in">diag</span>(<span class="built_in">ones</span>(<span class="number">1</span>,<span class="built_in">length</span>(y)<span class="number">-1</span>),<span class="number">-1</span>);</span><br><span class="line">dt = <span class="number">0.0001</span>;</span><br><span class="line">t = <span class="number">0</span>:dt:<span class="number">1</span>;</span><br><span class="line">[Y,X] = <span class="built_in">meshgrid</span>(Y,X);</span><br><span class="line">U0 = <span class="built_in">exp</span>(<span class="number">-10</span>*((X<span class="number">-1</span>/<span class="number">2</span>).^<span class="number">2</span>+(Y<span class="number">-1</span>/<span class="number">2</span>).^<span class="number">2</span>));</span><br><span class="line">U = U0;</span><br><span class="line">a = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">for</span> n = <span class="number">1</span>:<span class="built_in">length</span>(t)<span class="number">-1</span></span><br><span class="line">    U = U + a^<span class="number">2</span>*(<span class="number">1</span>/dx^<span class="number">2</span>*A1*U+<span class="number">1</span>/dy^<span class="number">2</span>*U*A2)*dt;</span><br><span class="line">    surf(X,Y,U);</span><br><span class="line">    axis([x(<span class="number">1</span>) x(<span class="keyword">end</span>) y(<span class="number">1</span>) y(<span class="keyword">end</span>) <span class="number">0</span> <span class="number">1</span>]);</span><br><span class="line">    getframe;</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><p>加上边界条件后就变为了：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">clear,clc;</span><br><span class="line">dx = <span class="number">0.05</span>;<span class="comment">% 时间和空间精度要同时增加</span></span><br><span class="line">Lx = <span class="number">1</span>;</span><br><span class="line">x = <span class="number">0</span>:dx:Lx;</span><br><span class="line">dy = <span class="number">0.05</span>;</span><br><span class="line">Ly = <span class="number">1</span>;</span><br><span class="line">y = <span class="number">0</span>:dy:Ly;</span><br><span class="line">A1 = <span class="number">-2</span>*<span class="built_in">eye</span>(<span class="built_in">length</span>(x))+<span class="built_in">diag</span>(<span class="built_in">ones</span>(<span class="number">1</span>,<span class="built_in">length</span>(x)<span class="number">-1</span>),<span class="number">1</span>)+<span class="built_in">diag</span>(<span class="built_in">ones</span>(<span class="number">1</span>,<span class="built_in">length</span>(x)<span class="number">-1</span>),<span class="number">-1</span>);</span><br><span class="line">A2 = <span class="number">-2</span>*<span class="built_in">eye</span>(<span class="built_in">length</span>(y))+<span class="built_in">diag</span>(<span class="built_in">ones</span>(<span class="number">1</span>,<span class="built_in">length</span>(y)<span class="number">-1</span>),<span class="number">1</span>)+<span class="built_in">diag</span>(<span class="built_in">ones</span>(<span class="number">1</span>,<span class="built_in">length</span>(y)<span class="number">-1</span>),<span class="number">-1</span>);</span><br><span class="line">dt = <span class="number">0.0001</span>;</span><br><span class="line">t = <span class="number">0</span>:dt:<span class="number">1</span>;</span><br><span class="line">m1 = x&#x27;;</span><br><span class="line">m2 = x&#x27;.^<span class="number">2</span>;</span><br><span class="line">m3 = y;</span><br><span class="line">m4 = <span class="number">2</span> - y;</span><br><span class="line">[X,Y] = <span class="built_in">meshgrid</span>(x,y);</span><br><span class="line">U0 = <span class="built_in">exp</span>(<span class="number">-10</span>*((X<span class="number">-1</span>/<span class="number">2</span>).^<span class="number">2</span>+(Y<span class="number">-1</span>/<span class="number">2</span>).^<span class="number">2</span>));</span><br><span class="line">U = U0;</span><br><span class="line">a = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">for</span> n = <span class="number">1</span>:<span class="built_in">length</span>(t)<span class="number">-1</span></span><br><span class="line">    U = U + a^<span class="number">2</span>*(<span class="number">1</span>/dx^<span class="number">2</span>*A1*U+<span class="number">1</span>/dy^<span class="number">2</span>*U*A2)*dt;</span><br><span class="line">    U(:,<span class="number">1</span>) = m1;</span><br><span class="line">    U(:,<span class="keyword">end</span>) = m2;</span><br><span class="line">    U(<span class="number">1</span>,:) = m3;</span><br><span class="line">    U(<span class="keyword">end</span>,:)=m4;</span><br><span class="line">    surf(X,Y,U);</span><br><span class="line">    axis([x(<span class="number">1</span>) x(<span class="keyword">end</span>) y(<span class="number">1</span>) y(<span class="keyword">end</span>) <span class="number">0</span> <span class="number">1</span>]);</span><br><span class="line">    getframe;</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><h2 id="二维薛定谔方程的有限差分求法"><a href="#二维薛定谔方程的有限差分求法" class="headerlink" title="二维薛定谔方程的有限差分求法"></a>二维薛定谔方程的有限差分求法</h2><script type="math/tex; mode=display">i\hbar \frac{\partial \psi(x, y, t)}{\partial t} = -\frac{\hbar^2}{2m} \left( \frac{\partial^2 \psi(x, y, t)}{\partial x^2} + \frac{\partial^2 \psi(x, y, t)}{\partial y^2} \right) + V(x, y) \psi(x, y, t)</script><p>对二阶导数进行离散化，得到：</p><script type="math/tex; mode=display">\frac{\partial^2 \psi}{\partial x^2} \approx \frac{\psi_{i+1,j}^n - 2\psi_{i,j}^n + \psi_{i-1,j}^n}{\Delta x^2}</script><script type="math/tex; mode=display">\frac{\partial^2 \psi}{\partial y^2} \approx \frac{\psi_{i,j+1}^n - 2\psi_{i,j}^n + \psi_{i,j-1}^n}{\Delta y^2}</script><p>对时间进行离散，得到：</p><script type="math/tex; mode=display">\frac{\partial \psi}{\partial t} \approx \frac{\psi_{i,j}^{n+1} - \psi_{i,j}^n}{\Delta t}</script><p>离散化后得到：</p><script type="math/tex; mode=display">i\hbar \frac{\psi_{i,j}^{n+1} - \psi_{i,j}^n}{\Delta t} = -\frac{\hbar^2}{2m} \left( \frac{\psi_{i+1,j}^n - 2\psi_{i,j}^n + \psi_{i-1,j}^n}{\Delta x^2} + \frac{\psi_{i,j+1}^n - 2\psi_{i,j}^n + \psi_{i,j-1}^n}{\Delta y^2} \right) + V_{i,j} \psi_{i,j}^n</script><p>不考虑边界条件的简单情况：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">clear,clc;</span><br><span class="line">dx = <span class="number">0.05</span><span class="comment">% 时间和空间精度要同时增加</span></span><br><span class="line">Lx = <span class="number">4</span>;</span><br><span class="line">x = -Lx:dx:Lx;</span><br><span class="line">dy = <span class="number">0.05</span>;</span><br><span class="line">Ly = <span class="number">4</span>;</span><br><span class="line">y = -Ly:dy:Ly;</span><br><span class="line">A1 = <span class="number">-2</span>*<span class="built_in">eye</span>(<span class="built_in">length</span>(x))+<span class="built_in">diag</span>(<span class="built_in">ones</span>(<span class="number">1</span>,<span class="built_in">length</span>(x)<span class="number">-1</span>),<span class="number">1</span>)+<span class="built_in">diag</span>(<span class="built_in">ones</span>(<span class="number">1</span>,<span class="built_in">length</span>(x)<span class="number">-1</span>),<span class="number">-1</span>);</span><br><span class="line">A2 = <span class="number">-2</span>*<span class="built_in">eye</span>(<span class="built_in">length</span>(y))+<span class="built_in">diag</span>(<span class="built_in">ones</span>(<span class="number">1</span>,<span class="built_in">length</span>(y)<span class="number">-1</span>),<span class="number">1</span>)+<span class="built_in">diag</span>(<span class="built_in">ones</span>(<span class="number">1</span>,<span class="built_in">length</span>(y)<span class="number">-1</span>),<span class="number">-1</span>);</span><br><span class="line">dt = <span class="number">0.0001</span>;</span><br><span class="line">t = <span class="number">0</span>:dt:<span class="number">1</span>;</span><br><span class="line">m = <span class="number">1</span>;</span><br><span class="line">[Y,X] = <span class="built_in">meshgrid</span>(y,x);</span><br><span class="line">U0 = <span class="built_in">exp</span>(<span class="number">-20</span>*((X<span class="number">-1</span>/<span class="number">2</span>).^<span class="number">2</span>+(Y<span class="number">-1</span>/<span class="number">2</span>).^<span class="number">2</span>));</span><br><span class="line">U = U0;</span><br><span class="line">hb = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">for</span> n = <span class="number">1</span>:<span class="built_in">length</span>(t)<span class="number">-1</span></span><br><span class="line">    U = U + (<span class="number">1</span><span class="built_in">i</span>*hb/<span class="number">2</span>/m)*(<span class="number">1</span>/dx^<span class="number">2</span>*A1*U+<span class="number">1</span>/dy^<span class="number">2</span>*U*A2)*dt;</span><br><span class="line">    surf(X,Y,<span class="built_in">abs</span>(U.^<span class="number">2</span>));</span><br><span class="line">    axis([x(<span class="number">1</span>) x(<span class="keyword">end</span>) y(<span class="number">1</span>) y(<span class="keyword">end</span>) <span class="number">0</span> <span class="number">1</span>]);</span><br><span class="line">    getframe;</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><p>加上$V(x)$后是：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">clear,clc;</span><br><span class="line">dx = <span class="number">0.1</span><span class="comment">% 时间和空间精度要同时增加</span></span><br><span class="line">Lx = <span class="number">10</span>;</span><br><span class="line">x = -Lx:dx:Lx;</span><br><span class="line">dy = <span class="number">0.1</span>;</span><br><span class="line">Ly = <span class="number">10</span>;</span><br><span class="line">y = -Ly:dy:Ly;</span><br><span class="line">A1 = <span class="number">-2</span>*<span class="built_in">eye</span>(<span class="built_in">length</span>(x))+<span class="built_in">diag</span>(<span class="built_in">ones</span>(<span class="number">1</span>,<span class="built_in">length</span>(x)<span class="number">-1</span>),<span class="number">1</span>)+<span class="built_in">diag</span>(<span class="built_in">ones</span>(<span class="number">1</span>,<span class="built_in">length</span>(x)<span class="number">-1</span>),<span class="number">-1</span>);</span><br><span class="line">A2 = <span class="number">-2</span>*<span class="built_in">eye</span>(<span class="built_in">length</span>(y))+<span class="built_in">diag</span>(<span class="built_in">ones</span>(<span class="number">1</span>,<span class="built_in">length</span>(y)<span class="number">-1</span>),<span class="number">1</span>)+<span class="built_in">diag</span>(<span class="built_in">ones</span>(<span class="number">1</span>,<span class="built_in">length</span>(y)<span class="number">-1</span>),<span class="number">-1</span>);</span><br><span class="line">dt = <span class="number">0.0001</span>;</span><br><span class="line">t = <span class="number">0</span>:dt:<span class="number">1</span>;</span><br><span class="line">m = <span class="number">1</span>;</span><br><span class="line">wx = <span class="number">3</span>;</span><br><span class="line">wy = <span class="number">3</span>;</span><br><span class="line">[Y,X] = <span class="built_in">meshgrid</span>(y,x);</span><br><span class="line">V = <span class="number">1</span>/<span class="number">2</span>*m*wx^<span class="number">2</span>*X.^<span class="number">2</span>+<span class="number">1</span>/<span class="number">2</span>*m*wy^<span class="number">2</span>*Y.^<span class="number">2</span>;</span><br><span class="line">D = <span class="number">3</span>;</span><br><span class="line">U0 = <span class="built_in">exp</span>(-((X<span class="number">-5</span>).^<span class="number">2</span>+Y.^<span class="number">2</span>)/D^<span class="number">2</span>).*<span class="built_in">exp</span>(<span class="number">1</span><span class="built_in">i</span>*<span class="number">10</span>*X);</span><br><span class="line">U = U0;</span><br><span class="line">hb = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">for</span> n = <span class="number">1</span>:<span class="built_in">length</span>(t)<span class="number">-1</span></span><br><span class="line">    U = U + (<span class="number">1</span><span class="built_in">i</span>*hb/<span class="number">2</span>/m)*(<span class="number">1</span>/dx^<span class="number">2</span>*A1*U+<span class="number">1</span>/dy^<span class="number">2</span>*U*A2)*dt+<span class="number">1</span>/hb/<span class="number">1</span><span class="built_in">i</span>*V.*U*dt;</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">mod</span>(n,<span class="number">50</span>) == <span class="number">1</span></span><br><span class="line">    surf(X,Y,<span class="built_in">abs</span>(U.^<span class="number">2</span>));</span><br><span class="line">    shading interp</span><br><span class="line">    axis([x(<span class="number">1</span>) x(<span class="keyword">end</span>) y(<span class="number">1</span>) y(<span class="keyword">end</span>) <span class="number">0</span> <span class="number">1</span>]);</span><br><span class="line">    getframe;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><p>如果精度太低，可以替换为：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">% Compute k1</span></span><br><span class="line">    K1 = (<span class="number">1</span><span class="built_in">i</span> * hb / <span class="number">2</span> / m) * (<span class="number">1</span> / dx^<span class="number">2</span> * (A1 * U) + <span class="number">1</span> / dy^<span class="number">2</span> * (U * A2)) * dt ...</span><br><span class="line">          + <span class="number">1</span> / hb / <span class="number">1</span><span class="built_in">i</span> * (V .* U) * dt;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">% Compute k2</span></span><br><span class="line">    U_half = U + <span class="number">0.5</span> * K1;</span><br><span class="line">    K2 = (<span class="number">1</span><span class="built_in">i</span> * hb / <span class="number">2</span> / m) * (<span class="number">1</span> / dx^<span class="number">2</span> * (A1 * U_half) + <span class="number">1</span> / dy^<span class="number">2</span> * (U_half * A2)) * dt ...</span><br><span class="line">          + <span class="number">1</span> / hb / <span class="number">1</span><span class="built_in">i</span> * (V .* U_half) * dt;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">% Compute k3</span></span><br><span class="line">    U_half = U + <span class="number">0.5</span> * K2;</span><br><span class="line">    K3 = (<span class="number">1</span><span class="built_in">i</span> * hb / <span class="number">2</span> / m) * (<span class="number">1</span> / dx^<span class="number">2</span> * (A1 * U_half) + <span class="number">1</span> / dy^<span class="number">2</span> * (U_half * A2)) * dt ...</span><br><span class="line">          + <span class="number">1</span> / hb / <span class="number">1</span><span class="built_in">i</span> * (V .* U_half) * dt;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">% Compute k4</span></span><br><span class="line">    U_full = U + K3;</span><br><span class="line">    K4 = (<span class="number">1</span><span class="built_in">i</span> * hb / <span class="number">2</span> / m) * (<span class="number">1</span> / dx^<span class="number">2</span> * (A1 * U_full) + <span class="number">1</span> / dy^<span class="number">2</span> * (U_full * A2)) * dt ...</span><br><span class="line">          + <span class="number">1</span> / hb / <span class="number">1</span><span class="built_in">i</span> * (V .* U_full) * dt;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">% Update U</span></span><br><span class="line">    U = U + (K1 + <span class="number">2</span> * K2 + <span class="number">2</span> * K3 + K4) / <span class="number">6</span>;</span><br></pre></td></tr></table></figure><h2 id="二维泊松方程"><a href="#二维泊松方程" class="headerlink" title="二维泊松方程"></a>二维泊松方程</h2><p>泊松方程属于椭圆形方程，假设不考虑z方向的差异性，那么可以将三维的泊松方程表达式转换为二维：</p><script type="math/tex; mode=display">(\frac{\partial^2}{\partial x^2}+\frac{\partial^2}{\partial y^2})u(x,y)=-\frac{\rho(x,y)}{\epsilon_0}</script><p>实际上，对于二维泊松方程处理和前面是大同小异的，通过给定一个初始条件，来让其随时间进行变化，如果最后解收敛后与时间无关，我们就认为得到了这个方程的解。</p><p>我们将二维泊松方程和二维热传导方程进行对比，会发现很像：</p><script type="math/tex; mode=display">\frac{\partial u}{\partial t}(x,y,t) = a^2(\frac{\partial^2}{\partial x^2}u(x,y,t)+\frac{\partial^2}{\partial y^2}u(x,y,t))+f(x,y,t)</script><p>二维泊松方程是静态的，而二维热传导方程是动态的，但是它们的数学表达式很大一部分的结构是一样的，区别就是它们的系数不同，所以我们可以利用热传导方程的方法去快速求解泊松方程，我们可以将$\rho(x,y)$类比成$f(x,y,t)$函数，然后只要当$\frac{\partial u}{\partial t}(x,y,t)=0$时，泊松方程的解法就与二维热传导方程解法一样了，这种方法可以大大减少编程的难度，这里的意思是， 当$u(x,y,t)$与时间变化无关后，相当于泊松方程其余项随时间演化完后变得与时间无关，最后变得稳定，也就是泊松方程最后的稳定解，泊松方程的求解可以看作是热传导方程在时间趋于稳定的极限情况。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">clear,clc;</span><br><span class="line">dx = <span class="number">0.02</span><span class="comment">% 时间和空间精度要同时增加</span></span><br><span class="line">Lx = <span class="number">1</span>;</span><br><span class="line">x = <span class="number">0</span>:dx:Lx;</span><br><span class="line">dy = <span class="number">0.1</span>;</span><br><span class="line">Ly = <span class="number">1</span>;</span><br><span class="line">y = <span class="number">0</span>:dy:Ly;</span><br><span class="line">A1 = <span class="number">-2</span>*<span class="built_in">eye</span>(<span class="built_in">length</span>(x))+<span class="built_in">diag</span>(<span class="built_in">ones</span>(<span class="number">1</span>,<span class="built_in">length</span>(x)<span class="number">-1</span>),<span class="number">1</span>)+<span class="built_in">diag</span>(<span class="built_in">ones</span>(<span class="number">1</span>,<span class="built_in">length</span>(x)<span class="number">-1</span>),<span class="number">-1</span>);</span><br><span class="line">A2 = <span class="number">-2</span>*<span class="built_in">eye</span>(<span class="built_in">length</span>(y))+<span class="built_in">diag</span>(<span class="built_in">ones</span>(<span class="number">1</span>,<span class="built_in">length</span>(y)<span class="number">-1</span>),<span class="number">1</span>)+<span class="built_in">diag</span>(<span class="built_in">ones</span>(<span class="number">1</span>,<span class="built_in">length</span>(y)<span class="number">-1</span>),<span class="number">-1</span>);</span><br><span class="line">dt = <span class="number">0.0001</span>;</span><br><span class="line">t = <span class="number">0</span>:dt:<span class="number">1</span>;</span><br><span class="line">m = <span class="number">1</span>;</span><br><span class="line">wx = <span class="number">3</span>;</span><br><span class="line">wy = <span class="number">3</span>;</span><br><span class="line">m1 = <span class="built_in">sin</span>(<span class="built_in">pi</span>*x/Lx);</span><br><span class="line">m2 = -<span class="built_in">sin</span>(<span class="built_in">pi</span>*x/Lx);</span><br><span class="line">m3 = <span class="number">0</span>*y&#x27;;</span><br><span class="line">m4 = <span class="number">0</span>*y&#x27;;</span><br><span class="line">[X,Y] = <span class="built_in">meshgrid</span>(x,y);</span><br><span class="line">D = <span class="number">0.2</span>;</span><br><span class="line">U0 = <span class="built_in">exp</span>(<span class="number">-10</span>*((X<span class="number">-1</span>/<span class="number">2</span>).^<span class="number">2</span>+(Y<span class="number">-1</span>/<span class="number">2</span>).^<span class="number">2</span>));</span><br><span class="line">U = U0;</span><br><span class="line">e0 = <span class="number">1</span>;</span><br><span class="line">rou = <span class="built_in">exp</span>(<span class="number">-10</span>*((X<span class="number">-1</span>/<span class="number">2</span>).^<span class="number">2</span>+(Y<span class="number">-1</span>/<span class="number">2</span>).^<span class="number">2</span>)/D^<span class="number">2</span>);</span><br><span class="line"><span class="keyword">for</span> n = <span class="number">1</span>:<span class="built_in">length</span>(t)<span class="number">-1</span></span><br><span class="line">    U = U + e0*(<span class="number">1</span>/dy^<span class="number">2</span>*A2*U+<span class="number">1</span>/dx^<span class="number">2</span>*U*A1)*dt+rou*dt;</span><br><span class="line">    U(<span class="number">1</span>,:)=m1;</span><br><span class="line">    U(<span class="keyword">end</span>,:)=m2;</span><br><span class="line">    U(:,<span class="number">1</span>)=m3;</span><br><span class="line">    U(:,<span class="keyword">end</span>)=m4;</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">mod</span>(n,<span class="number">50</span>) == <span class="number">1</span></span><br><span class="line">    surf(X,Y,U);</span><br><span class="line">    shading interp</span><br><span class="line">    axis([x(<span class="number">1</span>) x(<span class="keyword">end</span>) y(<span class="number">1</span>) y(<span class="keyword">end</span>) <span class="number">-1</span> <span class="number">1</span>]);</span><br><span class="line">    getframe;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">[Ex,Ey]=gradient(-U,dx,dy);</span><br><span class="line">contour(X,Y,U)<span class="comment">% 等势线</span></span><br><span class="line"><span class="built_in">hold</span> on</span><br><span class="line">quiver(X,Y,Ex,Ey)</span><br><span class="line">axis([x(<span class="number">1</span>) x(<span class="keyword">end</span>) y(<span class="number">1</span>) y(<span class="keyword">end</span>)])</span><br><span class="line">axis equal</span><br></pre></td></tr></table></figure><h2 id="二维拉普拉斯方程"><a href="#二维拉普拉斯方程" class="headerlink" title="二维拉普拉斯方程"></a>二维拉普拉斯方程</h2><p>实际上就是泊松方程的$\rho(x,y)=0$，得到的方程就是拉普拉斯方程。</p><script type="math/tex; mode=display">\frac{\partial^2}{\partial x^2}u(x,y)+\frac{\partial^2}{\partial y^2}u(x,y)=0</script><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">clear,clc;</span><br><span class="line">dx = <span class="number">0.02</span><span class="comment">% 时间和空间精度要同时增加</span></span><br><span class="line">Lx = <span class="number">1</span>;</span><br><span class="line">x = <span class="number">0</span>:dx:Lx;</span><br><span class="line">dy = <span class="number">0.1</span>;</span><br><span class="line">Ly = <span class="number">1</span>;</span><br><span class="line">y = <span class="number">0</span>:dy:Ly;</span><br><span class="line">A1 = <span class="number">-2</span>*<span class="built_in">eye</span>(<span class="built_in">length</span>(x))+<span class="built_in">diag</span>(<span class="built_in">ones</span>(<span class="number">1</span>,<span class="built_in">length</span>(x)<span class="number">-1</span>),<span class="number">1</span>)+<span class="built_in">diag</span>(<span class="built_in">ones</span>(<span class="number">1</span>,<span class="built_in">length</span>(x)<span class="number">-1</span>),<span class="number">-1</span>);</span><br><span class="line">A2 = <span class="number">-2</span>*<span class="built_in">eye</span>(<span class="built_in">length</span>(y))+<span class="built_in">diag</span>(<span class="built_in">ones</span>(<span class="number">1</span>,<span class="built_in">length</span>(y)<span class="number">-1</span>),<span class="number">1</span>)+<span class="built_in">diag</span>(<span class="built_in">ones</span>(<span class="number">1</span>,<span class="built_in">length</span>(y)<span class="number">-1</span>),<span class="number">-1</span>);</span><br><span class="line">dt = <span class="number">0.0001</span>;</span><br><span class="line">t = <span class="number">0</span>:dt:<span class="number">1</span>;</span><br><span class="line">m = <span class="number">1</span>;</span><br><span class="line">wx = <span class="number">3</span>;</span><br><span class="line">wy = <span class="number">3</span>;</span><br><span class="line">m1 = <span class="built_in">sin</span>(<span class="built_in">pi</span>*x/Lx);</span><br><span class="line">m2 = -<span class="built_in">sin</span>(<span class="built_in">pi</span>*x/Lx);</span><br><span class="line">m3 = <span class="number">0</span>*y&#x27;;</span><br><span class="line">m4 = <span class="number">0</span>*y&#x27;;</span><br><span class="line">[X,Y] = <span class="built_in">meshgrid</span>(x,y);</span><br><span class="line">D = <span class="number">3</span>;</span><br><span class="line">U0 = <span class="built_in">exp</span>(-(X.^<span class="number">2</span>+Y.^<span class="number">2</span>)/D^<span class="number">2</span>);</span><br><span class="line">U = U0;</span><br><span class="line">e0 = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">for</span> n = <span class="number">1</span>:<span class="built_in">length</span>(t)<span class="number">-1</span></span><br><span class="line">    U = U + e0*(<span class="number">1</span>/dy^<span class="number">2</span>*A2*U+<span class="number">1</span>/dx^<span class="number">2</span>*U*A1)*dt;</span><br><span class="line">    U(<span class="number">1</span>,:)=m1;</span><br><span class="line">    U(<span class="keyword">end</span>,:)=m2;</span><br><span class="line">    U(:,<span class="number">1</span>)=m3;</span><br><span class="line">    U(:,<span class="keyword">end</span>)=m4;</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">mod</span>(n,<span class="number">50</span>) == <span class="number">1</span></span><br><span class="line">    surf(X,Y,U);</span><br><span class="line">    shading interp</span><br><span class="line">    axis([x(<span class="number">1</span>) x(<span class="keyword">end</span>) y(<span class="number">1</span>) y(<span class="keyword">end</span>) <span class="number">-1</span> <span class="number">1</span>]);</span><br><span class="line">    getframe;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">[Ex,Ey]=gradient(-U,dx,dy);</span><br><span class="line">contour(X,Y,U)<span class="comment">% 等势线</span></span><br><span class="line"><span class="built_in">hold</span> on</span><br><span class="line">quiver(X,Y,Ex,Ey)</span><br><span class="line">axis([x(<span class="number">1</span>) x(<span class="keyword">end</span>) y(<span class="number">1</span>) y(<span class="keyword">end</span>)])</span><br><span class="line">axis equal</span><br></pre></td></tr></table></figure><h2 id="一维波动方程"><a href="#一维波动方程" class="headerlink" title="一维波动方程"></a>一维波动方程</h2><p>一维波动方程是描述一维空间中波动现象的经典方程。它通常用于模拟和分析声波、光波或其他类型的波在一维介质中的传播，一维波动方程是双曲型波动方程，其表达式为:</p><script type="math/tex; mode=display">\frac{\partial^2u}{\partial t^2}=a^2\frac{\partial^2u}{\partial x^2}+f(x,t)</script><p>假设$f(x,t)=0$，初始条件为：</p><script type="math/tex; mode=display">u(0,t) = \mu_1(t) , u(l,t)=\mu_2(t)</script><script type="math/tex; mode=display">u(x,0) = \varphi_1(x) , \frac{\partial u(x,t)}{\partial t}|_{t=0}=\varphi_2(x)</script><p>当不设有边界条件后，根据达朗贝尔公式，有：</p><script type="math/tex; mode=display">u(x,t)=f_1(x-at)+f_2(x+at)</script><p>这里的$u(x,t)$便是方程的解，可以把$f_1(x-at)$和$f_2(x+at)$当作两个波，$a$就是波速。</p><p>假设波动在一条无限长的弦上，这里可以用周期性边界来实现，假设初始条件为：</p><script type="math/tex; mode=display">u|_{t=0}=f_1(x), \frac{\partial u}{\partial t} |_{t=0} = -af_1'(x)</script><p>令：</p><script type="math/tex; mode=display">v = \frac{\partial u}{\partial t}</script><p>则有：</p><script type="math/tex; mode=display">u^{n+1}=u^n+v^ndt</script><script type="math/tex; mode=display">v^{n+1}=v^n+\frac{a^2Au^2}{dx^2}dt</script><script type="math/tex; mode=display">u^1=f_1(x),v^1=-af_1'(x)</script><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">clear; clc;</span><br><span class="line">dx = <span class="number">0.01</span>;</span><br><span class="line">Lx = <span class="number">1</span>;</span><br><span class="line">x = -Lx:dx:Lx;</span><br><span class="line">a = <span class="number">1</span>;</span><br><span class="line">n = <span class="built_in">length</span>(x);</span><br><span class="line"><span class="comment">% 构建离散化矩阵 A</span></span><br><span class="line">A = <span class="number">-2</span>*<span class="built_in">eye</span>(n) + <span class="built_in">diag</span>(<span class="built_in">ones</span>(n<span class="number">-1</span>,<span class="number">1</span>),<span class="number">1</span>) + <span class="built_in">diag</span>(<span class="built_in">ones</span>(n<span class="number">-1</span>,<span class="number">1</span>),<span class="number">-1</span>);</span><br><span class="line"><span class="comment">% 周期边界条件</span></span><br><span class="line">A(<span class="number">1</span>,n) = <span class="number">1</span>;</span><br><span class="line">A(n,<span class="number">1</span>) = <span class="number">1</span>;</span><br><span class="line">dt = <span class="number">0.001</span>;</span><br><span class="line">t = <span class="number">0</span>:dt:<span class="number">4</span>;</span><br><span class="line">u = <span class="built_in">zeros</span>(n, <span class="built_in">length</span>(t));</span><br><span class="line">v = <span class="built_in">zeros</span>(n, <span class="built_in">length</span>(t));</span><br><span class="line">Dx = <span class="number">0.1</span>;</span><br><span class="line">u0 = <span class="built_in">exp</span>(-x.^<span class="number">2</span>/Dx^<span class="number">2</span>);</span><br><span class="line">v0 = <span class="number">2</span>*a*<span class="built_in">exp</span>(-x.^<span class="number">2</span>/Dx^<span class="number">2</span>).*x/Dx^<span class="number">2</span>;</span><br><span class="line">u(:,<span class="number">1</span>) = u0&#x27;;</span><br><span class="line">v(:,<span class="number">1</span>) = v0&#x27;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[u_next, v_next]</span> = <span class="title">rk4_step</span><span class="params">(u, v, A, a, dx, dt)</span></span></span><br><span class="line">    k1u = v;</span><br><span class="line">    k1v = a^<span class="number">2</span> * (A * u) / dx^<span class="number">2</span>;</span><br><span class="line">    </span><br><span class="line">    k2u = v + <span class="number">0.5</span> * dt * k1v;</span><br><span class="line">    k2v = a^<span class="number">2</span> * (A * (u + <span class="number">0.5</span> * dt * k1u)) / dx^<span class="number">2</span>;</span><br><span class="line">    </span><br><span class="line">    k3u = v + <span class="number">0.5</span> * dt * k2v;</span><br><span class="line">    k3v = a^<span class="number">2</span> * (A * (u + <span class="number">0.5</span> * dt * k2u)) / dx^<span class="number">2</span>;</span><br><span class="line">    </span><br><span class="line">    k4u = v + dt * k3v;</span><br><span class="line">    k4v = a^<span class="number">2</span> * (A * (u + dt * k3u)) / dx^<span class="number">2</span>;</span><br><span class="line">    </span><br><span class="line">    u_next = u + (dt / <span class="number">6</span>) * (k1u + <span class="number">2</span>*k2u + <span class="number">2</span>*k3u + k4u);</span><br><span class="line">    v_next = v + (dt / <span class="number">6</span>) * (k1v + <span class="number">2</span>*k2v + <span class="number">2</span>*k3v + k4v);</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> n = <span class="number">1</span>:<span class="built_in">length</span>(t)<span class="number">-1</span></span><br><span class="line">    [u(:,n+<span class="number">1</span>), v(:,n+<span class="number">1</span>)] = rk4_step(u(:,n), v(:,n), A, a, dx, dt);</span><br><span class="line">    <span class="built_in">plot</span>(x, u(:,n+<span class="number">1</span>));</span><br><span class="line">    axis([x(<span class="number">1</span>) x(<span class="keyword">end</span>) <span class="number">0</span> <span class="number">1.2</span>]);</span><br><span class="line">    getframe;</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><p>以上只有一股波，如果想实现两股波的叠加，只需要在u0和v0处进行更改即可：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">clear; clc;</span><br><span class="line">dx = <span class="number">0.01</span>;</span><br><span class="line">Lx = <span class="number">1</span>;</span><br><span class="line">x = -Lx:dx:Lx;</span><br><span class="line">a = <span class="number">1</span>;</span><br><span class="line">n = <span class="built_in">length</span>(x);</span><br><span class="line"><span class="comment">% 构建离散化矩阵 A</span></span><br><span class="line">A = <span class="number">-2</span>*<span class="built_in">eye</span>(n) + <span class="built_in">diag</span>(<span class="built_in">ones</span>(n<span class="number">-1</span>,<span class="number">1</span>),<span class="number">1</span>) + <span class="built_in">diag</span>(<span class="built_in">ones</span>(n<span class="number">-1</span>,<span class="number">1</span>),<span class="number">-1</span>);</span><br><span class="line"><span class="comment">% 周期边界条件</span></span><br><span class="line">A(<span class="number">1</span>,<span class="keyword">end</span>) = <span class="number">1</span>;</span><br><span class="line">A(<span class="keyword">end</span>,<span class="number">1</span>) = <span class="number">1</span>;</span><br><span class="line">dt = <span class="number">0.0001</span>;</span><br><span class="line">t = <span class="number">0</span>:dt:<span class="number">4</span>;</span><br><span class="line">u = <span class="built_in">zeros</span>(n, <span class="built_in">length</span>(t));</span><br><span class="line">v = <span class="built_in">zeros</span>(n, <span class="built_in">length</span>(t));</span><br><span class="line">Dx = <span class="number">0.2</span>;</span><br><span class="line">x0=<span class="number">0.5</span>;</span><br><span class="line">u0 = <span class="built_in">exp</span>(-(x-x0).^<span class="number">2</span>/Dx^<span class="number">2</span>)-<span class="built_in">exp</span>(-(x+x0).^<span class="number">2</span>/Dx^<span class="number">2</span>);</span><br><span class="line">v0 = <span class="number">-2</span>*a*<span class="built_in">exp</span>(-(x-x0).^<span class="number">2</span>/Dx^<span class="number">2</span>).*(x-x0)/Dx^<span class="number">2</span><span class="number">-2</span>*a*<span class="built_in">exp</span>(-(x+x0).^<span class="number">2</span>/Dx^<span class="number">2</span>).*(x+x0)/Dx^<span class="number">2</span>;</span><br><span class="line">u(:,<span class="number">1</span>) = u0&#x27;;</span><br><span class="line">v(:,<span class="number">1</span>) = v0&#x27;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[u_next, v_next]</span> = <span class="title">rk4_step</span><span class="params">(u, v, A, a, dx, dt)</span></span></span><br><span class="line">    k1u = v;</span><br><span class="line">    k1v = a^<span class="number">2</span> * (A * u) / dx^<span class="number">2</span>;</span><br><span class="line">    </span><br><span class="line">    k2u = v + <span class="number">0.5</span> * dt * k1v;</span><br><span class="line">    k2v = a^<span class="number">2</span> * (A * (u + <span class="number">0.5</span> * dt * k1u)) / dx^<span class="number">2</span>;</span><br><span class="line">    </span><br><span class="line">    k3u = v + <span class="number">0.5</span> * dt * k2v;</span><br><span class="line">    k3v = a^<span class="number">2</span> * (A * (u + <span class="number">0.5</span> * dt * k2u)) / dx^<span class="number">2</span>;</span><br><span class="line">    </span><br><span class="line">    k4u = v + dt * k3v;</span><br><span class="line">    k4v = a^<span class="number">2</span> * (A * (u + dt * k3u)) / dx^<span class="number">2</span>;</span><br><span class="line">    </span><br><span class="line">    u_next = u + (dt / <span class="number">6</span>) * (k1u + <span class="number">2</span>*k2u + <span class="number">2</span>*k3u + k4u);</span><br><span class="line">    v_next = v + (dt / <span class="number">6</span>) * (k1v + <span class="number">2</span>*k2v + <span class="number">2</span>*k3v + k4v);</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> n = <span class="number">1</span>:<span class="built_in">length</span>(t)<span class="number">-1</span></span><br><span class="line">    [u(:,n+<span class="number">1</span>), v(:,n+<span class="number">1</span>)] = rk4_step(u(:,n), v(:,n), A, a, dx, dt);</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">mod</span>(n,<span class="number">100</span>)==<span class="number">1</span></span><br><span class="line">    <span class="built_in">plot</span>(x, u(:,n+<span class="number">1</span>));</span><br><span class="line">    axis([x(<span class="number">1</span>) x(<span class="keyword">end</span>) <span class="number">-1</span> <span class="number">2</span>]);</span><br><span class="line">    getframe;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 数值分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数值积分与数值微分(Matlab实现)(Updating...)</title>
      <link href="/2024/08/22/%E6%95%B0%E5%80%BC%E7%A7%AF%E5%88%86%E4%B8%8E%E6%95%B0%E5%80%BC%E5%BE%AE%E5%88%86/"/>
      <url>/2024/08/22/%E6%95%B0%E5%80%BC%E7%A7%AF%E5%88%86%E4%B8%8E%E6%95%B0%E5%80%BC%E5%BE%AE%E5%88%86/</url>
      
        <content type="html"><![CDATA[<h1 id="数值积分与数值微分"><a href="#数值积分与数值微分" class="headerlink" title="数值积分与数值微分"></a>数值积分与数值微分</h1><h2 id="数值积分"><a href="#数值积分" class="headerlink" title="数值积分"></a>数值积分</h2><p>我们曾学习过牛顿莱布尼茨公式，只要知道F(X)，就可以来计算定积分。</p><script type="math/tex; mode=display">\int_a^bf(x)dx = F(b)-F(a)</script><p>但实际上，很多复杂函数的原函数我们是无法求出其解析解的，所以想要求解任意一个定积分，就需要数值积分来进行求解。</p><p>后面介绍的许多积分公式都是在<strong>机械求积公式</strong>得到的，机械求积公式是最简单的办法，同时精度也很低。</p><script type="math/tex; mode=display">\int_a^b f(x)dx = \sum_{k=0}^nA_kf(x_k)</script><script type="math/tex; mode=display">\sum_{k=1}^nA_k=b-a</script><p>在此基础上，根据积分中值定理，以b-a为底，$f(\xi)$为高的矩形面积：</p><script type="math/tex; mode=display">\int_a^bf(x)dx = f(\xi)(b-a)</script><p>根据梯形公式，得到<strong>梯形积分公式</strong>：</p><script type="math/tex; mode=display">f(\xi)=\frac{f(a)+f(b)}{2}</script><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">f = @(t) <span class="built_in">sin</span>(t);</span><br><span class="line"></span><br><span class="line"><span class="comment">% 梯形法数值积分</span></span><br><span class="line">h = <span class="number">0.01</span>;</span><br><span class="line">t = <span class="number">0</span>:h:<span class="number">10</span>;</span><br><span class="line">n = <span class="built_in">length</span>(t);</span><br><span class="line">s = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:n<span class="number">-1</span></span><br><span class="line">    s = s + <span class="number">0.5</span> * (f(t(<span class="built_in">i</span>)) + f(t(<span class="built_in">i</span>+<span class="number">1</span>))) * h;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% 解析解</span></span><br><span class="line">exact_solution = integral(f, <span class="number">0</span>, <span class="number">10</span>);</span><br><span class="line"></span><br><span class="line">fprintf(<span class="string">&#x27;数值积分结果: %.6f\n&#x27;</span>, s);</span><br><span class="line">fprintf(<span class="string">&#x27;解析解结果: %.6f\n&#x27;</span>, exact_solution);</span><br><span class="line">fprintf(<span class="string">&#x27;误差: %.6f\n&#x27;</span>, <span class="built_in">abs</span>(s - exact_solution));</span><br></pre></td></tr></table></figure><p>可以得到:</p><script type="math/tex; mode=display">\int_a^b f(x)dx=\frac{f(a)+f(b)}{2}(b-a)</script><p>又或是根据中值公式：</p><script type="math/tex; mode=display">f(\xi)=f(\frac{a+b}{2})</script><p>可以得到<strong>中值积分公式</strong>：</p><script type="math/tex; mode=display">\int_a^bf(x)dx=f(\frac{a+b}{2})(b-a)</script><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">f = @(t) <span class="built_in">sin</span>(t);</span><br><span class="line"></span><br><span class="line"><span class="comment">% 中点法数值积分</span></span><br><span class="line">h = <span class="number">0.01</span>;</span><br><span class="line">t = <span class="number">0</span>:h:<span class="number">10</span>;</span><br><span class="line">n = <span class="built_in">length</span>(t);</span><br><span class="line">s = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:n<span class="number">-1</span></span><br><span class="line">    s = s + f(t(<span class="built_in">i</span>) + <span class="number">0.5</span> * h) * h;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">exact_solution = integral(f, <span class="number">0</span>, <span class="number">10</span>);</span><br><span class="line"></span><br><span class="line">fprintf(<span class="string">&#x27;数值积分结果: %.6f\n&#x27;</span>, s);</span><br><span class="line">fprintf(<span class="string">&#x27;解析解结果: %.6f\n&#x27;</span>, exact_solution);</span><br><span class="line">fprintf(<span class="string">&#x27;误差: %.6f\n&#x27;</span>, <span class="built_in">abs</span>(s - exact_solution));</span><br></pre></td></tr></table></figure><p>这两种都是简单的近似，更高精度的近似可以用<strong>辛普森公式（Simpson)</strong>：</p><script type="math/tex; mode=display">\int_a^bf(x)dx\approx \frac{(b-a)}{6}\cdot[f(a)+4f(\frac{a+b}{2})+f(b)]</script><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">f = @(t) <span class="built_in">sin</span>(t);</span><br><span class="line"></span><br><span class="line"><span class="comment">% Simpson method</span></span><br><span class="line">h = <span class="number">0.001</span>; <span class="comment">%</span></span><br><span class="line">t = <span class="number">0</span>:h:<span class="number">20</span>; </span><br><span class="line">n = <span class="built_in">length</span>(t);</span><br><span class="line">s = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:n<span class="number">-1</span></span><br><span class="line">    s = s + (f(t(<span class="built_in">i</span>)) + <span class="number">4</span> * f(t(<span class="built_in">i</span>) + <span class="number">0.5</span> * h) + f(t(<span class="built_in">i</span>) + h)) * h / <span class="number">6</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">exact_solution = integral(f, <span class="number">0</span>, <span class="number">20</span>);</span><br><span class="line">fprintf(<span class="string">&#x27;数值积分结果: %.6f\n&#x27;</span>, s);</span><br><span class="line">fprintf(<span class="string">&#x27;解析解结果: %.6f\n&#x27;</span>, exact_solution);</span><br><span class="line">fprintf(<span class="string">&#x27;误差: %.6f\n&#x27;</span>, <span class="built_in">abs</span>(s - exact_solution));</span><br></pre></td></tr></table></figure><p>对梯形法进行改造，得到新的方法：<strong>龙贝格积分法</strong>（Romberg Integration）是一种数值积分方法，它通过递归加速梯形积分法的收敛速度，以提高积分的精度。龙贝格积分法利用<strong>Richardson外推</strong>技术来组合多个不同步长的梯形法积分结果，从而实现更高阶的精度，其中b - a = h。</p><script type="math/tex; mode=display">T_{0,0} = \frac{h}{2} \left( f(a) + f(b) \right)</script><script type="math/tex; mode=display">T_{k,0} = \frac{1}{2} T_{k-1,0} + h_k \sum_{i=1}^{2^{k-1}} f\left( a + \left( i - \frac{1}{2} \right) h_k \right)</script><script type="math/tex; mode=display">T_{k,m} = \frac{4^m T_{k,m-1} - T_{k-1,m-1}}{4^m - 1}</script><script type="math/tex; mode=display">h_k = \frac{b - a}{2^k}</script><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">R</span> = <span class="title">romberg</span><span class="params">(f, a, b, n)</span></span></span><br><span class="line">    R = <span class="built_in">zeros</span>(n,n);  <span class="comment">% 初始化Romberg表</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">% 梯形法的计算</span></span><br><span class="line">    h = b - a;</span><br><span class="line">    R(<span class="number">1</span>,<span class="number">1</span>) = <span class="number">0.5</span> * h * (f(a) + f(b));</span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">2</span>:n</span><br><span class="line">        h = h / <span class="number">2</span>;</span><br><span class="line">        sum = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> k = <span class="number">1</span>:<span class="number">2</span>^(<span class="built_in">i</span><span class="number">-2</span>)</span><br><span class="line">            sum = sum + f(a + (<span class="number">2</span>*k<span class="number">-1</span>)*h);</span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">        R(<span class="built_in">i</span>,<span class="number">1</span>) = <span class="number">0.5</span> * R(<span class="built_in">i</span><span class="number">-1</span>,<span class="number">1</span>) + sum * h;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">% Richardson外推</span></span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">j</span> = <span class="number">2</span>:n</span><br><span class="line">        <span class="keyword">for</span> <span class="built_in">i</span> = <span class="built_in">j</span>:n</span><br><span class="line">            R(<span class="built_in">i</span>,<span class="built_in">j</span>) = (<span class="number">4</span>^(<span class="built_in">j</span><span class="number">-1</span>) * R(<span class="built_in">i</span>,<span class="built_in">j</span><span class="number">-1</span>) - R(<span class="built_in">i</span><span class="number">-1</span>,<span class="built_in">j</span><span class="number">-1</span>)) / (<span class="number">4</span>^(<span class="built_in">j</span><span class="number">-1</span>) - <span class="number">1</span>);</span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">f = @(x) <span class="built_in">sin</span>(x);</span><br><span class="line">a = <span class="number">0</span>;</span><br><span class="line">b = <span class="built_in">pi</span>;</span><br><span class="line">n = <span class="number">5</span>;  <span class="comment">% 5阶Romberg积分</span></span><br><span class="line">R = romberg(f, a, b, n);</span><br><span class="line">fprintf(<span class="string">&#x27;Romberg积分结果: %.6f\n&#x27;</span>, R(n,n));</span><br></pre></td></tr></table></figure><h2 id="代数精度"><a href="#代数精度" class="headerlink" title="代数精度"></a>代数精度</h2><p>若一个求积公式对于所有次数不超过m的多项式都准确成立，而对于某一个m+1次的多项式等式不成立，则称这个求积公式有m次代数精度。比如，如果一个方法能够对任意线性多项式（即一阶多项式，如 ax+b）给出精确结果，但不能对二次多项式（如 ax2+bx+c）给出精确结果，那么该方法的代数精度为 1。</p><p><strong>矩形法（Midpoint Rule）</strong>：代数精度为 1。它能精确积分常数和线性函数，但对二次及更高次多项式不准确。</p><p><strong>梯形法（Trapezoidal Rule）</strong>：代数精度为 1。它能精确积分线性函数，但不能精确积分二次及更高次多项式。</p><p><strong>辛普森法（Simpson’s Rule）</strong>：代数精度为 3。它能精确积分最高三次的多项式（包括常数、线性、二次和三次函数）。</p><p><strong>高斯求积法（Gaussian Quadrature）</strong>：根据选定的节点数，代数精度可以是非常高的。例如，使用 n 个节点的高斯求积法的代数精度为 2n−1。</p><h2 id="插值型求积公式"><a href="#插值型求积公式" class="headerlink" title="插值型求积公式"></a>插值型求积公式</h2><p><strong>插值型求积分公式</strong>是一种利用插值多项式来近似计算定积分的方法。具体而言，这种方法通过对函数 f(x) 进行插值，并计算插值多项式的积分来近似原函数的积分值。常见的插值积分公式包括牛顿-科特斯公式和高斯求积公式。</p><p>首先，根据给定节点 x0,x1,…,xn对函数 f(x)进行插值，得到插值多项式 P(x)。然后对插值多项式 P(x) 进行积分，以近似原函数 f(x)的积分。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 数值分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>用Matlab求解非线性函数方程</title>
      <link href="/2024/08/22/%E9%9D%9E%E7%BA%BF%E6%80%A7%E5%87%BD%E6%95%B0%E6%96%B9%E7%A8%8B%E7%9A%84%E6%B1%82%E8%A7%A3/"/>
      <url>/2024/08/22/%E9%9D%9E%E7%BA%BF%E6%80%A7%E5%87%BD%E6%95%B0%E6%96%B9%E7%A8%8B%E7%9A%84%E6%B1%82%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<h1 id="二分搜索法"><a href="#二分搜索法" class="headerlink" title="二分搜索法"></a>二分搜索法</h1><p><strong>二分法</strong>（Bisection Method）是一种用于求解实数函数方程根的数值方法。基于连续函数的介值定理，通过逐步缩小区间来逼近方程的根，若想改成特定的函数，只需要将0改为所需的a即可。</p><p>选择一个初始区间 [a,b]，要求函数 f(x) 在该区间内连续，并且满足 f(a)⋅f(b)&lt;0。这意味着在区间[a, b] 内存在一个根（根据介值定理），接着计算区间的中点 $c = \frac{a + b}{2}$。根据 f(c) 的符号来决定更新区间：如果 f(a)⋅f(c)&lt;0，则根在 [a,c] 区间内，将 b 更新为 c。如果 f(c)⋅f(b)&lt;0，则根在 [c,b] 区间内，将 a 更新为 c，重复上述步骤，直到区间的长度小于预设的精度 ϵ，或者达到最大迭代次数。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">f = @(x) x^<span class="number">4</span> - <span class="number">4</span>;</span><br><span class="line">a = <span class="number">1</span>; <span class="comment">% 区间下界</span></span><br><span class="line">b = <span class="number">3</span>; <span class="comment">% 区间上界</span></span><br><span class="line">tol = <span class="number">1e-6</span>; <span class="comment">% 精度</span></span><br><span class="line">max_iter = <span class="number">100</span>; <span class="comment">% 最大迭代次数</span></span><br><span class="line">[root, iter] = bisection_method(f, a, b, tol, max_iter);</span><br></pre></td></tr></table></figure><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[root,inter]</span> = <span class="title">bisection_method</span><span class="params">(f,a,b,error,max_inter)</span></span></span><br><span class="line">inter = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">if</span> f(a)*f(b)&gt;= <span class="number">0</span></span><br><span class="line">    error(<span class="string">&quot;No suitable answer&quot;</span>);</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">root = (a+b)/<span class="number">2</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> (b - a) / <span class="number">2</span> &gt; error &amp;&amp; inter &lt; max_inter</span><br><span class="line">    inter = inter + <span class="number">1</span>;</span><br><span class="line">    c = (a+b)/<span class="number">2</span>;</span><br><span class="line">    <span class="keyword">if</span> f(c) == <span class="number">0</span></span><br><span class="line">        root = c;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">elseif</span> f(c)*f(a) &lt; <span class="number">0</span></span><br><span class="line">        b = c;</span><br><span class="line">        root = (a+b)/<span class="number">2</span>;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        a = c;</span><br><span class="line">        root = (a+b)/<span class="number">2</span>;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">fprintf(<span class="string">&quot;根的近似值为:%.6f&quot;</span>,root);</span><br><span class="line">fprintf(<span class="string">&quot;迭代次数为:%.6f&quot;</span>,inter);</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><h1 id="牛顿法"><a href="#牛顿法" class="headerlink" title="牛顿法"></a>牛顿法</h1><p>牛顿法是一种用于寻找函数零点的迭代方法。其基本思想是通过函数的泰勒二阶展开式来近似解，并逐步逼近根，缺点是必须知道函数的一阶和二阶导数。</p><script type="math/tex; mode=display">f(x) \approx f(a) + f'(a)(x-a)+\frac{f''(a)}{2!}(x-a)^2</script><script type="math/tex; mode=display">f(x)\approx \frac{1}{2}f''(a)x^2+[f'(a)-f''(a)a]x + C(a)</script><script type="math/tex; mode=display">\frac{f(x)}{dx} \approx f''(a)x + [f'(a)-f''(a)a] = 0</script><script type="math/tex; mode=display">x = a - \frac{f'(a)}{f''(a)}</script><p>假定初始猜测值为$x_0$，迭代公式为：</p><script type="math/tex; mode=display">x_{n+1} = x_n - \frac{f'(x_n)}{f''(x_n)}</script><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">clc;</span><br><span class="line">clear all;</span><br><span class="line">close all;</span><br><span class="line"></span><br><span class="line"><span class="comment">% 定义目标函数及其导数</span></span><br><span class="line">y = @(x) (x.^<span class="number">2</span> - <span class="number">4</span>*x + <span class="built_in">sin</span>(x));</span><br><span class="line">y_first = @(x) (<span class="number">2.</span>*x - <span class="number">4</span> + <span class="built_in">cos</span>(x));</span><br><span class="line">y_second = @(x) (x - <span class="built_in">sin</span>(x));</span><br><span class="line"></span><br><span class="line"><span class="comment">% 初始值</span></span><br><span class="line">x_ori = <span class="number">20</span>;</span><br><span class="line">x_solu = [x_ori];</span><br><span class="line"></span><br><span class="line"><span class="comment">% 牛顿法迭代</span></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:<span class="number">20</span></span><br><span class="line">    x = x_ori;</span><br><span class="line">    y_first_1 = y_first(x);</span><br><span class="line">    y_second_1 = y_second(x);</span><br><span class="line">    x_temp = x - y_first_1 ./ (y_second_1 + <span class="built_in">eps</span>);</span><br><span class="line">    x_solu = [x_solu; x_temp];</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% 绘图</span></span><br><span class="line">f = @(x) (x.^<span class="number">2</span> - <span class="number">4</span>*x + <span class="built_in">sin</span>(x));</span><br><span class="line"></span><br><span class="line">x = <span class="number">-40</span>:<span class="number">0.1</span>:<span class="number">40</span>;</span><br><span class="line"><span class="built_in">plot</span>(x, f(x), <span class="string">&#x27;k&#x27;</span>); <span class="comment">% 绘制目标函数</span></span><br><span class="line"><span class="built_in">hold</span> on;</span><br><span class="line"><span class="built_in">scatter</span>(x_solu(<span class="number">1</span>), f(x_solu(<span class="number">1</span>)), <span class="string">&#x27;g&#x27;</span>, <span class="string">&#x27;filled&#x27;</span>); <span class="comment">% 起始点</span></span><br><span class="line"><span class="built_in">plot</span>(x_solu(<span class="number">2</span>:<span class="keyword">end</span><span class="number">-1</span>), f(x_solu(<span class="number">2</span>:<span class="keyword">end</span><span class="number">-1</span>)), <span class="string">&#x27;r&#x27;</span>); <span class="comment">% 迭代轨迹</span></span><br><span class="line"><span class="built_in">scatter</span>(x_solu(<span class="number">2</span>:<span class="keyword">end</span><span class="number">-1</span>), f(x_solu(<span class="number">2</span>:<span class="keyword">end</span><span class="number">-1</span>)), <span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;filled&#x27;</span>); <span class="comment">% 迭代点</span></span><br><span class="line"><span class="built_in">scatter</span>(x_solu(<span class="keyword">end</span>), f(x_solu(<span class="keyword">end</span>)), <span class="string">&#x27;y&#x27;</span>, <span class="string">&#x27;filled&#x27;</span>); <span class="comment">% 最终点</span></span><br><span class="line"><span class="built_in">legend</span>(<span class="string">&#x27;Objective Function&#x27;</span>, <span class="string">&#x27;Start Point&#x27;</span>, <span class="string">&#x27;Search Trace&#x27;</span>, <span class="string">&#x27;Minimizer&#x27;</span>);</span><br><span class="line"><span class="built_in">hold</span> off;</span><br><span class="line">title(<span class="string">&#x27;Newton Method Optimization&#x27;</span>);</span><br><span class="line">xlabel(<span class="string">&#x27;x&#x27;</span>);</span><br><span class="line">ylabel(<span class="string">&#x27;f&#x27;</span>);</span><br></pre></td></tr></table></figure><h1 id="梯度下降法"><a href="#梯度下降法" class="headerlink" title="梯度下降法"></a>梯度下降法</h1><p>梯度下降法的数学原理其实特别简单，就是一阶泰勒展开，假如导数小于0，说明这时候X应该向前走，所以学习率前要加一个负号，对于原始的梯度下降法，我们需要知道原函数的导数。</p><script type="math/tex; mode=display">\mathbf{x}_{k+1} = \mathbf{x}_k - \alpha \nabla f(\mathbf{x}_k)</script><p>其中，α是学习率，是一个超参数，需要人为的不断调整，$\nabla f(\mathbf{x}_k)$则代表了函数的梯度。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%f(x) = x^2 + 4x + 4</span></span><br><span class="line"></span><br><span class="line">x0 = <span class="number">0</span>; <span class="comment">% 初始值</span></span><br><span class="line">alpha = <span class="number">0.1</span>; <span class="comment">% 学习率</span></span><br><span class="line">tolerance = <span class="number">1e-6</span>; <span class="comment">% 收敛条件</span></span><br><span class="line">max_iter = <span class="number">1000</span>; <span class="comment">% 最大迭代次数</span></span><br><span class="line"></span><br><span class="line">f = @(x) x.^<span class="number">2</span> + <span class="number">4</span>*x + <span class="number">4</span>; </span><br><span class="line">grad_f = @(x) <span class="number">2</span>*x + <span class="number">4</span>;</span><br><span class="line"></span><br><span class="line">x = x0; </span><br><span class="line"><span class="keyword">for</span> k = <span class="number">1</span>:max_iter</span><br><span class="line">    x_new = x - alpha * grad_f(x); </span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">abs</span>(x_new - x) &lt; tolerance <span class="comment">% 判断是否满足收敛条件</span></span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    x = x_new; </span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">fprintf(<span class="string">&#x27;迭代次数: %d\n&#x27;</span>, k);</span><br><span class="line">fprintf(<span class="string">&#x27;最优解: x = %.6f\n&#x27;</span>, x);</span><br><span class="line">fprintf(<span class="string">&#x27;最优函数值: f(x) = %.6f\n&#x27;</span>, f(x));</span><br><span class="line"></span><br><span class="line">x_vals = <span class="number">-5</span>:<span class="number">0.1</span>:<span class="number">3</span>;</span><br><span class="line">y_vals = f(x_vals);</span><br><span class="line"><span class="built_in">plot</span>(x_vals, y_vals, <span class="string">&#x27;-b&#x27;</span>, <span class="string">&#x27;LineWidth&#x27;</span>, <span class="number">2</span>);</span><br><span class="line"><span class="built_in">hold</span> on;</span><br><span class="line"><span class="built_in">plot</span>(x, f(x), <span class="string">&#x27;ro&#x27;</span>, <span class="string">&#x27;MarkerSize&#x27;</span>, <span class="number">10</span>, <span class="string">&#x27;LineWidth&#x27;</span>, <span class="number">2</span>);</span><br><span class="line">xlabel(<span class="string">&#x27;x&#x27;</span>);</span><br><span class="line">ylabel(<span class="string">&#x27;f(x)&#x27;</span>);</span><br><span class="line">title(<span class="string">&#x27;梯度下降法&#x27;</span>);</span><br><span class="line">grid on;</span><br></pre></td></tr></table></figure><h1 id="遍历法"><a href="#遍历法" class="headerlink" title="遍历法"></a>遍历法</h1><p>遍历法（Exhaustive Search 或 Brute Force Search）是一种通过枚举所有可能的解，找到最优解的优化方法。对于某些简单的或可枚举的优化问题，遍历法可以确保找到全局最优解。</p><p>遍历法的思想很简单，就是首先在定义搜索区间内，以生成一系列自变量点，然后带入函数 ，输出因变量向量 ，画出图像观察，最后采用 min/max 函数，计算出最小值/最大值。通过估计来寻找大致位置。</p><p>遍历法是采用 for 循环来实现的，对于多元函数需要多个 for 循环来实现，所以遍历法一般最多用来求解二元函数的优化问题。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">% 最小化函数 f(x) = x^2 + 4x + 4</span></span><br><span class="line">f = @(x) x.^<span class="number">2</span> + <span class="number">4</span>*x + <span class="number">4</span>;</span><br><span class="line"></span><br><span class="line">x_vals = <span class="number">-10</span>:<span class="number">0.01</span>:<span class="number">10</span>; <span class="comment">% 在区间[-10, 10]上以0.01为步长进行遍历</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% 初始化最优解</span></span><br><span class="line">min_f = <span class="built_in">inf</span>; <span class="comment">% 最小函数值，初始设为无穷大</span></span><br><span class="line">optimal_x = <span class="built_in">nan</span>; <span class="comment">% 最优解</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> x = x_vals</span><br><span class="line">    current_f = f(x); <span class="comment">% 计算当前x值对应的函数值</span></span><br><span class="line">    <span class="keyword">if</span> current_f &lt; min_f <span class="comment">% 如果找到更小的函数值，则更新最优解</span></span><br><span class="line">        min_f = current_f;</span><br><span class="line">        optimal_x = x;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">fprintf(<span class="string">&#x27;最优解: x = %.6f\n&#x27;</span>, optimal_x);</span><br><span class="line">fprintf(<span class="string">&#x27;最优函数值: f(x) = %.6f\n&#x27;</span>, min_f);</span><br><span class="line"></span><br><span class="line">y_vals = f(x_vals);</span><br><span class="line"><span class="built_in">plot</span>(x_vals, y_vals, <span class="string">&#x27;-b&#x27;</span>, <span class="string">&#x27;LineWidth&#x27;</span>, <span class="number">2</span>);</span><br><span class="line"><span class="built_in">hold</span> on;</span><br><span class="line"><span class="built_in">plot</span>(optimal_x, min_f, <span class="string">&#x27;ro&#x27;</span>, <span class="string">&#x27;MarkerSize&#x27;</span>, <span class="number">10</span>, <span class="string">&#x27;LineWidth&#x27;</span>, <span class="number">2</span>);</span><br><span class="line">xlabel(<span class="string">&#x27;x&#x27;</span>);</span><br><span class="line">ylabel(<span class="string">&#x27;f(x)&#x27;</span>);</span><br><span class="line">title(<span class="string">&#x27;遍历法&#x27;</span>);</span><br><span class="line">grid on;</span><br></pre></td></tr></table></figure><h1 id="随机优化算法"><a href="#随机优化算法" class="headerlink" title="随机优化算法"></a>随机优化算法</h1><p><strong>Step 1</strong>: 在给定的区间内随机生成一个自变量 <code>x</code>。</p><p><strong>Step 2</strong>: 进行约束条件的判断。</p><p><strong>Step 3</strong>: 计算目标函数值并存储。每次计算后，将当前最小值保存到 <code>min_f_history</code> 向量中。</p><p><strong>Step 4</strong>: 比较当前函数值与之前的最小值，如果当前值更小，则更新最优解 <code>best_x</code>，并重置计数器 <code>counter</code>；否则，计数器增加。</p><p><strong>Step 5</strong>: 如果计数器达到阈值，则停止循环并输出结果。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">f = @(x) x.^<span class="number">2</span> + <span class="number">4</span>*x + <span class="number">4</span>;</span><br><span class="line"></span><br><span class="line">range = [<span class="number">-10</span>, <span class="number">10</span>]; <span class="comment">% 自变量的取值范围</span></span><br><span class="line">max_iter = <span class="number">1000</span>; <span class="comment">% 最大迭代次数</span></span><br><span class="line">threshold = <span class="number">20</span>; <span class="comment">% 阈值</span></span><br><span class="line">counter = <span class="number">0</span>; <span class="comment">% 计数器</span></span><br><span class="line">min_f_history = []; <span class="comment">% 存放每次循环中的最小值</span></span><br><span class="line">best_x = NaN; <span class="comment">% 记录最优自变量</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> iter = <span class="number">1</span>:max_iter</span><br><span class="line">    <span class="comment">% 随机生成自变量 x</span></span><br><span class="line">    x = range(<span class="number">1</span>) + (range(<span class="number">2</span>) - range(<span class="number">1</span>)) * <span class="built_in">rand</span>();</span><br><span class="line">    <span class="comment">% 如果有约束条件，判断是否满足</span></span><br><span class="line">    <span class="comment">% 计算函数值并存储在向量中</span></span><br><span class="line">    f_val = f(x);</span><br><span class="line">    <span class="comment">% 将当前函数值与历史最小值比较，更新最小值向量</span></span><br><span class="line">    <span class="keyword">if</span> iter == <span class="number">1</span></span><br><span class="line">        min_f_history = [min_f_history, f_val];</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        min_f_history = [min_f_history, <span class="built_in">min</span>(f_val, min_f_history(<span class="keyword">end</span>))];</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">% 记录当前最优解</span></span><br><span class="line">    <span class="keyword">if</span> iter == <span class="number">1</span> || f_val &lt; min_f_history(<span class="keyword">end</span><span class="number">-1</span>)</span><br><span class="line">        best_x = x;</span><br><span class="line">        counter = <span class="number">0</span>; <span class="comment">% 计数器重置</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        counter = counter + <span class="number">1</span>; </span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> counter &gt;= threshold</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">fprintf(<span class="string">&#x27;总循环次数: %d\n&#x27;</span>, iter);</span><br><span class="line">fprintf(<span class="string">&#x27;最优自变量: x = %.6f\n&#x27;</span>, best_x);</span><br><span class="line">fprintf(<span class="string">&#x27;最小函数值: f(x) = %.6f\n&#x27;</span>, min_f_history(<span class="keyword">end</span>));</span><br><span class="line"></span><br><span class="line"><span class="built_in">figure</span>;</span><br><span class="line"><span class="built_in">plot</span>(min_f_history, <span class="string">&#x27;-o&#x27;</span>, <span class="string">&#x27;LineWidth&#x27;</span>, <span class="number">2</span>);</span><br><span class="line">xlabel(<span class="string">&#x27;迭代次数&#x27;</span>);</span><br><span class="line">ylabel(<span class="string">&#x27;最小值&#x27;</span>);</span><br><span class="line">title(<span class="string">&#x27;阶梯图&#x27;</span>);</span><br><span class="line">grid on;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 数值分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>常微分方程的数值求解(Matlab实现)</title>
      <link href="/2024/08/22/%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B%E7%9A%84%E8%A7%A3%E6%B3%95/"/>
      <url>/2024/08/22/%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B%E7%9A%84%E8%A7%A3%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h1 id="微分方程求解"><a href="#微分方程求解" class="headerlink" title="微分方程求解"></a>微分方程求解</h1><p>常微分方程求解一般分为解析解和数值解，但是对于大多数的现实问题来看，解析解往往是不可取的，所以我们只能通过数值解来进行求解。</p><script type="math/tex; mode=display">\frac{dx}{dt} = f(x(t),t) \\x(t_0) = x_0</script><h2 id="欧拉法"><a href="#欧拉法" class="headerlink" title="欧拉法"></a>欧拉法</h2><p>从初始条件出发，沿着解的切线方向前进一小步，从而得到解的近似值，这种方法是最易求解的，但是精度过低，所以一般仅作为后续知识的铺垫或是简单情况下的使用。</p><script type="math/tex; mode=display">\frac{x(t+\Delta t)-x(t)}{\Delta t} \approx f(x(t),t) \quad When\quad\Delta t \rightarrow 0</script><script type="math/tex; mode=display">x(t+\Delta t) \approx x(t)+\Delta t\cdot f(x(t),t)</script><p>所以，下一时刻的值可以这么表示出来</p><script type="math/tex; mode=display">x(t_{k+1})=x(t_k)+\Delta t \cdot f(x(t_k),t_k)</script><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">result</span> = <span class="title">func</span><span class="params">(x,t)</span> %模拟目标函数</span></span><br><span class="line">result = <span class="built_in">cos</span>(t);</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">h = <span class="number">0.001</span>; <span class="comment">% 时间步长</span></span><br><span class="line">t = <span class="number">0</span>:h:<span class="number">10</span>; <span class="comment">% 时间序列</span></span><br><span class="line">n = <span class="built_in">length</span>(t);</span><br><span class="line">x = <span class="built_in">zeros</span>(<span class="number">1</span>, n); <span class="comment">% 预留空间</span></span><br><span class="line">x(<span class="number">1</span>) = <span class="number">0</span>; <span class="comment">% 初始条件</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:n<span class="number">-1</span></span><br><span class="line">    x(<span class="built_in">i</span>+<span class="number">1</span>) = x(<span class="built_in">i</span>) + h * func(x(<span class="built_in">i</span>), t(<span class="built_in">i</span>)); <span class="comment">% 使用时间 t(i)</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">plot</span>(t, x) <span class="comment">% 绘制数值积分结果</span></span><br><span class="line"><span class="built_in">hold</span> on</span><br><span class="line"><span class="built_in">plot</span>(t, <span class="built_in">sin</span>(t), <span class="string">&#x27;--&#x27;</span>) <span class="comment">% 绘制真实解 sin(t) 进行对比</span></span><br><span class="line"><span class="built_in">legend</span>(<span class="string">&#x27;Euler Approximation&#x27;</span>, <span class="string">&#x27;True Solution&#x27;</span>)</span><br><span class="line">title(<span class="string">&#x27;Comparison of Numerical Integration and True Solution&#x27;</span>)</span><br><span class="line">xlabel(<span class="string">&#x27;Time t&#x27;</span>)</span><br><span class="line">ylabel(<span class="string">&#x27;x(t)&#x27;</span>)</span><br></pre></td></tr></table></figure><h2 id="梯形法"><a href="#梯形法" class="headerlink" title="梯形法"></a>梯形法</h2><p>梯形法是欧拉法的改进，也可以认为是Runge-Kutta方法的简单版，具体内容如下：</p><script type="math/tex; mode=display">x_{k+1} = x_k + \frac{h}{2}[f(x_k,t_k)+f(x_{k+1},t_{k+1})]</script><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">h = <span class="number">0.001</span>; <span class="comment">% 时间步长</span></span><br><span class="line">t = <span class="number">0</span>:h:<span class="number">10</span>; <span class="comment">% 时间序列</span></span><br><span class="line">n = <span class="built_in">length</span>(t);</span><br><span class="line">x_trapezoidal = <span class="built_in">zeros</span>(<span class="number">1</span>, n); <span class="comment">% 预留空间</span></span><br><span class="line">x_trapezoidal(<span class="number">1</span>) = <span class="number">0</span>; <span class="comment">% 初始条件</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% 梯形法</span></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:n<span class="number">-1</span></span><br><span class="line">    x_trapezoidal(<span class="built_in">i</span>+<span class="number">1</span>) = x_trapezoidal(<span class="built_in">i</span>) + (h / <span class="number">2</span>) * (func(x(<span class="built_in">i</span>),t(<span class="built_in">i</span>))+func(x(<span class="built_in">i</span>+<span class="number">1</span>),t(<span class="built_in">i</span>+<span class="number">1</span>)));</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">plot</span>(t, x_trapezoidal, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;DisplayName&#x27;</span>, <span class="string">&#x27;Trapezoidal Method&#x27;</span>)</span><br><span class="line"><span class="built_in">hold</span> on</span><br><span class="line"><span class="built_in">plot</span>(t, <span class="built_in">sin</span>(t), <span class="string">&#x27;r--&#x27;</span>, <span class="string">&#x27;DisplayName&#x27;</span>, <span class="string">&#x27;True Solution (sin(t))&#x27;</span>)</span><br><span class="line"><span class="built_in">legend</span> show</span><br><span class="line">title(<span class="string">&#x27;Comparison of Trapezoidal Method and True Solution&#x27;</span>)</span><br><span class="line">xlabel(<span class="string">&#x27;Time t&#x27;</span>)</span><br><span class="line">ylabel(<span class="string">&#x27;x(t)&#x27;</span>)</span><br><span class="line">grid on</span><br></pre></td></tr></table></figure><h2 id="龙格-库塔算法-Runge-Kutta"><a href="#龙格-库塔算法-Runge-Kutta" class="headerlink" title="龙格-库塔算法(Runge-Kutta)"></a>龙格-库塔算法(Runge-Kutta)</h2><p>龙格库塔算法广泛用于工程上，其具有高精度的特点，缺点就是计算量较大，原理比较复杂。</p><p>数学原理为从中间找几个点进行插值，故精度更高, 以下为RK4的实现方法:</p><script type="math/tex; mode=display">x_{k+1} = x_k + \frac{h}{6}(k_1+2k_2+2k_3+k_4)</script><script type="math/tex; mode=display">\text{其中} \quad k_1 = f(x_k,t_k) \\k_2 = f(x_k+h\frac{k_1}{2},t_k+\frac{h}{2}) \\k_3 = f(x_k+h\frac{k_2}{2},t_k+\frac{h}{2}) \\k_4 = f(x_k+hk_3,t_k+h)</script><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">h = <span class="number">0.001</span>; <span class="comment">% 时间步长</span></span><br><span class="line">t = <span class="number">0</span>:h:<span class="number">10</span>; <span class="comment">% 时间序列</span></span><br><span class="line">n = <span class="built_in">length</span>(t);</span><br><span class="line">x = <span class="built_in">zeros</span>(<span class="number">1</span>, n); <span class="comment">% 预留空间</span></span><br><span class="line">x(<span class="number">1</span>) = <span class="number">0</span>; <span class="comment">% 初始条件</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% 四阶Runge-Kutta法</span></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:n<span class="number">-1</span></span><br><span class="line">    k1 = func(x(<span class="built_in">i</span>), t(<span class="built_in">i</span>));</span><br><span class="line">    k2 = func(x(<span class="built_in">i</span>) + <span class="number">0.5</span>*h*k1, t(<span class="built_in">i</span>) + <span class="number">0.5</span>*h);</span><br><span class="line">    k3 = func(x(<span class="built_in">i</span>) + <span class="number">0.5</span>*h*k2, t(<span class="built_in">i</span>) + <span class="number">0.5</span>*h);</span><br><span class="line">    k4 = func(x(<span class="built_in">i</span>) + h*k3, t(<span class="built_in">i</span>) + h);</span><br><span class="line">    x(<span class="built_in">i</span>+<span class="number">1</span>) = x(<span class="built_in">i</span>) + (h / <span class="number">6</span>) * (k1 + <span class="number">2</span>*k2 + <span class="number">2</span>*k3 + k4); <span class="comment">% 修正权重系数</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% 绘图对比</span></span><br><span class="line"><span class="built_in">figure</span>(<span class="number">1</span>)</span><br><span class="line"><span class="built_in">plot</span>(t, x, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;DisplayName&#x27;</span>, <span class="string">&#x27;Runge-Kutta Method&#x27;</span>)</span><br><span class="line"><span class="built_in">hold</span> on</span><br><span class="line"><span class="built_in">plot</span>(t, <span class="built_in">sin</span>(t), <span class="string">&#x27;r--&#x27;</span>, <span class="string">&#x27;DisplayName&#x27;</span>, <span class="string">&#x27;True Solution (sin(t))&#x27;</span>)</span><br><span class="line"><span class="built_in">legend</span> show</span><br><span class="line">title(<span class="string">&#x27;Comparison of Runge-Kutta Method and True Solution&#x27;</span>)</span><br><span class="line">xlabel(<span class="string">&#x27;Time t&#x27;</span>)</span><br><span class="line">ylabel(<span class="string">&#x27;x(t)&#x27;</span>)</span><br><span class="line">grid on</span><br><span class="line"></span><br><span class="line"><span class="comment">% 绘制误差</span></span><br><span class="line"><span class="built_in">figure</span>(<span class="number">2</span>)</span><br><span class="line"><span class="built_in">plot</span>(t, <span class="built_in">sin</span>(t) - x, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;DisplayName&#x27;</span>, <span class="string">&#x27;Error&#x27;</span>)</span><br><span class="line">xlabel(<span class="string">&#x27;Time t&#x27;</span>)</span><br><span class="line">ylabel(<span class="string">&#x27;Error&#x27;</span>)</span><br><span class="line">title(<span class="string">&#x27;Total Error&#x27;</span>)</span><br><span class="line">grid on</span><br></pre></td></tr></table></figure><p>那对于二阶非齐次方程应该怎么求解呢?这就需要做变换了</p><script type="math/tex; mode=display">\frac{d^2x}{dt^2} + p(t) \frac{dx}{dt} + q(t) x = g(t)</script><p>对于这种形式的微分方程,我们需要做以下变换:</p><script type="math/tex; mode=display">\frac{dx_1}{dt} = x_2(t) \\\frac{dx_2}{dt} = -p(t) x_2(t) - q(t) x_1(t) + g(t)</script><p>那么有:</p><script type="math/tex; mode=display">k_1^x = v_i \\k_1^v = -p(t_i) v_i - q(t_i) x_i + g(t_i) \\k_2^x = v_i + 0.5h k_1^v \\k_2^v = -p(t_i + 0.5h) \left(v_i + 0.5h k_1^v\right) - q(t_i + 0.5h) \left(x_i + 0.5h k_1^x\right) + g(t_i + 0.5h) \\k_3^x = v_i + 0.5h k_2^v \\k_3^v= -p(t_i + 0.5h) \left(v_i + 0.5h k_2^v\right) - q(t_i + 0.5h) \left(x_i + 0.5h k_2^x\right) + g(t_i + 0.5h) \\k_4^x = v_i + h k_3^v \\k_4^v = -p(t_i + h) \left(v_i + h k_3^v\right) - q(t_i + h) \left(x_i + h k_3^x\right) + g(t_i + h)</script><p>假设我们要解:</p><script type="math/tex; mode=display">\frac{d^2x}{dt^2} + 2\frac{dx}{dt} + 5x = \cos(t)</script><script type="math/tex; mode=display">x(0) = 0 \quad and \quad \frac{dx}{dt}(0) = 1</script><p>有:</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">h = <span class="number">0.01</span>; <span class="comment">% 时间步长</span></span><br><span class="line">t = <span class="number">0</span>:h:<span class="number">10</span>; <span class="comment">% 时间序列</span></span><br><span class="line">n = <span class="built_in">length</span>(t);</span><br><span class="line"></span><br><span class="line">x = <span class="built_in">zeros</span>(<span class="number">1</span>, n); <span class="comment">% x(t)</span></span><br><span class="line">v = <span class="built_in">zeros</span>(<span class="number">1</span>, n); <span class="comment">% v(t) = dx/dt</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% 初始条件</span></span><br><span class="line">x(<span class="number">1</span>) = <span class="number">0</span>; <span class="comment">% x(0) = 0</span></span><br><span class="line">v(<span class="number">1</span>) = <span class="number">1</span>; <span class="comment">% v(0) = dx/dt = 1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% 定义方程中的函数</span></span><br><span class="line">p = @(t) <span class="number">2</span>; <span class="comment">% p(t)</span></span><br><span class="line">q = @(t) <span class="number">5</span>; <span class="comment">% q(t)</span></span><br><span class="line">g = @(t) <span class="built_in">cos</span>(t); <span class="comment">% g(t)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% 四阶Runge-Kutta法求解</span></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:n<span class="number">-1</span></span><br><span class="line">    <span class="comment">% k1</span></span><br><span class="line">    k1x = v(<span class="built_in">i</span>);</span><br><span class="line">    k1v = -p(t(<span class="built_in">i</span>)) * v(<span class="built_in">i</span>) - q(t(<span class="built_in">i</span>)) * x(<span class="built_in">i</span>) + g(t(<span class="built_in">i</span>));</span><br><span class="line">    </span><br><span class="line">    <span class="comment">% k2</span></span><br><span class="line">    k2x = v(<span class="built_in">i</span>) + <span class="number">0.5</span>*h*k1v;</span><br><span class="line">    k2v = -p(t(<span class="built_in">i</span>) + <span class="number">0.5</span>*h) * (v(<span class="built_in">i</span>) + <span class="number">0.5</span>*h*k1v) - q(t(<span class="built_in">i</span>) + <span class="number">0.5</span>*h) * (x(<span class="built_in">i</span>) + <span class="number">0.5</span>*h*k1x) + g(t(<span class="built_in">i</span>) + <span class="number">0.5</span>*h);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">% k3</span></span><br><span class="line">    k3x = v(<span class="built_in">i</span>) + <span class="number">0.5</span>*h*k2v;</span><br><span class="line">    k3v = -p(t(<span class="built_in">i</span>) + <span class="number">0.5</span>*h) * (v(<span class="built_in">i</span>) + <span class="number">0.5</span>*h*k2v) - q(t(<span class="built_in">i</span>) + <span class="number">0.5</span>*h) * (x(<span class="built_in">i</span>) + <span class="number">0.5</span>*h*k2x) + g(t(<span class="built_in">i</span>) + <span class="number">0.5</span>*h);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">% k4</span></span><br><span class="line">    k4x = v(<span class="built_in">i</span>) + h*k3v;</span><br><span class="line">    k4v = -p(t(<span class="built_in">i</span>) + h) * (v(<span class="built_in">i</span>) + h*k3v) - q(t(<span class="built_in">i</span>) + h) * (x(<span class="built_in">i</span>) + h*k3x) + g(t(<span class="built_in">i</span>) + h);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">% 更新x和v</span></span><br><span class="line">    x(<span class="built_in">i</span>+<span class="number">1</span>) = x(<span class="built_in">i</span>) + (h/<span class="number">6</span>) * (k1x + <span class="number">2</span>*k2x + <span class="number">2</span>*k3x + k4x);</span><br><span class="line">    v(<span class="built_in">i</span>+<span class="number">1</span>) = v(<span class="built_in">i</span>) + (h/<span class="number">6</span>) * (k1v + <span class="number">2</span>*k2v + <span class="number">2</span>*k3v + k4v);</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% 绘图</span></span><br><span class="line"><span class="built_in">figure</span>(<span class="number">1</span>)</span><br><span class="line"><span class="built_in">plot</span>(t, x, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;DisplayName&#x27;</span>, <span class="string">&#x27;x(t) - RK4&#x27;</span>)</span><br><span class="line">title(<span class="string">&#x27;Solution of Second Order ODE using RK4&#x27;</span>)</span><br><span class="line">xlabel(<span class="string">&#x27;Time t&#x27;</span>)</span><br><span class="line">ylabel(<span class="string">&#x27;x(t)&#x27;</span>)</span><br><span class="line"><span class="built_in">legend</span> show</span><br><span class="line">grid on</span><br><span class="line"></span><br><span class="line"><span class="built_in">figure</span>(<span class="number">2</span>)</span><br><span class="line"><span class="built_in">plot</span>(t, v, <span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;DisplayName&#x27;</span>, <span class="string">&#x27;v(t) = dx/dt - RK4&#x27;</span>)</span><br><span class="line">title(<span class="string">&#x27;Velocity v(t) using RK4&#x27;</span>)</span><br><span class="line">xlabel(<span class="string">&#x27;Time t&#x27;</span>)</span><br><span class="line">ylabel(<span class="string">&#x27;v(t)&#x27;</span>)</span><br><span class="line"><span class="built_in">legend</span> show</span><br><span class="line">grid on</span><br></pre></td></tr></table></figure><p>实际上, 有这些基本的算法就已经可以实现高精度的数值积分模拟了, 比如可以用在数学建模或是你的科研项目中, 当然我们也可以用Matlab自带的函数(ODE45)去求解: </p><script type="math/tex; mode=display">\frac{dy_1}{dt} = y_2 \\\frac{dy_2}{dt} = -3y_2 - 2y_1 + \cos(t)</script><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">% 微分方程组</span></span><br><span class="line">odes = @(t, y) [y(<span class="number">2</span>); <span class="number">-3</span>*y(<span class="number">2</span>) - <span class="number">2</span>*y(<span class="number">1</span>) + <span class="built_in">cos</span>(t)];</span><br><span class="line"></span><br><span class="line"><span class="comment">% 初始条件</span></span><br><span class="line">y0 = [<span class="number">0</span>; <span class="number">1</span>];</span><br><span class="line"></span><br><span class="line"><span class="comment">% 时间区间</span></span><br><span class="line">tspan = [<span class="number">0</span> <span class="number">10</span>];</span><br><span class="line"></span><br><span class="line">[t, y] = ode45(odes, tspan, y0);</span><br><span class="line"><span class="built_in">plot</span>(t, y(:,<span class="number">1</span>))</span><br><span class="line">title(<span class="string">&#x27;Solution of Second Order ODE using ode45&#x27;</span>)</span><br><span class="line">xlabel(<span class="string">&#x27;Time t&#x27;</span>)</span><br><span class="line">ylabel(<span class="string">&#x27;y(t)&#x27;</span>)</span><br><span class="line">grid on</span><br></pre></td></tr></table></figure><h3 id="一阶微分方程的平衡点及稳定性"><a href="#一阶微分方程的平衡点及稳定性" class="headerlink" title="一阶微分方程的平衡点及稳定性"></a>一阶微分方程的平衡点及稳定性</h3><p>设有微分方程</p><script type="math/tex; mode=display">\dot{x}(t)=f(x) \tag{(1)}</script><p>方程右端不显含自变量 $t$,称为<strong>自治方程</strong>.代数方程</p><script type="math/tex; mode=display">f(x)=0 \tag{(2)}</script><p>的实根 $x=x_0$ 称为方程 (1) 的<strong>平衡点</strong> (或奇点). 它也是方程 (1) 的解 (奇解).<br>如果存在某个邻域,使方程 (1) 的解 $x(t)$ 从这个邻域内的某个 $x(0)$ 出发, 满足</p><script type="math/tex; mode=display">\lim _{t \rightarrow \infty} x(t)=x_0 \tag{(3)}</script><p>则称平衡点 $x_0$ 是<strong>稳定</strong>的 (稳定性理论中称渐近稳定) ; 否则, 称 $x_0$ 是<strong>不稳定</strong>的 (不渐近稳定).<br>判断平衡点 $x_0$ 是否稳定通常有两种方法. 利用定义即 (3) 式称<strong>间接法</strong>. 不求方程 (1) 的解 $x(t)$, 因而不利用 (3) 式的方法称<strong>直接法</strong>.下面介绍直接法.<br>将 $f(x)$ 在 $x_0$ 点作 Taylor 展开, 只取一次项, 方程 (1) 近似为</p><script type="math/tex; mode=display">\dot{x}(t)=f^{\prime}\left(x_0\right)\left(x-x_0\right) \tag{(4)}</script><p>(4) 称为 (1) 的近似线性方程, $x_0$ 也是方程 (4) 的平衡点. 关于 $x_0$ 点稳定性有如下的结论:<br>若 $f^{\prime}\left(x_0\right)<0$, 则 $x_0$ 对于方程 (4) 和 (1) 都是称稳定的;若 $f^{\prime}\left(x_0\right)>0$, 则 $x_0$ 对于方程 $(4)$ 和 (1) 都是不稳定的.<br>$x_0$ 对于方程 (4) 的稳定性很容易由定义 (3) 证明, 因为若记 $f^{\prime}\left(x_0\right)=a$, 则 (4) 的一般解是</p><script type="math/tex; mode=display">x(t)=c \mathrm{e}^{a t}+x_0 \tag{(5)}</script><p>其中 $c$ 是由初始条件决定的常数, 显然, 当 $a&lt;0$ 时 (3) 式成立.<br>### 7.2 二阶微分方程的平衡点和稳定性<br>二阶微分方程可用两个一阶微分方程表为</p><script type="math/tex; mode=display">\left\{\begin{array}{l}\dot{x}_1(t)=f\left(x_1, x_2\right) \\\dot{x}_2(t)=g\left(x_1, x_2\right)\end{array}\right. \tag{(6)}</script><p>右端不显含 $t$, 是自治方程.代数方程组</p><script type="math/tex; mode=display">\left\{\begin{array}{l}f\left(x_1, x_2\right)=0 \\g\left(x_1, x_2\right)=0\end{array}\right. \tag{(7)}</script><p>的实根 $x_1=x_1^0, x_2=x_2^0$ 称为方程 (6) 的平衡点, 记作 $P_0\left(x_1^0, x_2^0\right)$.<br>如果存在某个邻域, 使方程 (6) 的解 $x_1(t), x_2(t)$ 从这个邻域内的某个 $\left(x_1(0), x_2(0)\right)$ 出发, 满足</p><script type="math/tex; mode=display">\lim _{t \rightarrow \infty} x_1(t)=x_1^0, \quad \lim _{t \rightarrow \infty} x_2(t)=x_2^0 \tag{(8)}</script><p>则称平衡点 $P_0$ 是<strong>稳定</strong>的(渐近稳定); 否则, 称 $P_0$ 是<strong>不稳定</strong>的(不渐近稳定).<br>为了用直接法讨论方程 (6) 的平衡点的稳定性, 先看线性常系数方程</p><script type="math/tex; mode=display">\left\{\begin{array}{l}\dot{x}_1(t)=a_1 x_1+a_2 x_2 \\\dot{x}_2(t)=b_1 x_1+b_2 x_2\end{array}\right. \tag{(9)}</script><p>系数矩伡记作</p><script type="math/tex; mode=display">\boldsymbol{A}=\left[\begin{array}{ll}a_1 & a_2 \\b_1 & b_2\end{array}\right] \tag{(10)}</script><p>为研究方程 $(9)$ 的惟一平衡点 $P_0(0,0)$ 的稳定性, 假定 $A$ 的行列式</p><script type="math/tex; mode=display">\operatorname{det} A \neq 0 \tag{(11)}</script><p>$P_0(0,0)$ 的稳定性由 $(9)$ 的特征方程</p><script type="math/tex; mode=display">\operatorname{det}(A-\lambda I)=0 \tag{(12)}</script><p>的根 $\lambda$ (特征根) 决定.方程 (12) 可以写成脜加明晣的形式</p><script type="math/tex; mode=display">\left\{\begin{array}{l}\lambda^2+p \lambda+q=0 \\p=-\left(a_1+b_2\right) \\q=\operatorname{det} A\end{array}\right. \tag{(13)}</script><p>将特征根记作 $\lambda_1, \lambda_2$, 则</p><script type="math/tex; mode=display">\lambda_1, \lambda_2=\frac{1}{2}\left(-p \pm \sqrt{p^2-4 q}\right) \tag{(14)}</script><p>方程 (9) 的一般解具有形式 $c_1 \mathrm{e}^{\lambda_1^{\prime}}+c_2 \mathrm{e}^{\lambda 2^{\prime}}\left(\lambda_1 \neq \lambda_2\right)$ 或 $c_1 \mathrm{e}^{\lambda_1^{\prime}}+c_2 t \mathrm{e}^{\lambda_1^{\prime}}\left(\lambda_1=\lambda_2\right), c_1, c_2$ 为任意常数.按照稳定性的定义 (8) 式可知, 当 $\lambda_1, \lambda_2$ 为负数或存负实部时， $P_0(0,0)$ 是稳定平衡点; 而当 $\lambda_1, \lambda_2$ 有一个为正数或有正实部时, $P_0(0,0)$ 是不稳定平衡点.在条件(11)下 $\lambda_1, \lambda_2$ 不可能为 0 .<br>微分方程稳定性理论将平衡点分为结点、焦点、鞍点、中心等类型, 完全由特征根 $\lambda_1, \lambda_2$ 或相应的 $p, q$ 取值决定.表 1 简明地给出了这些结果, 表中最后一列 指按照定义 (8)式得到的关于稳定性的结论.\</p><p>表1 由特征方程决定的平衡点的类型和稳定性</p><script type="math/tex; mode=display">\begin{array}{|c|c|c|c|}\hline\lambda_1, \lambda_2 & p, q & 平衡点类型 & 稳定性\\\hline\lambda_1 < \lambda_2 <0 & p>0, q>0, p^2>4q & 稳定结点 & 稳定\\\hline\lambda_1 > \lambda_2 > 0 & p<0, q>0, p^2>4q & 不稳定结点 & 不稳定\\\hline\lambda_1 < 0 < \lambda_2 & q<0 & 鞍点 & 不稳定\\\hline\lambda_1 = \lambda_2 <0 & p>0, q>0, p^2=4q & 稳定退化结点 & 稳定\\\hline\lambda_1 = \lambda_2 > 0 & p<0, q>0, p^2=4q & 不稳定退化结点 & 不稳定\\\hline\lambda_{1,2}=\alpha \pm \beta i, \alpha<0 & p>0, q>0, p^2<4q & 稳定焦点 & 稳定\\\hline\lambda_{1,2}=\alpha \pm \beta i, \alpha>0 & p<0, q>0, p^2<4q & 不稳定焦点 & 不稳定\\\hline\lambda_{1,2}=\alpha \pm \beta i, \alpha=0 & p=0, q>0 & 中心 & 不稳定\\\hline\end{array}</script><p>由表 1 可以看出, 根据特征方程的系数 $p, q$ 的正负很容易判断平衡点的稳定性, 准则如下:若</p><script type="math/tex; mode=display">p>0, q>0 \tag{(15)}</script><p>则平衡点稳定；若</p><script type="math/tex; mode=display">p<0 \text { 或 } q<0 \tag{(16)}</script><p>则平衡点不稳定.<br>以上是对线性方程 $(9)$ 的平衡点 $P_0(0,0)$ 稳定性的结论. 对于一般的非线性方程 (6), 可以用近似线性方法判断其平衡点 $P_0\left(x_1^0, x_2^0\right)$ 的稳定性. 在 $P_0$ 点将 $f\left(x_1, x_2\right)$ 和 $g\left(x_1, x_2\right)$ 作 Taylor 展开, 只取一次项,得 (6) 的近似线性方程</p><script type="math/tex; mode=display">\left\{\begin{array}{l}\dot{x}_1(t)=f_{x_1}\left(x_1^0, x_2^0\right)\left(x_1-x_1^0\right)+f_{x_2}\left(x_1^0, x_2^0\right)\left(x_2-x_2^0\right) \\\dot{x}_2(t)=g_{x_1}\left(x_1^0, x_2^0\right)\left(x_1-x_1^0\right)+g_{x_2}\left(x_1^0, x_2^0\right)\left(x_2-x_2^0\right)\end{array}\right. \tag{(17)}</script><p>系数矩阵记作</p><script type="math/tex; mode=display">\boldsymbol{A}=\left.\left[\begin{array}{ll}f_{x_1} & f_{x_2} \\g_{x_1} & g_{x_2}\end{array}\right]\right|_{P_0\left(x_1^0 \cdot x_2^0\right)} \tag{(18)}</script><p>特征方程系数为</p><script type="math/tex; mode=display">p=-\left.\left(f_{x_1}+g_{x_2}\right)\right|_{p_0}, \quad q=\operatorname{det} \boldsymbol{A} \tag{(19)}</script><p>显然, $P_0$ 点对于方程 (17) 的稳定性由表 1 或准则 (15),（16) 决定, 而且已经证明了如下结论:<br>若方程 (17) 的特征根不为 0 或实部不为 0 , 则 $P_0$​ 点对于方程 (6) 的稳定性与对于近似方程 (17) 的稳定性相同, 即由准则 (15), (16) 决定.<br>最后，提出以下几点值得注意：</p><ol><li>平衡点及其稳定性的概念只是对<strong>自治方程</strong> $(1)$ ，(6)而言才有意义.</li><li>非线性方程 $(1),(6)$ 的平衡点的稳定性, 与相应的近似线性方程 (4), (17) 的平衡点的稳定性一致, 是在非临界情况下(即 $a \neq 0$, 或 $p, q \neq 0$ ) 得到的, 在临界情况下(即 $a=0$ 或 $p, q=0$ )二者可以不一致.</li><li>在讨论平衡点稳定性时, 对初始点的要求是存在一个邻域, 这是<strong>局部稳定</strong>的定义.如果要求对任意的初始点,(3), (8)式成立, 称为<strong>全局稳定</strong>.对于线性方程, 局部稳定与全局稳定是等价的; 对于非线性方程, 二者不同.</li><li>对于临界情况和非线性方程的全局稳定,可以用相轨线分析方法讨论.</li></ol><h2 id="常用的微分方程模型"><a href="#常用的微分方程模型" class="headerlink" title="常用的微分方程模型"></a>常用的微分方程模型</h2><p>有很多常用的微分方程, 这里举例两个, 一个是 SIR , 一个是Logistic模型.</p><h3 id="SIR模型"><a href="#SIR模型" class="headerlink" title="SIR模型"></a>SIR模型</h3><p>SIR模型是流行病学中的一种数学模型，用于描述传染病在群体中的传播。SIR模型将人口分为三类：</p><ol><li><strong>S（易感者，Susceptible）</strong>：尚未感染疾病但有可能被感染的人。</li><li><strong>I（感染者，Infectious）</strong>：已经被感染并且可以传播疾病的人。</li><li><strong>R（移除者，Removed）</strong>：已经康复或死亡并且不再具有传染性的人。</li></ol><h4 id="数学模型"><a href="#数学模型" class="headerlink" title="数学模型"></a>数学模型</h4><p>SIR模型用以下三个微分方程描述群体中这三类人口的变化：</p><ol><li><strong>易感者的变化率</strong>： dS/dt=−βSI</li><li><strong>感染者的变化率</strong>： dI/dt=βSI−γI</li><li><strong>移除者的变化率</strong>： dR/dt=γI</li></ol><p>其中：</p><ul><li>β 是传染率系数，表示每个感染者每天使多少易感者感染。</li><li>γ 是恢复率系数，表示感染者每天康复的比例。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> scipy.integrate <span class="keyword">import</span> odeint</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义SIR模型的微分方程</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sir_model</span>(<span class="params">y, t, beta, gamma</span>):</span><br><span class="line">    S, I, R = y</span><br><span class="line">    dS_dt = -beta * S * I</span><br><span class="line">    dI_dt = beta * S * I - gamma * I</span><br><span class="line">    dR_dt = gamma * I</span><br><span class="line">    <span class="keyword">return</span> [dS_dt, dI_dt, dR_dt]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始条件</span></span><br><span class="line">S0 = <span class="number">0.99</span>  <span class="comment"># 初始易感者比例</span></span><br><span class="line">I0 = <span class="number">0.01</span>  <span class="comment"># 初始感染者比例</span></span><br><span class="line">R0 = <span class="number">0.0</span>   <span class="comment"># 初始移除者比例</span></span><br><span class="line">initial_conditions = [S0, I0, R0]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 参数</span></span><br><span class="line">beta = <span class="number">0.3</span>   <span class="comment"># 传染率系数</span></span><br><span class="line">gamma = <span class="number">0.1</span>  <span class="comment"># 恢复率系数</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 时间点（天数）</span></span><br><span class="line">t = np.linspace(<span class="number">0</span>, <span class="number">160</span>, <span class="number">160</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 求解微分方程</span></span><br><span class="line">solution = odeint(sir_model, initial_conditions, t, args=(beta, gamma))</span><br><span class="line">S, I, R = solution.T</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制结果</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">plt.plot(t, S, label=<span class="string">&#x27;Susceptible&#x27;</span>, color=<span class="string">&#x27;blue&#x27;</span>)</span><br><span class="line">plt.plot(t, I, label=<span class="string">&#x27;Infectious&#x27;</span>, color=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">plt.plot(t, R, label=<span class="string">&#x27;Removed&#x27;</span>, color=<span class="string">&#x27;green&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Time (days)&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Proportion of population&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;SIR Model&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.grid(<span class="literal">True</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h3 id="Logistic人口增长模型"><a href="#Logistic人口增长模型" class="headerlink" title="Logistic人口增长模型"></a>Logistic人口增长模型</h3><p>Logistic人口增长模型是描述人口增长的一种模型，它考虑了资源有限对人口增长的限制。该模型是对简单的指数增长模型的扩展，能够更真实地反映实际情况下人口增长的动态。</p><script type="math/tex; mode=display">\frac{dP}{dt} = rP \left(1 - \frac{P}{K}\right)</script><p>求解出来后,得到:</p><script type="math/tex; mode=display">P(t) = \frac{K}{1 + \left(\frac{K - P_0}{P_0}\right)e^{-rt}}</script><p>其中：P(t) 是时间 t 时的人口数量, r 是人口增长率（单位时间内的增长率）, K 是环境的承载能力或最大人口容量，即系统能够支持的最大人口数。</p><h3 id="模型的解释"><a href="#模型的解释" class="headerlink" title="模型的解释"></a>模型的解释</h3><ul><li><strong>指数增长阶段</strong>：当人口 P 很小，相对于 K 来说，可以近似地看作 P 和 K 的差值很大，因此人口增长可以近似为指数增长。</li><li><strong>减缓阶段</strong>：当人口接近 K 时，增长率逐渐减小，因为 1−PK 逐渐接近零。这表示资源有限的情况下，人口增长的速度减慢。</li><li><strong>稳定阶段</strong>：当 P 达到 K 时，人口增长率趋近于零，系统达到稳定状态，即达到环境承载能力的最大值。</li></ul><p>假设一个地区的人口增长率 r=0.1，环境承载能力 K=1000，初始人口 P0=10。可以通过上面的公式计算任意时刻 t 的人口数量。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">% 参数</span></span><br><span class="line">r = <span class="number">0.1</span>;</span><br><span class="line">K = <span class="number">1000</span>;</span><br><span class="line">P0 = <span class="number">10</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">% 时间</span></span><br><span class="line">t = <span class="built_in">linspace</span>(<span class="number">0</span>, <span class="number">100</span>, <span class="number">500</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">% Logistic增长模型</span></span><br><span class="line">P = K ./ (<span class="number">1</span> + ((K - P0) / P0) .* <span class="built_in">exp</span>(-r * t));</span><br><span class="line"></span><br><span class="line"><span class="comment">% 绘制结果</span></span><br><span class="line"><span class="built_in">plot</span>(t, P)</span><br><span class="line">title(<span class="string">&#x27;Logistic Population Growth&#x27;</span>)</span><br><span class="line">xlabel(<span class="string">&#x27;Time&#x27;</span>)</span><br><span class="line">ylabel(<span class="string">&#x27;Population&#x27;</span>)</span><br><span class="line">grid on</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 数值分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>用Matlab求解优化规划问题(Updating...)</title>
      <link href="/2024/08/21/%E7%94%A8Matlab%E6%B1%82%E8%A7%A3%E4%BC%98%E5%8C%96%E8%A7%84%E5%88%92%E9%97%AE%E9%A2%98/"/>
      <url>/2024/08/21/%E7%94%A8Matlab%E6%B1%82%E8%A7%A3%E4%BC%98%E5%8C%96%E8%A7%84%E5%88%92%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h1 id="优化问题"><a href="#优化问题" class="headerlink" title="优化问题"></a>优化问题</h1><p>在现代工程与科学研究中，优化问题的求解扮演着至关重要的角色。从资源分配到产品设计，从控制系统到数据分析，几乎每一个领域都涉及到如何在复杂的约束条件下，找到一个或多个最优解的挑战。为了应对这些挑战，不同类型的优化方法被广泛应用，其中最为常见的包括线性规划、非线性规划、整数规划和多目标规划。</p><p>实际上，经常阅读工程方面的文献就可以发现，许多问题最后都可以用这些方法来建立成一个单目标或多目标的优化模型去解决实际问题。</p><h2 id="线性规划"><a href="#线性规划" class="headerlink" title="线性规划"></a>线性规划</h2><p>对于线性规划而言，可以用以下的公式来表达。</p><script type="math/tex; mode=display">\text{Minimize} \quad & \mathbf{c}^\top \mathbf{x} \\\text{subject to} \quad &\begin{cases}\mathbf{A} \mathbf{x} \leq \mathbf{b}\\Aeq\cdot x = beq \\lb ≤x≤ub\end{cases}</script><p>其中，对于目标函数，可以通过在前面加一个符号，将一个最大值转换成最小值问题，$c$是目标函数的系数向量。n×1，其中 n 是决策变量 x 的数量。A是不等式约束的系数矩阵，b是不等式约束的常数向量，而Aeq和beq就是等式约束的系数矩阵和常数向量，对于决策变量x,有lb与ub的上下限。</p><p>对于此类问题，可以用Matlab的linprog函数去求解。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[x,fval] = linprog(f,A,b,Aeq,beq,lb,ub)</span><br></pre></td></tr></table></figure><p>其中，x返回决策变量的取值，fval返回目标函数的最优解，f为优化函数的系数。</p><p><strong>实例</strong>：假设优化一个产品生产和资源分配计划，其中 $x_{ij}$代表在第 (i) 类产品的第 (j) 种资源的分配量。目标是最大化资源的总价值（基于系数矩阵 C）。约束条件包括每类产品的最大资源限制、资源的总需求量，以及每种资源分配量不能为负。</p><script type="math/tex; mode=display">\text{maximize } z = \sum_{i=1}^2 \sum_{j=1}^3 c_{ij} x_{ij}</script><script type="math/tex; mode=display">\sum_{j=1}^3 x_{1j} \leq 10 \\\sum_{j=1}^3 x_{2j} \leq 15 \\\sum_{i=1}^2 \sum_{j=1}^3 x_{ij} = 20 \\x_{ij} \geq 0 \text{ for all } i \text{ and } j</script><script type="math/tex; mode=display">C = \begin{bmatrix}4 & 3 & 2 \\5 & 6 & 1\end{bmatrix}</script><p>在 MATLAB 的 <code>linprog</code> 函数中，所有的变量需要被展平（flattened）成一个一维列向量进行处理。尽管在问题的实际背景中，变量是一个二维矩阵（比如 2×32），但为了简化计算，<code>linprog</code> 只接受一维的向量形式。因此，二维变量矩阵 $x_{ij}$被展平成一个一维列向量。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">c = [<span class="number">-4</span>,<span class="number">-3</span>,<span class="number">-2</span>,<span class="number">-5</span>,<span class="number">-6</span>,<span class="number">-1</span>];  <span class="comment">% 目标函数系数</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% 约束矩阵</span></span><br><span class="line">A = [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>;</span><br><span class="line">     <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>];</span><br><span class="line"><span class="comment">% 约束向量</span></span><br><span class="line">b = [<span class="number">10</span>; <span class="number">15</span>];</span><br><span class="line">Aeq = <span class="built_in">ones</span>(<span class="number">1</span>, <span class="number">6</span>);  <span class="comment">% 线性等式约束矩阵</span></span><br><span class="line">beq = <span class="number">20</span>;  <span class="comment">% 线性等式约束向量</span></span><br><span class="line">lb = <span class="built_in">zeros</span>(<span class="number">6</span>, <span class="number">1</span>);  <span class="comment">% 变量的下界</span></span><br><span class="line"></span><br><span class="line">options = optimoptions(<span class="string">&#x27;linprog&#x27;</span>,<span class="string">&#x27;Display&#x27;</span>,<span class="string">&#x27;none&#x27;</span>); </span><br><span class="line">[x, fval] = linprog(c, A, b, Aeq, beq, lb, [], options);</span><br><span class="line"></span><br><span class="line">fprintf(<span class="string">&#x27;最大化的目标值 z = %.2f\n&#x27;</span>, -fval);  <span class="comment">% 目标函数值，记得取负值恢复到最大化</span></span><br></pre></td></tr></table></figure><h2 id="非线性规划"><a href="#非线性规划" class="headerlink" title="非线性规划"></a>非线性规划</h2><p>在原有的线性规划的基础上稍作修改，就可以得到以下式子：</p><script type="math/tex; mode=display">\text{Minimize} \quad f(x) \\\text{subject to} \quad &\begin{cases}\mathbf{A} \mathbf{x} \leq \mathbf{b},Aeq\cdot x = beq \\c(x)≤0，Ceq(x)=0 \\lb ≤x≤ub\end{cases}</script><p>其中，c(x)表示非线性不等式约束，Ceq为非线性等式约束。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[x,value]=fmincon(func,x0,A,b,Aeq,beq,lb,ub,nonlcon，options)</span><br></pre></td></tr></table></figure><script type="math/tex; mode=display">\begin{aligned}&min\quad f(x)={x_1}^2+{x_2}^2+{x_3}^2-6\\&s.t.\begin{cases}x_1^2-x_2+0*x_3=0\\-x_1+x_2^2-x_3^3+2\leq0\\x_1+x_2^2-2x_3-5\leq0\\x_1,x_2,x_3\geq0\end{cases}\end{aligned}</script><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">f</span>=<span class="title">func</span><span class="params">(x)</span></span></span><br><span class="line">func=sum(x.^<span class="number">2</span>)<span class="number">-6</span>;</span><br></pre></td></tr></table></figure><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[C,Ceq]</span>=<span class="title">nonlcon</span><span class="params">(x)</span></span></span><br><span class="line">C=[-x(<span class="number">1</span>)+x(<span class="number">2</span>)^<span class="number">2</span>-x(<span class="number">3</span>)^<span class="number">2</span>+<span class="number">2</span>;</span><br><span class="line">x(<span class="number">1</span>)+x(<span class="number">2</span>)^<span class="number">2</span><span class="number">-2</span>*x(<span class="number">3</span>)<span class="number">-5</span>]</span><br><span class="line">Ceq=[x(<span class="number">1</span>)^<span class="number">2</span>-x(<span class="number">2</span>)]</span><br></pre></td></tr></table></figure><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[x,value]=fmincon(<span class="string">&#x27;func&#x27;</span>,[<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>],[],[],[],[],[<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>],[],<span class="string">&#x27;nonlcon&#x27;</span>);</span><br></pre></td></tr></table></figure><h2 id="遗传算法工具箱"><a href="#遗传算法工具箱" class="headerlink" title="遗传算法工具箱"></a>遗传算法工具箱</h2><p>事实上，非线性规划求出来的往往是局部最优解，所以我们可以利用一些智能优化算法工具箱去解决，这里以2023年数学建模国赛A题其中一篇优秀论文的模型为例：</p><script type="math/tex; mode=display">\eta_{ijk} = \frac{A(ST_i, D_j) \cdot B(ST_i, D_j)}{\sqrt{(x_k - x_0)^2 + (y_k - y_0)^2 + H^2}}</script><p>其中：</p><ul><li>A(STi,Dj) 是由时间和日期确定的太阳高度角参数。</li><li>B(STi,Dj)是由时间和日期确定的太阳方位角参数。</li><li>(xk,yk)是第 kkk 个定日镜的水平坐标。</li><li>(x0,y0)是聚光点的水平坐标（例如 x0=0,y0=−250）。</li><li>H 是所有定日镜的固定高度。</li></ul><p>以下是公式的latex代码，由于网页无法编译，故提供源代码</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\max_&#123;r,l,w,h,N,I_&#123;a&#125;&#125;\quad\overline&#123;E&#125;_&#123;u&#125;\left(r,l,w,h,N,I_&#123;a&#125;\right)=\frac&#123;\sum_&#123;&#123;i\operatorname&#123;=&#125;1&#125;&#125;^&#123;12&#125;\sum_&#123;&#123;j\operatorname&#123;=&#125;1&#125;&#125;^&#123;5&#125;\sum_&#123;&#123;k\operatorname&#123;=&#125;1&#125;&#125;^&#123;N&#125;DNI_&#123;ij&#125;\cdot\eta_&#123;ijk&#125;&#125;&#123;60N&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">s.t.\begin&#123;cases&#125;r\in[-R,R]\\l,w\in[2m,8m]\\l\leqslant w\\h\in[2m,6m]\\h&gt;\frac&#123;1&#125;&#123;2&#125;l\\N\in[1000,5000]\\\sqrt&#123;&#123;x_&#123;a&#125;&#125;^&#123;2&#125;+&#123;y_&#123;a&#125;&#125;^&#123;2&#125;&#125;\leqslant R\\\sqrt&#123;&#123;x_&#123;a&#125;&#125;^&#123;2&#125;+&#123;(y_&#123;a&#125;-r)&#125;^&#123;2&#125;&#125;\geqslant100\\\sqrt&#123;\left(x_&#123;a&#125;-x_&#123;b&#125;\right)^&#123;2&#125;+\left(y_&#123;a&#125;-y_&#123;b&#125;\right)^&#123;2&#125;&#125;&gt;w+5\\\overline&#123;E&#125;_&#123;fictd&#125;=\frac&#123;\sum_&#123;i=1&#125;^&#123;12&#125;\sum_&#123;j=1&#125;^&#123;5&#125;\sum_&#123;k=1&#125;^&#123;N&#125;DNI_&#123;ij&#125;\cdot A_&#123;k&#125;\cdot\eta_&#123;ijk&#125;&#125;&#123;60&#125;\geqslant60MW&amp;&amp;\end&#123;cases&#125;</span><br></pre></td></tr></table></figure><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><span class="line">clear;</span><br><span class="line">clc;</span><br><span class="line"></span><br><span class="line"><span class="comment">% 问题参数</span></span><br><span class="line">N = <span class="number">2739</span>;      <span class="comment">% 定日镜数量</span></span><br><span class="line">H = <span class="number">4</span>;         <span class="comment">% 定日镜高度</span></span><br><span class="line">R = <span class="number">350</span>;       <span class="comment">% 最大半径</span></span><br><span class="line">l_min = <span class="number">2</span>; l_max = <span class="number">8</span>;  <span class="comment">% l 的范围</span></span><br><span class="line">w_min = <span class="number">2</span>; w_max = <span class="number">8</span>;  <span class="comment">% w 的范围</span></span><br><span class="line">h_min = <span class="number">2</span>; h_max = <span class="number">6</span>;  <span class="comment">% h 的范围</span></span><br><span class="line">x0 = <span class="number">0</span>; y0 = <span class="number">-250</span>;     <span class="comment">% 聚光点的坐标</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% 遗传算法参数</span></span><br><span class="line">ns = N * <span class="number">2</span> + <span class="number">3</span>;        <span class="comment">% 要优化的变量数 (2N 个坐标 + 3 个尺寸变量 l, w, h)</span></span><br><span class="line">lb = [-R * <span class="built_in">ones</span>(<span class="number">1</span>, N*<span class="number">2</span>), l_min, w_min, h_min];  <span class="comment">% 下界</span></span><br><span class="line">ub = [R * <span class="built_in">ones</span>(<span class="number">1</span>, N*<span class="number">2</span>), l_max, w_max, h_max];   <span class="comment">% 上界</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% 遗传算法求解</span></span><br><span class="line">[x, fval] = ga(@objective_function, ns, [], [], [], [], lb, ub, @nonlin_constraints);</span><br><span class="line"></span><br><span class="line"><span class="comment">% 优化后的定日镜坐标</span></span><br><span class="line">x_a = x(<span class="number">1</span>:N);</span><br><span class="line">y_a = x(N+<span class="number">1</span>:<span class="number">2</span>*N);</span><br><span class="line"></span><br><span class="line"><span class="comment">% 优化后的尺寸变量</span></span><br><span class="line">l_opt = x(<span class="keyword">end</span><span class="number">-2</span>);</span><br><span class="line">w_opt = x(<span class="keyword">end</span><span class="number">-1</span>);</span><br><span class="line">h_opt = x(<span class="keyword">end</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">% 显示优化结果</span></span><br><span class="line"><span class="built_in">disp</span>([<span class="string">&#x27;优化后的目标函数值: &#x27;</span>, num2str(fval)]);</span><br><span class="line"><span class="built_in">disp</span>(<span class="string">&#x27;优化后的定日镜坐标:&#x27;</span>);</span><br><span class="line"><span class="built_in">disp</span>([x_a&#x27;, y_a&#x27;]);</span><br><span class="line"><span class="built_in">disp</span>([<span class="string">&#x27;优化后的 l, w, h: &#x27;</span>, num2str(l_opt), <span class="string">&#x27;, &#x27;</span>, num2str(w_opt), <span class="string">&#x27;, &#x27;</span>, num2str(h_opt)]);</span><br><span class="line"></span><br><span class="line"><span class="comment">% 目标函数定义</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">f</span> = <span class="title">objective_function</span><span class="params">(x)</span></span></span><br><span class="line">    N = <span class="number">2739</span>; x0 = <span class="number">0</span>; y0 = <span class="number">-250</span>;</span><br><span class="line">    ST = [<span class="number">9</span>, <span class="number">10.5</span>, <span class="number">12</span>, <span class="number">13.5</span>, <span class="number">15</span>];</span><br><span class="line">    D = [<span class="number">306</span>, <span class="number">337</span>, <span class="number">0</span>, <span class="number">31</span>, <span class="number">61</span>, <span class="number">92</span>, <span class="number">122</span>, <span class="number">153</span>, <span class="number">184</span>, <span class="number">214</span>, <span class="number">245</span>, <span class="number">275</span>];</span><br><span class="line">    </span><br><span class="line">    <span class="comment">% 定日镜坐标</span></span><br><span class="line">    xyz = [x(<span class="number">1</span>:N)&#x27;, x(N+<span class="number">1</span>:<span class="number">2</span>*N)&#x27;, <span class="built_in">repmat</span>(x(<span class="keyword">end</span>), N, <span class="number">1</span>)];  <span class="comment">% 使用优化变量 h</span></span><br><span class="line">    e2 = <span class="built_in">zeros</span>(<span class="number">12</span>, <span class="number">5</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:<span class="number">5</span></span><br><span class="line">        <span class="keyword">for</span> <span class="built_in">j</span> = <span class="number">1</span>:<span class="number">12</span></span><br><span class="line">            [A, B] = SUN(ST(<span class="built_in">i</span>), D(<span class="built_in">j</span>));  <span class="comment">% 计算太阳位置参数</span></span><br><span class="line">            e2(<span class="built_in">j</span>, <span class="built_in">i</span>) = calculate_efficiency(xyz, N, x0, y0, A, B);</span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    </span><br><span class="line">    Se2 = <span class="built_in">mean</span>(e2, <span class="string">&#x27;all&#x27;</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">% 判断是否满足最低发电要求</span></span><br><span class="line">    <span class="keyword">if</span> Se2 &lt; <span class="number">60</span></span><br><span class="line">        f = <span class="number">1e6</span>; <span class="comment">% 违反约束时，设置一个较大的目标函数值</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        f = -Se2; <span class="comment">% 遗传算法最小化 -Se2</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% 非线性约束函数</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[c, ceq]</span> = <span class="title">nonlin_constraints</span><span class="params">(x)</span></span></span><br><span class="line">    N = <span class="number">2739</span>; H = <span class="number">4</span>; R = <span class="number">350</span>; x0 = <span class="number">0</span>; y0 = <span class="number">-250</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">% 提取优化变量</span></span><br><span class="line">    x_a = x(<span class="number">1</span>:N);</span><br><span class="line">    y_a = x(N+<span class="number">1</span>:<span class="number">2</span>*N);</span><br><span class="line">    l = x(<span class="keyword">end</span><span class="number">-2</span>);</span><br><span class="line">    w = x(<span class="keyword">end</span><span class="number">-1</span>);</span><br><span class="line">    h = x(<span class="keyword">end</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">% 非线性不等式约束</span></span><br><span class="line">    c = [</span><br><span class="line">        <span class="comment">% 尺寸约束</span></span><br><span class="line">        l - w;                            <span class="comment">% l &lt;= w</span></span><br><span class="line">        h - <span class="number">0.5</span> * l;                      <span class="comment">% h &gt; 0.5 * l</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">% 几何约束</span></span><br><span class="line">        <span class="built_in">sqrt</span>(x_a.^<span class="number">2</span> + y_a.^<span class="number">2</span>) - R;        <span class="comment">% sqrt(x_a^2 + y_a^2) &lt;= R</span></span><br><span class="line">        -<span class="built_in">sqrt</span>(x_a.^<span class="number">2</span> + (y_a - r).^<span class="number">2</span>) + <span class="number">100</span>;  <span class="comment">% sqrt(x_a^2 + (y_a - r)^2) &gt;= 100</span></span><br><span class="line">        -<span class="built_in">sqrt</span>((x_a - x0).^<span class="number">2</span> + (y_a - y0).^<span class="number">2</span>) + w + <span class="number">5</span> <span class="comment">% sqrt((x_a-x0)^2 + (y_a-y0)^2) &gt; w + 5</span></span><br><span class="line">    ];</span><br><span class="line">    </span><br><span class="line">    <span class="comment">% 非线性等式约束</span></span><br><span class="line">    ceq = [];</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 优化问题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>支持向量机</title>
      <link href="/2024/08/18/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/"/>
      <url>/2024/08/18/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/</url>
      
        <content type="html"><![CDATA[<h1 id="支持向量机"><a href="#支持向量机" class="headerlink" title="支持向量机"></a>支持向量机</h1><p>支持向量机（Support Vector Machine, SVM）是一种用于分类和回归的监督学习模型，尤其适用于线性和非线性分类问题。SVM的核心思想是通过寻找一个最佳的超平面来将数据分开，并且最大化类间的边界间隔，在SVM中，我们把数据点看做是n维空间中的点，每个点有n个特征。</p><p>支持向量机与其他许多机器学习算法的原理有些不同，支持向量机更偏向于最优化理论，所以原理比较复杂。</p><p>首先，要了解<strong>决策边界</strong>，我们通过找到一个超平面来将不同类型的数据分开，其可以是一条直线，一个平面，或是核函数下的超平面。</p><p>其次，了解什么是<strong>支持向量(Support Vector)</strong>，支持向量是指距离决策边界最近的样本点。</p><p><strong>间隔</strong>是指能够在两个类别中留出一个尽可能大的间隔，这样可以提高模型的泛化能力。</p><p>SVM的目标是找到一个超平面将数据分为两类。超平面的表达式为：</p><script type="math/tex; mode=display">\mathbf{w}^T \cdot \mathbf{x} + b = 0</script><p>对每个样本$\mathbf{x}_i$，它到超平面的距离为：</p><script type="math/tex; mode=display">d = \frac{| \mathbf{w}^T \cdot \mathbf{x}_i + b |}{\|\mathbf{w}\|}</script><p>为了最大化间隔  $\frac{2}{||w||}$  ，可以等价为以下优化的问题：</p><script type="math/tex; mode=display">\min_{\mathbf{w}, b} \frac{1}{2} \|\mathbf{w}\|^2</script><script type="math/tex; mode=display">\text{subject to } y_i (\mathbf{w} \cdot \mathbf{x}_i + b) \geq 1, \quad \forall i</script><p>当数据集不可线性分割时，可以引入松弛变量 $ξ_i≥0$ 来允许某些点违背间隔条件。优化问题变为：</p><script type="math/tex; mode=display">\min_{\mathbf{w}, b, \xi} \frac{1}{2} \|\mathbf{w}\|^2 + C \sum_{i=1}^n \xi_i</script><script type="math/tex; mode=display">\text{subject to } y_i (\mathbf{w} \cdot \mathbf{x}_i + b) \geq 1 - \xi_i, \quad \xi_i \geq 0, \quad \forall i</script><p>为了解决带有约束的优化问题，引入拉格朗日乘子 $α_i≥0$和 $μ_i≥0$，构造拉格朗日函数：</p><script type="math/tex; mode=display">L(\mathbf{w}, b, \xi, \alpha, \mu) = \frac{1}{2} \|\mathbf{w}\|^2 + C \sum_{i=1}^n \xi_i - \sum_{i=1}^n \alpha_i \left[ y_i (\mathbf{w} \cdot \mathbf{x}_i + b) - 1 + \xi_i \right] - \sum_{i=1}^n \mu_i \xi_i</script><p>Karush-Kuhn-Tucker (KKT) 条件是优化问题的必要条件:</p><script type="math/tex; mode=display">\frac{\partial L}{\partial \mathbf{w}} = \mathbf{w} - \sum_{i=1}^n \alpha_i y_i \mathbf{x}_i = 0</script><script type="math/tex; mode=display">\frac{\partial L}{\partial b} = -\sum_{i=1}^n \alpha_i y_i = 0</script><script type="math/tex; mode=display">\frac{\partial L}{\partial \xi_i} = C - \alpha_i - \mu_i = 0</script><p>将拉格朗日函数中的 $w,b,ξ$​ 消去后，可以得到对偶问题：</p><script type="math/tex; mode=display">\\max_{\alpha} \sum_{i=1}^n \alpha_i - \frac{1}{2} \sum_{i=1}^n \sum_{j=1}^n \alpha_i \alpha_j y_i y_j \mathbf{x}_i \cdot \mathbf{x}_j</script><script type="math/tex; mode=display">\text{subject to } \sum_{i=1}^n \alpha_i y_i = 0, \quad 0 \leq \alpha_i \leq C</script><p>这个对偶问题是一个凸二次规划问题，可以通过现有的优化算法如SMO（Sequential Minimal Optimization）来求解。</p><p><strong>SVC的使用</strong><code>kernel</code>：指定核函数的类型。常见的有 <code>&#39;linear&#39;</code>（线性核），<code>&#39;poly&#39;</code>（多项式核），<code>&#39;rbf&#39;</code>（径向基核，也叫高斯核），以及 <code>&#39;sigmoid&#39;</code>。</p><p><code>C</code>：正则化参数，控制模型的复杂度与误分类样本之间的权衡。较小的 <code>C</code> 值会使模型更加平滑，较大的 <code>C</code> 值则会更倾向于正确分类每个训练样本。</p><p><code>gamma</code>：核函数的参数，控制决策边界的灵活性。这个参数只在非线性核函数（如 <code>&#39;rbf&#39;</code>）中使用。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> (accuracy_score, precision_score, recall_score, </span><br><span class="line">                             f1_score, confusion_matrix, roc_auc_score, roc_curve)</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">X = iris.data[:, :<span class="number">2</span>]  <span class="comment"># 选择前两个特征：sepal length 和 sepal width</span></span><br><span class="line">y = iris.target</span><br><span class="line"></span><br><span class="line"><span class="comment"># 只选择两个类别的数据进行二分类</span></span><br><span class="line">binary_indices = y != <span class="number">2</span></span><br><span class="line">X = X[binary_indices]</span><br><span class="line">y = y[binary_indices]</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.3</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">scaler = StandardScaler()</span><br><span class="line">X_train = scaler.fit_transform(X_train)</span><br><span class="line">X_test = scaler.transform(X_test)</span><br><span class="line"></span><br><span class="line">svm_model = SVC(kernel=<span class="string">&#x27;linear&#x27;</span>, C=<span class="number">1.0</span>, random_state=<span class="number">42</span>)</span><br><span class="line">svm_model.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">y_pred = svm_model.predict(X_test)</span><br><span class="line"></span><br><span class="line">accuracy = accuracy_score(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Accuracy: <span class="subst">&#123;accuracy:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_decision_boundary</span>(<span class="params">model, X, y</span>):</span><br><span class="line">    <span class="comment"># 创建一个网格来绘制</span></span><br><span class="line">    h = <span class="number">.02</span>  <span class="comment"># 网格步长</span></span><br><span class="line">    x_min, x_max = X[:, <span class="number">0</span>].<span class="built_in">min</span>() - <span class="number">1</span>, X[:, <span class="number">0</span>].<span class="built_in">max</span>() + <span class="number">1</span></span><br><span class="line">    y_min, y_max = X[:, <span class="number">1</span>].<span class="built_in">min</span>() - <span class="number">1</span>, X[:, <span class="number">1</span>].<span class="built_in">max</span>() + <span class="number">1</span></span><br><span class="line">    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))</span><br><span class="line">    </span><br><span class="line">    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])</span><br><span class="line">    Z = Z.reshape(xx.shape)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 绘制决策边界</span></span><br><span class="line">    plt.contourf(xx, yy, Z, cmap=plt.cm.Paired, alpha=<span class="number">0.8</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 绘制训练数据点</span></span><br><span class="line">    plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=y, cmap=plt.cm.Paired, edgecolors=<span class="string">&#x27;k&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 绘制支持向量</span></span><br><span class="line">    plt.scatter(model.support_vectors_[:, <span class="number">0</span>], model.support_vectors_[:, <span class="number">1</span>], s=<span class="number">100</span>, </span><br><span class="line">                facecolors=<span class="string">&#x27;none&#x27;</span>, edgecolors=<span class="string">&#x27;k&#x27;</span>, label=<span class="string">&#x27;Support Vectors&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    plt.title(<span class="string">&#x27;SVM Decision Boundary with Support Vectors&#x27;</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;Sepal Length&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;Sepal Width&#x27;</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用函数绘制决策边界和超平面</span></span><br><span class="line">plot_decision_boundary(svm_model, X_train, y_train)</span><br><span class="line">y_pred = svm_model.predict(X_test)</span><br><span class="line"></span><br><span class="line">accuracy = accuracy_score(y_test, y_pred)</span><br><span class="line">precision = precision_score(y_test, y_pred)</span><br><span class="line">recall = recall_score(y_test, y_pred)</span><br><span class="line">f1 = f1_score(y_test, y_pred)</span><br><span class="line">conf_matrix = confusion_matrix(y_test, y_pred)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Accuracy: <span class="subst">&#123;accuracy:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Precision: <span class="subst">&#123;precision:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Recall: <span class="subst">&#123;recall:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;F1-Score: <span class="subst">&#123;f1:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Confusion Matrix:\n<span class="subst">&#123;conf_matrix&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Accuracy: <span class="number">1.0000</span></span><br><span class="line">Precision: <span class="number">1.0000</span></span><br><span class="line">Recall: <span class="number">1.0000</span></span><br><span class="line">F1-Score: <span class="number">1.0000</span></span><br><span class="line">Confusion Matrix:</span><br><span class="line">[[<span class="number">17</span>  <span class="number">0</span>]</span><br><span class="line"> [ <span class="number">0</span> <span class="number">13</span>]]</span><br></pre></td></tr></table></figure><p>SVM相对于普通的线性回归分类性能更好：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使 matplotlib 在 Jupyter Notebook 中内联显示图像</span></span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置 matplotlib 的图形参数</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.labelsize&#x27;</span>] = <span class="number">14</span>  <span class="comment"># 坐标轴标签字体大小</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;xtick.labelsize&#x27;</span>] = <span class="number">12</span>  <span class="comment"># x 轴刻度标签字体大小</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;ytick.labelsize&#x27;</span>] = <span class="number">12</span>  <span class="comment"># y 轴刻度标签字体大小</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 忽略所有警告</span></span><br><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载 Iris 数据集</span></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 选择特征: 仅选择花瓣长度和花瓣宽度特征</span></span><br><span class="line">X = iris[<span class="string">&#x27;data&#x27;</span>][:, (<span class="number">2</span>, <span class="number">3</span>)]  <span class="comment"># 花瓣长度和花瓣宽度</span></span><br><span class="line">y = iris[<span class="string">&#x27;target&#x27;</span>]  <span class="comment"># 目标变量（类别）</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 选择两个类别的数据: Setosa (0) 和 Versicolor (1)</span></span><br><span class="line">setosa_or_versicolor = (y == <span class="number">0</span>) | (y == <span class="number">1</span>)</span><br><span class="line">X = X[setosa_or_versicolor]  <span class="comment"># 仅选择 Setosa 和 Versicolor 的特征</span></span><br><span class="line">y = y[setosa_or_versicolor]  <span class="comment"># 仅选择 Setosa 和 Versicolor 的目标变量</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化支持向量机分类器，使用线性核函数，设置 C 参数为 5</span></span><br><span class="line">svm_clf = SVC(kernel=<span class="string">&#x27;linear&#x27;</span>, C=<span class="number">5</span>)</span><br><span class="line">svm_clf.fit(X, y)  <span class="comment"># 拟合模型</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义不同的决策边界线的函数（仅用于绘图）</span></span><br><span class="line">x0 = np.linspace(<span class="number">0</span>, <span class="number">5.5</span>, <span class="number">200</span>)  <span class="comment"># x 轴坐标，从 0 到 5.5，生成 200 个点</span></span><br><span class="line">pred_1 = <span class="number">5</span> * x0 - <span class="number">20</span>  <span class="comment"># 第一条预测线</span></span><br><span class="line">pred_2 = x0 - <span class="number">1.8</span>  <span class="comment"># 第二条预测线</span></span><br><span class="line">pred_3 = <span class="number">0.1</span> * x0 + <span class="number">0.5</span>  <span class="comment"># 第三条预测线</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_svc_decision_boundary</span>(<span class="params">svm_clf, xmin, xmax, sv=<span class="literal">True</span></span>):</span><br><span class="line">    <span class="comment"># 画出支持向量机模型的决策边界和支持向量</span></span><br><span class="line">    w = svm_clf.coef_[<span class="number">0</span>]  <span class="comment"># 提取模型的权重系数</span></span><br><span class="line">    b = svm_clf.intercept_[<span class="number">0</span>]  <span class="comment"># 提取模型的截距</span></span><br><span class="line">    x0 = np.linspace(xmin, xmax, <span class="number">200</span>)  <span class="comment"># 在指定的 x 范围内生成 200 个点</span></span><br><span class="line">    decision_boundary = -w[<span class="number">0</span>] / w[<span class="number">1</span>] * x0 - b / w[<span class="number">1</span>]  <span class="comment"># 计算决策边界</span></span><br><span class="line">    margin = <span class="number">1</span> / w[<span class="number">1</span>]  <span class="comment"># 计算边际（支持向量机的间隔）</span></span><br><span class="line">    gutter_up = decision_boundary + margin  <span class="comment"># 上边界</span></span><br><span class="line">    gutter_down = decision_boundary - margin  <span class="comment"># 下边界</span></span><br><span class="line">    <span class="keyword">if</span> sv:</span><br><span class="line">        svs = svm_clf.support_vectors_  <span class="comment"># 获取支持向量</span></span><br><span class="line">        plt.scatter(svs[:, <span class="number">0</span>], svs[:, <span class="number">1</span>], s=<span class="number">180</span>, facecolors=<span class="string">&#x27;#FFAAAA&#x27;</span>)  <span class="comment"># 绘制支持向量</span></span><br><span class="line">    plt.plot(x0, decision_boundary, <span class="string">&#x27;k-&#x27;</span>, linewidth=<span class="number">2</span>)  <span class="comment"># 绘制决策边界线</span></span><br><span class="line">    plt.plot(x0, gutter_up, <span class="string">&#x27;k--&#x27;</span>, linewidth=<span class="number">2</span>)  <span class="comment"># 绘制上边际线</span></span><br><span class="line">    plt.plot(x0, gutter_down, <span class="string">&#x27;k--&#x27;</span>, linewidth=<span class="number">2</span>)  <span class="comment"># 绘制下边际线</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建图形窗口</span></span><br><span class="line">plt.figure(figsize=(<span class="number">14</span>, <span class="number">4</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制第一个子图</span></span><br><span class="line">plt.subplot(<span class="number">121</span>)  <span class="comment"># 选择第一个子图</span></span><br><span class="line">plt.plot(X[:, <span class="number">0</span>][y == <span class="number">1</span>], X[:, <span class="number">1</span>][y == <span class="number">1</span>], <span class="string">&#x27;bs&#x27;</span>)  <span class="comment"># 绘制类别为 1 的数据点（蓝色方块）</span></span><br><span class="line">plt.plot(X[:, <span class="number">0</span>][y == <span class="number">0</span>], X[:, <span class="number">1</span>][y == <span class="number">0</span>], <span class="string">&#x27;ys&#x27;</span>)  <span class="comment"># 绘制类别为 0 的数据点（黄色方块）</span></span><br><span class="line">plt.plot(x0, pred_1, <span class="string">&#x27;g--&#x27;</span>, linewidth=<span class="number">2</span>)  <span class="comment"># 绘制第一条预测线（绿色虚线）</span></span><br><span class="line">plt.plot(x0, pred_2, <span class="string">&#x27;m-&#x27;</span>, linewidth=<span class="number">2</span>)  <span class="comment"># 绘制第二条预测线（品红色实线）</span></span><br><span class="line">plt.plot(x0, pred_3, <span class="string">&#x27;r-&#x27;</span>, linewidth=<span class="number">2</span>)  <span class="comment"># 绘制第三条预测线（红色实线）</span></span><br><span class="line">plt.axis([<span class="number">0</span>, <span class="number">5.5</span>, <span class="number">0</span>, <span class="number">2</span>])  <span class="comment"># 设置 x 和 y 轴的范围</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制第二个子图</span></span><br><span class="line">plt.subplot(<span class="number">122</span>)  <span class="comment"># 选择第二个子图</span></span><br><span class="line">plot_svc_decision_boundary(svm_clf, <span class="number">0</span>, <span class="number">5.5</span>)  <span class="comment"># 绘制 SVM 决策边界</span></span><br><span class="line">plt.plot(X[:, <span class="number">0</span>][y == <span class="number">1</span>], X[:, <span class="number">1</span>][y == <span class="number">1</span>], <span class="string">&#x27;bs&#x27;</span>)  <span class="comment"># 绘制类别为 1 的数据点（蓝色方块）</span></span><br><span class="line">plt.plot(X[:, <span class="number">0</span>][y == <span class="number">0</span>], X[:, <span class="number">1</span>][y == <span class="number">0</span>], <span class="string">&#x27;ys&#x27;</span>)  <span class="comment"># 绘制类别为 0 的数据点（黄色方块）</span></span><br><span class="line">plt.axis([<span class="number">0</span>, <span class="number">5.5</span>, <span class="number">0</span>, <span class="number">2</span>])  <span class="comment"># 设置 x 和 y 轴的范围</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示图形</span></span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>支持向量机不仅可以作为二分类模型，还可以作为回归预测模型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVR</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line"><span class="comment"># 加载波士顿房屋数据集</span></span><br><span class="line">data_url = <span class="string">&quot;http://lib.stat.cmu.edu/datasets/boston&quot;</span></span><br><span class="line">raw_df = pd.read_csv(data_url, sep=<span class="string">&quot;\s+&quot;</span>, skiprows=<span class="number">22</span>, header=<span class="literal">None</span>)</span><br><span class="line">data = np.hstack([raw_df.values[::<span class="number">2</span>, :], raw_df.values[<span class="number">1</span>::<span class="number">2</span>, :<span class="number">2</span>]])</span><br><span class="line">target = raw_df.values[<span class="number">1</span>::<span class="number">2</span>, <span class="number">2</span>]</span><br><span class="line">X = data</span><br><span class="line">y = target</span><br><span class="line"></span><br><span class="line">scaler = StandardScaler()</span><br><span class="line">X = scaler.fit_transform(X)</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">svm = SVR(kernel=<span class="string">&#x27;linear&#x27;</span>)</span><br><span class="line">svm.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">y_pred = svm.predict(X_test)</span><br><span class="line"></span><br><span class="line">mse = mean_squared_error(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;均方误差（MSE）：&quot;</span>, mse)</span><br><span class="line"></span><br><span class="line">plt.scatter(<span class="built_in">range</span>(<span class="built_in">len</span>(y_test)), y_test, color=<span class="string">&#x27;b&#x27;</span>, label=<span class="string">&#x27;Actual&#x27;</span>)</span><br><span class="line">plt.plot(<span class="built_in">range</span>(<span class="built_in">len</span>(y_test)), y_pred, color=<span class="string">&#x27;r&#x27;</span>, label=<span class="string">&#x27;Predicted&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Sample&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Price&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;SVM Regression&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>主成分分析PCA</title>
      <link href="/2024/08/18/%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90PCA/"/>
      <url>/2024/08/18/%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90PCA/</url>
      
        <content type="html"><![CDATA[<h1 id="主成分分析"><a href="#主成分分析" class="headerlink" title="主成分分析"></a>主成分分析</h1><p>主成分分析（Principal Component Analysis, PCA）是一种统计技术，用于将高维数据降维到较低的维度，同时保留数据中尽可能多的原始信息。它通过线性变换来找到数据中方差最大的方向，并将数据投影到这些方向上，从而实现降维和特征提取。</p><p>一个最直观的例子，假如有一个二维的数据集，假设散点图所展示的关系大致为:y = 2*X + 3，那么可以发现，当x越大，y也就越大，这就叫共线性，也叫做信息冗余，而对于实际的机器学习问题来说，我们更多想要的是线性可分的特征变量，如果我们对这个x,y轴进行旋转的话，那么就可以得到一种情况，即在新的x，y图像上，这个倾斜的直线变成了一条水平或竖直的直线，这种情况下的新特征x,y就变得线性可分了，也就是我们想要的这种情况。</p><p>由于旋转后以及没有了信息冗余，而我们又想知道新生成的特征所携带的信息量如何，就可以通过方差来观察，旋转后得到的各个变量是独立地代表样本的某部分信息，<br>比如，x的方差为6，y 的方差为4，那么相当于x携带了60%的样本信息，y携带了40%的信息，因此称旋转后得到的各个变量为主成份并根据方差的大小命名为n主成份，通过方差排序。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line">iris   = load_iris()    </span><br><span class="line">X      = iris.data      </span><br><span class="line">x_mean = X.mean(axis=<span class="number">0</span>)  <span class="comment"># 样本中心 </span></span><br><span class="line"></span><br><span class="line">clf = PCA() </span><br><span class="line">clf.fit(X)    </span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;主成份系数矩阵A:\n A=&#x27;</span>,clf.components_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;主成份方差var:&#x27;</span>,clf.explained_variance_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;主成份贡献占比(方差占比)Pr:&#x27;</span>,clf.explained_variance_ratio_)</span><br><span class="line"></span><br><span class="line">y = clf.transform(X)                <span class="comment"># transform方法获取主成份数据  </span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kmeans聚类</title>
      <link href="/2024/08/18/Kmeans%E8%81%9A%E7%B1%BB/"/>
      <url>/2024/08/18/Kmeans%E8%81%9A%E7%B1%BB/</url>
      
        <content type="html"><![CDATA[<h1 id="Kmeans聚类"><a href="#Kmeans聚类" class="headerlink" title="Kmeans聚类"></a>Kmeans聚类</h1><p>Kmeans是一种经典的无监督聚类算法，它试图将数据分成 K 个簇（clusters），使得簇内的数据点尽可能相似，而簇间的数据点尽可能不同。算法的目标是最小化簇内数据点到簇心的距离的平方和。</p><p>首先随机选择 K 个数据点作为初始簇心（centroids），对于数据集中的每个数据点，计算其到 K 个簇心的距离，并将其分配到距离最近的簇心所在的簇，接着重新计算每个簇的簇心，作为当前簇内所有点的均值。重复上述的分配步骤和更新步骤，直到簇心不再变化或变化非常小（即收敛）。</p><script type="math/tex; mode=display">J = \sum_{i=1}^K \sum_{x \in C_i} \| x - \mu_i \|^2</script><p>K 是簇的数量。Ci 是第 i 个簇，x 是簇 Ci 中的一个数据点。μi 是第 i 个簇的簇心（均值）。</p><script type="math/tex; mode=display">\mu_i = \frac{1}{|C_i|} \sum_{x \in C_i} x</script><p>其中 ∣Ci∣ 是簇 Ci 中的数据点数量。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成示例数据</span></span><br><span class="line">X, _ = make_blobs(n_samples=<span class="number">300</span>, centers=<span class="number">4</span>, cluster_std=<span class="number">0.60</span>, random_state=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">kmeans = KMeans(n_clusters=<span class="number">4</span>)</span><br><span class="line">kmeans.fit(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测簇</span></span><br><span class="line">y_kmeans = kmeans.predict(X)</span><br><span class="line"></span><br><span class="line">plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=y_kmeans, s=<span class="number">50</span>, cmap=<span class="string">&#x27;viridis&#x27;</span>)</span><br><span class="line">centers = kmeans.cluster_centers_</span><br><span class="line">plt.scatter(centers[:, <span class="number">0</span>], centers[:, <span class="number">1</span>], c=<span class="string">&#x27;red&#x27;</span>, s=<span class="number">200</span>, alpha=<span class="number">0.75</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Customer Segmentation&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Feature 1&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Feature 2&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h1 id="Kmeans-聚类"><a href="#Kmeans-聚类" class="headerlink" title="Kmeans++聚类"></a>Kmeans++聚类</h1><p>K-Means++ 是 K-Means 算法的一种改进版本，旨在通过改进簇心的初始化过程来提高算法的性能和稳定性。传统的 K-Means 算法对初始簇心的选择非常敏感，可能会导致算法收敛到局部最优解。K-Means++ 通过优化初始化过程来解决这个问题，从而提高最终聚类的质量。</p><p>首先从数据集中随机选择一个数据点作为第一个簇心。对于数据集中每个点，计算其到最近簇心的距离，并根据这些距离计算一个加权概率分布。根据上述加权概率分布随机选择下一个簇心，距离已经选择的簇心较远的数据点被选择的概率更大。重复计算距离和选择簇心的过程，直到选择出所有 K 个簇心。</p><p>这样做可以<strong>减少局部最优解的风险</strong>，通过优化初始簇心的选择，K-Means++ 可以更好地覆盖数据空间，从而减少收敛到局部最优解的风险，同时<strong>提高聚类质量</strong>，通常会获得更好的聚类结果和更低的误差平方和。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs</span><br><span class="line"></span><br><span class="line">X, _ = make_blobs(n_samples=<span class="number">300</span>, centers=<span class="number">4</span>, cluster_std=<span class="number">0.60</span>, random_state=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建K-Means++模型</span></span><br><span class="line">kmeans = KMeans(n_clusters=<span class="number">4</span>, init=<span class="string">&#x27;k-means++&#x27;</span>)</span><br><span class="line">kmeans.fit(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测</span></span><br><span class="line">y_kmeans = kmeans.predict(X)</span><br><span class="line"></span><br><span class="line">plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=y_kmeans, s=<span class="number">50</span>, cmap=<span class="string">&#x27;viridis&#x27;</span>)</span><br><span class="line">centers = kmeans.cluster_centers_</span><br><span class="line">plt.scatter(centers[:, <span class="number">0</span>], centers[:, <span class="number">1</span>], c=<span class="string">&#x27;red&#x27;</span>, s=<span class="number">200</span>, alpha=<span class="number">0.75</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;K-Means++ Clustering&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Feature 1&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Feature 2&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs</span><br><span class="line"></span><br><span class="line"><span class="comment"># 三个featrue</span></span><br><span class="line">X, _ = make_blobs(n_samples=<span class="number">300</span>, centers=<span class="number">4</span>, n_features=<span class="number">3</span>, cluster_std=<span class="number">0.60</span>, random_state=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">kmeans = KMeans(n_clusters=<span class="number">4</span>, init=<span class="string">&#x27;k-means++&#x27;</span>)</span><br><span class="line">kmeans.fit(X)</span><br><span class="line"></span><br><span class="line">y_kmeans = kmeans.predict(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 由于特征数大于2，只能选择两个特征进行可视化</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">7</span>))</span><br><span class="line">plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=y_kmeans, s=<span class="number">50</span>, cmap=<span class="string">&#x27;viridis&#x27;</span>)</span><br><span class="line">centers = kmeans.cluster_centers_</span><br><span class="line">plt.scatter(centers[:, <span class="number">0</span>], centers[:, <span class="number">1</span>], c=<span class="string">&#x27;red&#x27;</span>, s=<span class="number">200</span>, alpha=<span class="number">0.75</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;K-Means Clustering with 3 Features (visualized with 2)&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Feature 1&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Feature 2&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>那如何选择Kmeans的k值呢？一般来说我们可以选择不同的k值来尝试，也可以用两种方法，手肘法（Elbow Method）和轮廓系数法（Silhouette Score）是两种用于评估和选择聚类算法中簇数 K 的方法。</p><h3 id="手肘法（Elbow-Method）"><a href="#手肘法（Elbow-Method）" class="headerlink" title="手肘法（Elbow Method）"></a>手肘法（Elbow Method）</h3><p>手肘法用于确定 K-Means 聚类中簇的数量 K。它的核心思想是绘制每个可能的 K 值对应的总平方误差（Within-Cluster Sum of Squares, WCSS），并观察图形中的“肘部”位置，以确定最佳的 K 值。</p><script type="math/tex; mode=display">\text{WCSS} = \sum_{i=1}^K \sum_{x \in C_i} \| x - \mu_i \|^2</script><p>其中 K 是簇的数量，Ci是第 i 个簇，x 是簇 Ci 中的一个数据点，μi 是第 i 个簇的簇心。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成示例数据</span></span><br><span class="line">X, _ = make_blobs(n_samples=<span class="number">300</span>, centers=<span class="number">4</span>, cluster_std=<span class="number">0.60</span>, random_state=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算WCSS</span></span><br><span class="line">wcss = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">11</span>):</span><br><span class="line">    kmeans = KMeans(n_clusters=i, init=<span class="string">&#x27;k-means++&#x27;</span>)</span><br><span class="line">    kmeans.fit(X)</span><br><span class="line">    wcss.append(kmeans.inertia_)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制手肘图</span></span><br><span class="line">plt.plot(<span class="built_in">range</span>(<span class="number">1</span>, <span class="number">11</span>), wcss, marker=<span class="string">&#x27;o&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Elbow Method for Optimal k&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Number of clusters&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;WCSS&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>图中通常会出现一个肘部，即 WCSS 随 K 增加的速度急剧减缓的位置。该位置的 K 值被认为是最佳簇数。</p><h3 id="轮廓系数法（Silhouette-Score）"><a href="#轮廓系数法（Silhouette-Score）" class="headerlink" title="轮廓系数法（Silhouette Score）"></a>轮廓系数法（Silhouette Score）</h3><p>轮廓系数法用于评估聚类质量和选择最佳的簇数 K。它测量了每个数据点与其簇内其他点的相似度以及与最近簇的相似度，得出一个综合评价指标。</p><p><strong>簇内相似度（ai）</strong>： 数据点 i 与其簇内所有其他数据点的平均距离：</p><script type="math/tex; mode=display">a_i = \frac{1}{|C_i| - 1} \sum_{j \in C_i, j \neq i} \| x_i - x_j \|</script><p><strong>最近簇的相似度（bi）</strong>： 数据点 i 到最近簇（不包含其当前簇）的所有数据点的平均距离：</p><script type="math/tex; mode=display">b_i = \min_{C_k \neq C_i} \frac{1}{|C_k|} \sum_{j \in C_k} \| x_i - x_j \|</script><p>计算轮廓系数 si：</p><script type="math/tex; mode=display">s_i = \frac{b_i - a_i}{\max(a_i, b_i)}</script><p>选择具有最高平均轮廓系数的 K 作为最佳簇数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> silhouette_score</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成示例数据</span></span><br><span class="line">X, _ = make_blobs(n_samples=<span class="number">300</span>, centers=<span class="number">4</span>, cluster_std=<span class="number">0.60</span>, random_state=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算不同K值的轮廓系数</span></span><br><span class="line">silhouette_avg = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, <span class="number">11</span>):</span><br><span class="line">    kmeans = KMeans(n_clusters=i, init=<span class="string">&#x27;k-means++&#x27;</span>)</span><br><span class="line">    kmeans.fit(X)</span><br><span class="line">    cluster_labels = kmeans.labels_</span><br><span class="line">    silhouette_avg.append(silhouette_score(X, cluster_labels))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制轮廓系数图</span></span><br><span class="line">plt.plot(<span class="built_in">range</span>(<span class="number">2</span>, <span class="number">11</span>), silhouette_avg, marker=<span class="string">&#x27;o&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Silhouette Score for Optimal k&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Number of clusters&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Average Silhouette Score&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据探索</title>
      <link href="/2024/08/18/%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E4%B8%AD%E7%9A%84%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83/"/>
      <url>/2024/08/18/%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E4%B8%AD%E7%9A%84%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83/</url>
      
        <content type="html"><![CDATA[<h1 id="数据探索"><a href="#数据探索" class="headerlink" title="数据探索"></a>数据探索</h1><p>对于一些机器学习领域的问题求解来说，判断数据是否符合正态分布是十分重要的，因为大多数情况下，很多模型只有在数据为正态分布的情况下，模型的效果才会更好，所以如何对数据进行正态分布检验探索十分必要。</p><p>一般来说，检验正态分布有两个大的方向，一个是可视化数据，另一个则是统计分析。</p><h2 id="数据的可视化"><a href="#数据的可视化" class="headerlink" title="数据的可视化"></a>数据的可视化</h2><p>这里不光是介绍数据的可视化，还要顺带的把数据探索中的其他方面也全都介绍一下。</p><p>首先对变量进行分析，对于连续型单变量，需要统计数据的中心分布趋势和变量分布，对于类别型变量，一般使用频次或占比表示每一个类别的分布情况，衡量指标分别是类别变量的频次和频率，可以用柱形图来表示可视化分布。</p><p>而对于多变量分析而言，又分为三种：</p><ul><li>连续型与连续型，可以通过绘制散点图和计算相关性系数来分析</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">X = np.array([<span class="number">65</span>,<span class="number">72</span>,<span class="number">78</span>,<span class="number">65</span>,<span class="number">72</span>,<span class="number">70</span>,<span class="number">65</span>,<span class="number">68</span>])</span><br><span class="line">y = np.array([<span class="number">72</span>,<span class="number">69</span>,<span class="number">79</span>,<span class="number">69</span>,<span class="number">84</span>,<span class="number">75</span>,<span class="number">60</span>,<span class="number">73</span>])</span><br><span class="line"></span><br><span class="line">np.corrcoef(X,y)</span><br><span class="line"></span><br><span class="line">plt.scatter(X,y)</span><br><span class="line">plt.title(<span class="string">&#x27;corr&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;X&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;y&#x27;</span>)</span><br></pre></td></tr></table></figure><p><code>corrcoef</code>是计算相关性系数的函数，<code>scatter</code>是plt包内置的散点图函数。</p><ul><li>类别型与类别型，可以通过双向表，堆叠柱状图和卡方检验来分析</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> chi2</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectKBest</span><br><span class="line">iris = load_iris()</span><br><span class="line">X,y = iris.data,iris.target</span><br><span class="line">chiValues = chi2(X,y)</span><br><span class="line">X_new = SelectKBest(chi2,k=<span class="number">2</span>).fit_transform(X,y)</span><br></pre></td></tr></table></figure><p>卡方检验主要用于两个和两个以上样本率及两个二值型离散变量的关联性分析。可以使用卡方检验来筛选与目标变量相关的特征。</p><ul><li>类别型与连续型，可以用小提琴图或箱线图来分析</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line">iris = load_iris()</span><br><span class="line">X, y = iris.data, iris.target</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将数据转换为 DataFrame 以便使用 Seaborn</span></span><br><span class="line">iris_df = pd.DataFrame(X, columns=iris.feature_names)</span><br><span class="line">iris_df[<span class="string">&#x27;species&#x27;</span>] = pd.Categorical.from_codes(y, iris.target_names)</span><br><span class="line"><span class="comment"># pd.Categorical.from_codes(y, iris.target_names) 创建了一个 pandas.Categorical 对象，这个对象将 y 中的整数代码转换为相应的类别名称。</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">sns.violinplot(x=<span class="string">&#x27;species&#x27;</span>, y=<span class="string">&#x27;sepal length (cm)&#x27;</span>, data=iris_df)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&#x27;Violin Plot of Sepal Length by Iris Species&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h2 id="缺失值与异常值"><a href="#缺失值与异常值" class="headerlink" title="缺失值与异常值"></a>缺失值与异常值</h2><p>缺失值的产生有多种原因，比如数据存储失败，机械故障，或人的主观失误、局限、有意隐瞒等机械原因和人为原因造成的。<br>缺失值主要分为四类：完全随机丢失，随机丢失，不可预测损失与取决于自身的损失。</p><p>成列删除会导致样本减少，拟合程度下降，而成对删除会保留更多的样本，不同的变量使用大小不同的样本集，也可以用平均值、众数、中值填充，具体操作又分为：一般填充和相似样本填充。一般填充是指用该变量下的所有非缺失值的平均值或中值来填充，而相似样本填充是利用具有相似特征的样本的值或者近似值进行填充。</p><p>一般可以用<code>fillna()</code>进行简单的缺失值填充。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">&#x27;A&#x27;</span>: [<span class="number">1</span>, <span class="number">2</span>, np.nan, <span class="number">4</span>],</span><br><span class="line">    <span class="string">&#x27;B&#x27;</span>: [np.nan, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>],</span><br><span class="line">    <span class="string">&#x27;C&#x27;</span>: [<span class="number">8</span>, np.nan, <span class="number">10</span>, <span class="number">11</span>]</span><br><span class="line">&#125;</span><br><span class="line">df = pd.DataFrame(data)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将所有 NaN 替换为 0</span></span><br><span class="line">df_filled = df.fillna(<span class="number">0</span>)</span><br><span class="line"><span class="comment"># 用各列的均值填充 NaN</span></span><br><span class="line">df_filled_mean = df.fillna(df.mean()</span><br></pre></td></tr></table></figure><p>异常值的产生原因主要包括数据录入错误、数据测量误差、数据随机误差、观测数据缺少重要自变量、缺少观测数据、模型选择错误、非线性回归、以及自然变异等。</p><p>数据录入错误：可能是由于人为因素导致的错误输入，例如拼写错误或格式错误，这些错误可能导致数据与实际值产生偏差，从而形成异常值。 数据测量误差：在进行数据测量时，由于测量工具的精度限制或操作人员的误差，可能会导致测量结果偏离真实值，形成异常值。 数据随机误差：即使在最好的条件下进行测量，由于随机因素的影响，数据也可能出现偏差，这种偏差可能导致异常值的出现。 观测数据缺少重要自变量：如果在进行数据分析时缺少关键的自变量信息，可能会导致模型无法准确预测结果，从而产生异常值。 缺少观测数据：在某些情况下，由于某些数据点的缺失，可能会导致模型无法准确拟合数据，进而产生异常值。 模型选择错误：如果选择的模型与数据特性不匹配，可能会导致模型预测结果出现偏差，形成异常值。 非线性回归：在进行非线性回归分析时，如果模型设定不正确或数据不符合模型的假设，可能会导致异常值的出现。 自然变异：在某些情况下，异常值可能是由于数据的自然变异导致的，例如在一个班级中，学生的身高普遍在170cm左右，但有一位同学的身高达到了220cm，这样的极端值就可以视为异常值。</p><h2 id="Pandas的数据操作"><a href="#Pandas的数据操作" class="headerlink" title="Pandas的数据操作"></a>Pandas的数据操作</h2><p>假如想要删除某些特征列，可以采取<code>drop()</code>操作，这里以相关性系数小于0.5来剔除：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">threshold = <span class="number">0.5</span></span><br><span class="line">corr_matrix = train_data1.corr().<span class="built_in">abs</span>()</span><br><span class="line">drop_col=corr_matrix[corr_matrix[<span class="string">&quot;target&quot;</span>]&lt;threshold].index</span><br><span class="line">train_x =  train_data.drop([<span class="string">&#x27;target&#x27;</span>], axis=<span class="number">1</span>)</span><br><span class="line">data_all = pd.concat([train_x,test_data]) </span><br><span class="line">data_all.drop(drop_col,axis=<span class="number">1</span>,inplace=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>假如你想要取出特定的某个值，可以使用<code>loc</code>与<code>iloc</code>操作，<code>loc</code> 通过标签（label）选择数据，而 <code>iloc</code> 通过整数位置（index）选择数据。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">&#x27;Name&#x27;</span>: [<span class="string">&#x27;Alice&#x27;</span>, <span class="string">&#x27;Bob&#x27;</span>, <span class="string">&#x27;Charlie&#x27;</span>, <span class="string">&#x27;David&#x27;</span>],</span><br><span class="line">    <span class="string">&#x27;Age&#x27;</span>: [<span class="number">24</span>, <span class="number">27</span>, <span class="number">22</span>, <span class="number">32</span>],</span><br><span class="line">    <span class="string">&#x27;Score&#x27;</span>: [<span class="number">85</span>, <span class="number">91</span>, <span class="number">78</span>, <span class="number">88</span>]</span><br><span class="line">&#125;</span><br><span class="line">df = pd.DataFrame(data)</span><br><span class="line"><span class="comment"># 使用 loc 选择标签为 1 的行（即第二行）</span></span><br><span class="line">row = df.loc[<span class="number">1</span>]</span><br><span class="line"><span class="built_in">print</span>(row)</span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Name     Bob</span><br><span class="line">Age       <span class="number">27</span></span><br><span class="line">Score     <span class="number">91</span></span><br><span class="line">Name: <span class="number">1</span>, dtype: <span class="built_in">object</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 选择标签为 0 和 2 的行，以及列 &quot;Name&quot; 和 &quot;Score&quot;</span></span><br><span class="line">selected_data = df.loc[[<span class="number">0</span>, <span class="number">2</span>], [<span class="string">&#x27;Name&#x27;</span>, <span class="string">&#x27;Score&#x27;</span>]]</span><br><span class="line"><span class="built_in">print</span>(selected_data)</span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">      Name  Score</span><br><span class="line"><span class="number">0</span>    Alice     <span class="number">85</span></span><br><span class="line"><span class="number">2</span>  Charlie     <span class="number">78</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用 iloc 选择第 1 行（即第二行）</span></span><br><span class="line">row = df.iloc[<span class="number">1</span>]</span><br><span class="line"><span class="built_in">print</span>(row)</span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Name     Bob</span><br><span class="line">Age       <span class="number">27</span></span><br><span class="line">Score     <span class="number">91</span></span><br><span class="line">Name: <span class="number">1</span>, dtype: <span class="built_in">object</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 选择第 0 和 2 行，以及第 0 和 2 列</span></span><br><span class="line">selected_data = df.iloc[[<span class="number">0</span>, <span class="number">2</span>], [<span class="number">0</span>, <span class="number">2</span>]]</span><br><span class="line"><span class="built_in">print</span>(selected_data)</span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">      Name  Score</span><br><span class="line"><span class="number">0</span>    Alice     <span class="number">85</span></span><br><span class="line"><span class="number">2</span>  Charlie     <span class="number">78</span></span><br></pre></td></tr></table></figure><p>在pandas中不光可以查看特征变量的类型，还可以修改类型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df.dtypes</span><br><span class="line">df[<span class="string">&#x27;Column1&#x27;</span>] = df[<span class="string">&#x27;Column1&#x27;</span>].astype(<span class="string">&#x27;float64&#x27;</span>)</span><br></pre></td></tr></table></figure><p>同时，还可以进行数据的合并。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 纵向合并</span></span><br><span class="line">pd.concat([df1, df2], ignore_index=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 横向合并</span></span><br><span class="line">pd.merge(df1, df2, on=<span class="string">&#x27;Column1&#x27;</span>)</span><br></pre></td></tr></table></figure><h2 id="数据可视化"><a href="#数据可视化" class="headerlink" title="数据可视化"></a>数据可视化</h2><p>可以用很多方法来进行数据的可视化展示，比如箱线图，直方图，Q-Q图，热力图，折线图，饼图，散点图等。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">iris = load_iris()</span><br><span class="line">X, y = iris.data, iris.target</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将数据转换为 DataFrame 以便使用 Seaborn</span></span><br><span class="line">iris_df = pd.DataFrame(X, columns=iris.feature_names)</span><br><span class="line">iris_df[<span class="string">&#x27;species&#x27;</span>] = pd.Categorical.from_codes(y, iris.target_names)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 Seaborn 绘制箱线图</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">sns.boxplot(x=<span class="string">&#x27;species&#x27;</span>, y=<span class="string">&#x27;sepal length (cm)&#x27;</span>, data=iris_df)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&#x27;Box Plot of Sepal Length by Iris Species&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Iris Species&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Sepal Length (cm)&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>箱线图显示了数据的四分位数、中位数、最大值、最小值，以及可能的离群值（通过箱子之外的点表示）。</p><p>中位数：箱子中的水平线表示数据的中位数。 四分位数：箱子的上下边界分别表示第一四分位数 (Q1) 和第三四分位数 (Q3)。 胡须：胡须（箱子上下的线条）延伸到不超过 1.5 倍四分位距的范围内的数据点。 离群点：超出胡须范围的点被认为是离群点，通常用单独的点标示。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用 Seaborn 绘制直方图</span></span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>, <span class="number">6</span>))</span><br><span class="line">sns.histplot(iris_df[<span class="string">&#x27;sepal length (cm)&#x27;</span>], bins=<span class="number">20</span>, kde=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&#x27;Histogram of Sepal Length&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Sepal Length (cm)&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Frequency&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用 Seaborn 绘制散点图</span></span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>, <span class="number">6</span>))</span><br><span class="line"><span class="comment"># sns.scatterplot(x=&#x27;sepal length (cm)&#x27;, y=&#x27;sepal width (cm)&#x27;, hue=&#x27;species&#x27;, data=iris_df)</span></span><br><span class="line"><span class="comment"># 筛选出 &#x27;setosa&#x27; 类别的数据</span></span><br><span class="line">setosa_df = iris_df[iris_df[<span class="string">&#x27;species&#x27;</span>] == <span class="string">&#x27;setosa&#x27;</span>]</span><br><span class="line">sns.scatterplot(x=<span class="string">&#x27;sepal length (cm)&#x27;</span>, y=<span class="string">&#x27;sepal width (cm)&#x27;</span>, hue=<span class="string">&#x27;species&#x27;</span>, data=setosa_df)</span><br><span class="line">plt.title(<span class="string">&#x27;Scatter Plot of Sepal Length vs Sepal Width&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Sepal Length (cm)&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Sepal Width (cm)&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>一般来说，我们得到了一个excel文件后，首先要通过pandas的<code>read_excel</code>函数来进行文件录入，得到一个pandas框架，假如命名为<code>data</code>，那么首先可以通过一些概述性统计来进行粗略的初步探索。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">data.head()</span><br><span class="line">data.info()</span><br><span class="line">data.describe()</span><br><span class="line">data.tail()</span><br><span class="line">data.<span class="built_in">sum</span>()</span><br><span class="line">data.mean()</span><br></pre></td></tr></table></figure><p>一般来说，我们想得到这个数据集的特征变量名与目标变量名，这时就要通过以下操作进行：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">column = data.columns.tolist()</span><br><span class="line">target = data.target.tolist()</span><br></pre></td></tr></table></figure><p>在Python中，axis = 1是针对列操作，axis = 0是针对行操作。</p><p>假如我们想查看这个数据是否符合正态分布，可以使用<code>Q-Q</code>图，具体操作如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">5</span>))</span><br><span class="line"></span><br><span class="line">ax = plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">sns.histplot(train_data[<span class="string">&#x27;V0&#x27;</span>], kde=<span class="literal">True</span>, stat=<span class="string">&quot;density&quot;</span>, line_kws=&#123;<span class="string">&#x27;color&#x27;</span>:<span class="string">&#x27;red&#x27;</span>&#125;, ax=ax)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加正态分布拟合</span></span><br><span class="line">xmin, xmax = plt.xlim()</span><br><span class="line">x = np.linspace(xmin, xmax, <span class="number">100</span>)</span><br><span class="line">p = stats.norm.pdf(x, train_data[<span class="string">&#x27;V0&#x27;</span>].mean(), train_data[<span class="string">&#x27;V0&#x27;</span>].std())</span><br><span class="line">plt.plot(x, p, linewidth=<span class="number">2</span>, color=<span class="string">&#x27;red&#x27;</span>) </span><br><span class="line"></span><br><span class="line">ax = plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">res = stats.probplot(train_data[<span class="string">&#x27;V0&#x27;</span>], plot=plt)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>如果这个数据越接近正态分布，那么数据点将会全部落在右面的直线上。</p><p>当然，还可以用KDE图，KDE图不光可以展示分布情况，还可以用来进行前后特征的分布对比。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ax = sns.kdeplot(train_data[<span class="string">&#x27;V0&#x27;</span>], color=<span class="string">&quot;Red&quot;</span>, fill=<span class="literal">True</span>)</span><br><span class="line">ax = sns.kdeplot(test_data[<span class="string">&#x27;V0&#x27;</span>], color=<span class="string">&quot;Blue&quot;</span>, fill=<span class="literal">True</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;V0&#x27;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&quot;Frequency&quot;</span>)</span><br><span class="line">ax = ax.legend([<span class="string">&quot;train&quot;</span>,<span class="string">&quot;test&quot;</span>])</span><br></pre></td></tr></table></figure><p>对于系数矩阵的计算，也可以直接对数据集进行<code>corr()</code>操作，比如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">corr_matrix = data.corr()</span><br><span class="line"><span class="comment"># 画出相关性热力图</span></span><br><span class="line">ax = plt.subplots(figsize=(<span class="number">20</span>, <span class="number">16</span>))</span><br><span class="line">ax = sns.heatmap(train_corr, vmax=<span class="number">.8</span>, square=<span class="literal">True</span>, annot=<span class="literal">True</span>)<span class="comment">#画热力图   annot=True 显示系数</span></span><br></pre></td></tr></table></figure><p>另一种下三角热力图展示。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">20</span>, <span class="number">16</span>))  </span><br><span class="line">column = train_data_scaler.columns.tolist()  </span><br><span class="line">mcorr = train_data_scaler[column].corr(method=<span class="string">&quot;spearman&quot;</span>)  </span><br><span class="line">mask = np.zeros_like(mcorr, dtype=np.bool_)  </span><br><span class="line">mask[np.triu_indices_from(mask)] = <span class="literal">True</span>  </span><br><span class="line">cmap = sns.diverging_palette(<span class="number">220</span>, <span class="number">10</span>, as_cmap=<span class="literal">True</span>)  </span><br><span class="line">g = sns.heatmap(mcorr, mask=mask, cmap=cmap, square=<span class="literal">True</span>, annot=<span class="literal">True</span>, fmt=<span class="string">&#x27;0.2f&#x27;</span>)  </span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>我们还可以用饼图来展示占比效果。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">sort_huaye = <span class="built_in">len</span>(huaye_index)</span><br><span class="line">sort_jun = <span class="built_in">len</span>(jun_index)</span><br><span class="line">sort_qie = <span class="built_in">len</span>(qie_index)</span><br><span class="line">sort_lajiao = <span class="built_in">len</span>(lajiao_index)</span><br><span class="line">sort_huacai = <span class="built_in">len</span>(huacai_index)</span><br><span class="line">sort_shuisheng = <span class="built_in">len</span>(shuisheng_index)</span><br><span class="line">sort_data = [sort_huaye,sort_lajiao,sort_qie,sort_jun,sort_huacai,sort_shuisheng]</span><br><span class="line">labels = [<span class="string">&#x27;花叶类&#x27;</span>,<span class="string">&#x27;辣椒类&#x27;</span>,<span class="string">&#x27;茄类&#x27;</span>,<span class="string">&#x27;食用菌&#x27;</span>,<span class="string">&#x27;花菜类&#x27;</span>,<span class="string">&#x27;水生根茎类&#x27;</span>,]</span><br><span class="line">plt.figure(figsize=(<span class="number">7</span>,<span class="number">7</span>))</span><br><span class="line">plt.title(<span class="string">&#x27;种类丰富度占比&#x27;</span>,fontsize = <span class="number">15</span>)</span><br><span class="line">colors =  [<span class="string">&#x27;red&#x27;</span>, <span class="string">&#x27;blue&#x27;</span>, <span class="string">&#x27;green&#x27;</span>, <span class="string">&#x27;yellow&#x27;</span>, <span class="string">&#x27;lightgray&#x27;</span>,<span class="string">&#x27;orange&#x27;</span>]</span><br><span class="line">plt.pie(sort_data,labels=labels,autopct=<span class="string">&#x27;%.1f %%&#x27;</span>,colors=colors,startangle=<span class="number">90</span>)</span><br></pre></td></tr></table></figure><p>折线图可以用来展示随某一变量变化的趋势。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">huayeXsl[<span class="string">&#x27;销售日期&#x27;</span>] = pd.to_datetime(huayeXsl[<span class="string">&#x27;销售日期&#x27;</span>]).dt.date</span><br><span class="line">huacaiXsl[<span class="string">&#x27;销售日期&#x27;</span>] = pd.to_datetime(huacaiXsl[<span class="string">&#x27;销售日期&#x27;</span>]).dt.date</span><br><span class="line">junXsl[<span class="string">&#x27;销售日期&#x27;</span>] = pd.to_datetime(junXsl[<span class="string">&#x27;销售日期&#x27;</span>]).dt.date</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将销售量按照日期进行求和</span></span><br><span class="line">huaye_daily = huayeXsl.groupby(<span class="string">&#x27;销售日期&#x27;</span>)[<span class="string">&#x27;销量(千克)&#x27;</span>].<span class="built_in">sum</span>().reset_index()</span><br><span class="line">huacai_daily = huacaiXsl.groupby(<span class="string">&#x27;销售日期&#x27;</span>)[<span class="string">&#x27;销量(千克)&#x27;</span>].<span class="built_in">sum</span>().reset_index()</span><br><span class="line">jun_daily = junXsl.groupby(<span class="string">&#x27;销售日期&#x27;</span>)[<span class="string">&#x27;销量(千克)&#x27;</span>].<span class="built_in">sum</span>().reset_index()</span><br><span class="line"></span><br><span class="line">x1 = huaye_daily[<span class="string">&#x27;销售日期&#x27;</span>]</span><br><span class="line">x2 = huacai_daily[<span class="string">&#x27;销售日期&#x27;</span>]</span><br><span class="line">x3 = jun_daily[<span class="string">&#x27;销售日期&#x27;</span>]</span><br><span class="line">y1 = huaye_daily[<span class="string">&#x27;销量(千克)&#x27;</span>]</span><br><span class="line">y2 = huacai_daily[<span class="string">&#x27;销量(千克)&#x27;</span>]</span><br><span class="line">y3 = jun_daily[<span class="string">&#x27;销量(千克)&#x27;</span>]</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">15</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line">plt.plot(x1, y1, linewidth=<span class="number">1</span>, color=<span class="string">&#x27;r&#x27;</span>,label=<span class="string">&quot;花叶类&quot;</span>)</span><br><span class="line">plt.plot(x2, y2, linewidth=<span class="number">1</span>, color=<span class="string">&#x27;g&#x27;</span>,label=<span class="string">&quot;花菜类&quot;</span>)</span><br><span class="line">plt.plot(x3, y3, linewidth=<span class="number">1</span>, color=<span class="string">&#x27;b&#x27;</span>,label=<span class="string">&quot;食用菌&quot;</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&#x27;每天销售量随时间变化图&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;销售日期&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;销量(千克)&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.xticks(rotation=<span class="number">45</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;upper left&#x27;</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h2 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h2><p>一般来说，有数据的标准化，归一化等，如果对输出范围有要求，则用归一化，如果数据较为稳定，不存在极端最大值和最小值则用归一化，若存在异常值和较多噪声则用标准化。具体方法为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> Normalizer<span class="comment"># 标准化</span></span><br><span class="line"></span><br><span class="line">norm = Normalizer()</span><br><span class="line">new_data_all = norm.fit_transform(data_all)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler <span class="comment"># 标准化</span></span><br><span class="line"></span><br><span class="line">stand = StandardScaler()</span><br><span class="line">NewData = stand.fit_transform(data_all)</span><br></pre></td></tr></table></figure><p>独热编码和哑编码是数据预处理中常见的两种编码方式，用于将分类特征转化为数值型数据。独热编码为每个类别创建一个独立的二进制变量，而哑编码则通过N-1个变量来表示N个类别，最后一个类别通过排除其他所有类别来确定。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.impute <span class="keyword">import</span> SimpleImputer</span><br><span class="line"></span><br><span class="line">imputer = SimpleImputer(strategy=<span class="string">&#x27;median&#x27;</span>)<span class="comment"># 使用均值填充</span></span><br><span class="line">X_train_imputed = imputer.fit_transform(train_data1)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> Binarizer</span><br><span class="line"></span><br><span class="line">Bin = Binarizer()</span><br><span class="line">data_1 = Bin.fit_transform(data_all)</span><br></pre></td></tr></table></figure><p>进行完数据的探索后，我们想对数据进行转换，来符合正态分布。</p><p>基于多项式转换：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"></span><br><span class="line">data1 = load_iris()</span><br><span class="line">X = data1.data</span><br><span class="line">poly = PolynomialFeatures()</span><br><span class="line">data2 = poly.fit_transform(X)</span><br></pre></td></tr></table></figure><p>基于对数变换,通过自定义单元进行数据转换:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> log1p</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> FunctionTransformer</span><br><span class="line"></span><br><span class="line">fun = FunctionTransformer(log1p,validate=<span class="literal">False</span>)</span><br><span class="line">data3 = fun.fit_transform(X)</span><br></pre></td></tr></table></figure><p>对于特征数量过多的数据集，我们可能还需要进行数据降维，降维是指在某些限定条件下，降低随机变量(特征)个数，得到一组“不相关”主变量的过程,一般分为特征选择和线性降维，特征选择一般有：过滤法，包装法，嵌入法</p><p>对于过滤法，则一般用VarianceThreshold和SelectKBest类来实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> VarianceThreshold</span><br><span class="line"></span><br><span class="line">Vari = VarianceThreshold(threshold=<span class="number">3</span>)<span class="comment"># 选择方差门槛为3</span></span><br><span class="line">data4 = Vari.fit_transform(X)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectKBest</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> pearsonr</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载数据集</span></span><br><span class="line">iris = load_iris()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义 Pearson 相关系数作为评分函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">pearson_corr</span>(<span class="params">X, y</span>):</span><br><span class="line">    <span class="comment"># 对每个特征计算与目标变量的 Pearson 相关系数，返回相关系数和p值</span></span><br><span class="line">    <span class="keyword">return</span> np.array([pearsonr(X[:, i], y)[<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(X.shape[<span class="number">1</span>])])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 SelectKBest 选择最相关的两个特征</span></span><br><span class="line">selector = SelectKBest(score_func=pearson_corr, k=<span class="number">2</span>)</span><br><span class="line">X_new = selector.fit_transform(iris.data, iris.target)</span><br></pre></td></tr></table></figure><p>可以使用卡方检验来进行特征的选择：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> chi2</span><br><span class="line">SelectKBest(chi2,k=<span class="number">2</span>).fit_transform(iris.data,iris.target)</span><br></pre></td></tr></table></figure><p>RFE法也可以用来进行特征选择，它是一种迭代模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> RFE</span><br><span class="line"></span><br><span class="line">RFE(estimator=LogisticRegression(multi_class=<span class="string">&#x27;auto&#x27;</span>,solver=<span class="string">&#x27;lbfgs&#x27;</span>,max_iter=<span class="number">500</span>),n_features_to_select=<span class="number">2</span>).fit_transform(iris.data,iris.target)</span><br></pre></td></tr></table></figure><p>线性降维，一般有主成分分析法与线性判别分析法</p><p>主成分分析法希望找到某种线性投影，使数据投到低维空间中的数据方差最大，以达到使用较少数据维度来保留较多数据原始特征的效果</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"></span><br><span class="line">PCA(n_components=<span class="number">2</span>).fit_transform(iris.data)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.discriminant_analysis <span class="keyword">import</span> LinearDiscriminantAnalysis <span class="keyword">as</span> LDA <span class="comment"># 线性判别法</span></span><br><span class="line"></span><br><span class="line">LDA(n_components=<span class="number">2</span>).fit_transform(iris.data,iris.target)</span><br></pre></td></tr></table></figure><h2 id="正态分布统计量的检验"><a href="#正态分布统计量的检验" class="headerlink" title="正态分布统计量的检验"></a>正态分布统计量的检验</h2><p>不光可以用可视化来观察，还可以通过统计量描述来判断数据是否符合正态分布，Shapiro-Wilk检验、Kolmogorov-Smirnov (KS) 检验以及Anderson-Darling检验是常用的正态性检验方法，主要用于检测样本数据是否符合正态分布。</p><h3 id="Shapiro-Wilk检验"><a href="#Shapiro-Wilk检验" class="headerlink" title="Shapiro-Wilk检验"></a>Shapiro-Wilk检验</h3><p>Shapiro-Wilk检验通过比较样本的顺序统计量（即样本数据的有序排列）与正态分布下相应的理论顺序统计量来检验数据的正态性。该检验的统计量W是通过如下公式计算的：</p><script type="math/tex; mode=display">W = \frac{\left(\sum_{i=1}^{n} a_i x_{(i)}\right)^2}{\sum_{i=1}^{n} (x_i - \bar{x})^2}</script><p>与显著性水平（如0.05）比较p值，若p值小于显著性水平，拒绝原假设（数据不服从正态分布）:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br><span class="line"></span><br><span class="line">statistic, p_value = stats.shapiro(data)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Shapiro-Wilk检验统计量: <span class="subst">&#123;statistic&#125;</span>, p值: <span class="subst">&#123;p_value&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><h3 id="Kolmogorov-Smirnov-KS-检验"><a href="#Kolmogorov-Smirnov-KS-检验" class="headerlink" title="Kolmogorov-Smirnov (KS) 检验"></a>Kolmogorov-Smirnov (KS) 检验</h3><p>Kolmogorov-Smirnov检验用于比较样本的经验分布函数（Empirical Distribution Function, EDF）与理论分布函数，或比较两个样本的EDF。检验的统计量是样本EDF与理论分布或另一个样本EDF之间的最大差距。</p><script type="math/tex; mode=display">D_n = \sup_x |F_n(x) - F(x)|</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br><span class="line"></span><br><span class="line">statistic, p_value = stats.kstest(data, <span class="string">&#x27;norm&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Kolmogorov-Smirnov检验统计量: <span class="subst">&#123;statistic&#125;</span>, p值: <span class="subst">&#123;p_value&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><h3 id="Anderson-Darling检验"><a href="#Anderson-Darling检验" class="headerlink" title="Anderson-Darling检验"></a>Anderson-Darling检验</h3><p>Anderson-Darling检验是对Kolmogorov-Smirnov检验的改进，增强了尾部的检验能力。它使用了加权的EDF，使得在分布尾部的差异贡献更大。</p><script type="math/tex; mode=display">A^2 = -n - \frac{1}{n} \sum_{i=1}^{n} \left[ (2i-1) \ln(F(x_i)) + (2n+1-2i) \ln(1-F(x_{n+1-i})) \right]</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br><span class="line"></span><br><span class="line">result = stats.anderson(data, dist=<span class="string">&#x27;norm&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Anderson-Darling检验统计量: <span class="subst">&#123;result.statistic&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;临界值: <span class="subst">&#123;result.critical_values&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;显著性水平: <span class="subst">&#123;result.significance_level&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><p><strong>Shapiro-Wilk检验</strong>: 适用于小样本，计算复杂但精度较高，适合正态性检验。</p><p><strong>Kolmogorov-Smirnov检验</strong>: 通用性强，可用于任意分布的检验，但对尾部差异不敏感。</p><p><strong>Anderson-Darling检验</strong>: 适用于更广泛的分布，增强了对尾部差异的敏感性，适合样本量较大时使用。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 数据分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>非参数检验</title>
      <link href="/2024/08/17/%E9%9D%9E%E5%8F%82%E6%95%B0%E6%A3%80%E9%AA%8C/"/>
      <url>/2024/08/17/%E9%9D%9E%E5%8F%82%E6%95%B0%E6%A3%80%E9%AA%8C/</url>
      
        <content type="html"><![CDATA[<h1 id="非参数检验"><a href="#非参数检验" class="headerlink" title="非参数检验"></a>非参数检验</h1><p>非参数检验是在总体方差未知或知道甚少的情况下，利用样本数据对总体分布形态等进行推断的方法。一般来说参数检验侧重于样本整体的均值，而非参数检验更侧重于样本的中位值，这也就意味对于极差较大的数据来说，非参数检验不容易收到极端值的干扰。</p><p>参数检验应用的前提是数据符合正态分布，而现实情况中很多数据的分布并不服从正态分布，虽然对于样本量很大的数据来说，即使其不符合正态分布，但应用参数检验也能取到较好的效果，但对于那些既不符合正态分布，同时样本量较小的情况下，则更适合用非参数检验。</p><p>这些检验方法都可以在SPSS中快速实现，本文只是简单对各类方法进行简要的原理介绍和适用条件概括。</p><h2 id="卡方检验-Chi-Square-Test"><a href="#卡方检验-Chi-Square-Test" class="headerlink" title="卡方检验(Chi-Square Test)"></a>卡方检验(Chi-Square Test)</h2><p>在这么多的非参数检验方法中，卡方检验无疑是最常用的方法之一，其常用于检验变量之间的关联性或检验观测数据与期望分布之间的适合度。</p><script type="math/tex; mode=display">\chi^2 = \sum \frac{(O_i - E_i)^2}{E_i}</script><p>其中，$Oi$是观测频数，$Ei$ 是期望频数。</p><p>比如假设你是一名市场研究人员，想要研究消费者的性别（男性或女性）与他们购买某种新产品的意愿（愿意购买、不愿意购买、尚未决定）之间是否存在关联。</p><p>你调查了200位消费者，收集了他们的性别以及对购买该产品的意愿，并将结果整理成以下的列联表：</p><div class="table-container"><table><thead><tr><th>性别</th><th>愿意购买</th><th>不愿意购买</th><th>尚未决定</th><th>合计</th></tr></thead><tbody><tr><td>男性</td><td>30</td><td>50</td><td>20</td><td>100</td></tr><tr><td>女性</td><td>40</td><td>30</td><td>30</td><td>100</td></tr><tr><td><strong>合计</strong></td><td><strong>70</strong></td><td><strong>80</strong></td><td><strong>50</strong></td><td><strong>200</strong></td></tr></tbody></table></div><p><strong>问题</strong>:<br>你想知道性别和购买意愿之间是否存在显著关联，或者说性别是否会影响消费者的购买决策。</p><p><strong>解决方法</strong>:<br>由于性别和购买意愿都是分类变量，并且数据以列联表的形式呈现，可以使用<strong>卡方检验</strong>来检验性别和购买意愿之间的独立性。</p><h2 id="Fisher精确检验-Fisher’s-Exact-Test"><a href="#Fisher精确检验-Fisher’s-Exact-Test" class="headerlink" title="Fisher精确检验(Fisher’s Exact Test)"></a>Fisher精确检验(Fisher’s Exact Test)</h2><p>Fisher精确检验其实与卡方检验很像，但其适用于当样本量小于20，或是某些单元格的期望频数小于5的情况。</p><script type="math/tex; mode=display">p = \frac{(a+b)!(c+d)!(a+c)!(b+d)!}{a!b!c!d!n!}</script><p>其中，$a,b,c,d$是列联表中的四个单元格频数，$n$ 是样本总数。</p><h2 id="Wilcoxon符号秩检验-Wilcoxon-Signed-Rank-Test"><a href="#Wilcoxon符号秩检验-Wilcoxon-Signed-Rank-Test" class="headerlink" title="Wilcoxon符号秩检验 (Wilcoxon Signed-Rank Test)"></a>Wilcoxon符号秩检验 (Wilcoxon Signed-Rank Test)</h2><p>符号检验只考虑的分布在中位数两侧的样本数据的个数，并没有考虑中位数两侧数据分布的疏密程度，而Wilcoxon符合秩检验便解决这个问题。</p><script type="math/tex; mode=display">W = \sum \text{sign}(x_i - y_i) \times R(|x_i - y_i|)</script><p>其中，$x_i$和 $y_i$是成对样本的值，$R(∣x_i−y_i∣)$ 是差值的秩。</p><p><strong>背景</strong>:<br>假设你是一名心理学家，正在研究一种新型的冥想疗法对减轻焦虑症状的效果。你招募了一组10名患有焦虑症的患者，分别在治疗前和治疗后测量他们的焦虑评分。你的目的是确定冥想疗法是否显著降低了焦虑评分。</p><p>以下是每位患者治疗前后的焦虑评分：</p><div class="table-container"><table><thead><tr><th>患者编号</th><th>治疗前评分</th><th>治疗后评分</th><th>差值（治疗后 - 治疗前）</th></tr></thead><tbody><tr><td>1</td><td>25</td><td>20</td><td>-5</td></tr><tr><td>2</td><td>28</td><td>22</td><td>-6</td></tr><tr><td>3</td><td>31</td><td>27</td><td>-4</td></tr><tr><td>4</td><td>29</td><td>25</td><td>-4</td></tr><tr><td>5</td><td>34</td><td>30</td><td>-4</td></tr><tr><td>6</td><td>32</td><td>28</td><td>-4</td></tr><tr><td>7</td><td>30</td><td>24</td><td>-6</td></tr><tr><td>8</td><td>27</td><td>22</td><td>-5</td></tr><tr><td>9</td><td>35</td><td>30</td><td>-5</td></tr><tr><td>10</td><td>33</td><td>29</td><td>-4</td></tr></tbody></table></div><p><strong>问题</strong>:<br>你想知道治疗前后的焦虑评分是否存在显著差异。</p><p><strong>解决方法</strong>:<br>由于数据是配对的（同一组患者在治疗前后分别测量了焦虑评分），而且你不确定数据是否服从正态分布，因此可以使用 <strong>Wilcoxon符号秩检验</strong> 来检验治疗前后的差异是否显著。</p><h2 id="Mann-Whitney检验-Mann-Whitney-U-Test"><a href="#Mann-Whitney检验-Mann-Whitney-U-Test" class="headerlink" title="Mann-Whitney检验 (Mann-Whitney U Test)"></a>Mann-Whitney检验 (Mann-Whitney U Test)</h2><p>Mann-Whitney检验是一种用于比较两组独立样本的非参数检验方法，它检验两组样本是否来自具有相同分布的总体。该检验是Wilcoxon秩和检验的变体。</p><script type="math/tex; mode=display">U = n_1n_2 + \frac{n_1(n_1+1)}{2} - R_1</script><p>其中，$n_1$ 和 $n_2$是两组样本的大小，$R_1$​是第一组样本的秩和。</p><p><strong>实际例子</strong>:<br>假设你是一名药物研究人员，正在研究两种药物（A和B）对降低血压的效果。你随机选择了两组不同的志愿者，每组20人，并分别给予药物A和药物B治疗一段时间，然后测量每位志愿者的血压变化值（治疗前后血压的差异）。</p><ul><li><strong>药物A组的血压变化值</strong>: 12,15,14,10,18,13,11,16,19,14,15,17,12,14,15,13,11,18,17,16</li><li><strong>药物B组的血压变化值</strong>: 10,9,12,11,14,10,13,12,11,9,8,14,10,11,12,10,9,11,10,13</li></ul><p><strong>问题</strong>:<br>你想知道药物A和药物B的效果是否有显著差异。</p><p><strong>解决方法</strong>:<br>由于两个组的志愿者是独立的（不同的人），而且假设数据不服从正态分布，因此可以使用<strong>Mann-Whitney检验</strong>来比较两组数据的分布是否存在显著差异。</p><p><strong>应用场景</strong>:</p><p>Mann-Whitney检验适用于这种情况，因为它不需要数据服从正态分布，并且可以处理独立样本间的比较。</p><h2 id="Kruskal-Wallis检验-Kruskal-Wallis-H-Test"><a href="#Kruskal-Wallis检验-Kruskal-Wallis-H-Test" class="headerlink" title="Kruskal-Wallis检验 (Kruskal-Wallis H Test)"></a>Kruskal-Wallis检验 (Kruskal-Wallis H Test)</h2><p>Kruskal-Wallis检验是Mann-Whitney检验的扩展，适用于比较两组以上的独立样本。它是一种秩和检验，用于检验多个样本是否来自同一分布。</p><script type="math/tex; mode=display">H = \frac{12}{N(N+1)} \sum_{i=1}^k \frac{R_i^2}{n_i} - 3(N+1)</script><p>其中，$N$ 是所有样本的总数，$R_i$是第$i$组样本的秩和，$n_i$是第$i$组的样本量，$k$是组数。</p><p><strong>背景</strong>:<br>假设你是一名教育研究人员，正在研究三种不同教学方法（传统教学、在线教学、混合教学）对学生期末考试成绩的影响。你从三所不同的学校中随机选择了30名学生，分别接受这三种不同的教学方法，每组10名学生。期末考试结束后，你收集了每个学生的考试成绩，并希望确定不同教学方法之间的成绩是否有显著差异。</p><p>以下是各组学生的考试成绩：</p><ul><li><strong>传统教学组</strong>: 78, 85, 82, 88, 90, 83, 79, 81, 87, 84</li><li><strong>在线教学组</strong>: 70, 75, 68, 80, 77, 72, 74, 76, 69, 73</li><li><strong>混合教学组</strong>: 85, 88, 90, 92, 89, 91, 87, 86, 90, 88</li></ul><p><strong>问题</strong>:<br>你想知道这三种不同的教学方法是否导致了学生成绩的显著差异。</p><p><strong>解决方法</strong>:<br>因为你在比较三个独立组的数据，并且不确定这些数据是否服从正态分布，因此可以使用 <strong>Kruskal-Wallis检验</strong> 来检验三组数据的中位数是否存在显著差异。</p><h2 id="Friedman检验（Friedman-Test）"><a href="#Friedman检验（Friedman-Test）" class="headerlink" title="Friedman检验（Friedman Test）"></a>Friedman检验（Friedman Test）</h2><script type="math/tex; mode=display">Q = \frac{12}{nk(k+1)} \sum_{j=1}^k R_j^2 - 3n(k+1)</script><p>其中，n是被试的数量，k是测量次数，$R_j$​是第j个条件的秩和。</p><p><strong>背景</strong>:<br>假设你是一名营养学研究人员，正在研究三种不同饮食计划对体重变化的效果。你从同一组志愿者中选择了10名志愿者，依次让他们接受三种不同的饮食计划，每个饮食计划持续一个月。为了控制变量，每名志愿者在每种饮食计划之间有一段清洗期，以确保前一饮食计划的影响不会影响后一饮食计划。</p><p>以下是每名志愿者在每个饮食计划后的体重减轻情况（单位：公斤）：</p><div class="table-container"><table><thead><tr><th>志愿者编号</th><th>饮食计划A</th><th>饮食计划B</th><th>饮食计划C</th></tr></thead><tbody><tr><td>1</td><td>2.1</td><td>2.5</td><td>1.9</td></tr><tr><td>2</td><td>3.4</td><td>3.0</td><td>2.8</td></tr><tr><td>3</td><td>1.5</td><td>2.0</td><td>1.7</td></tr><tr><td>4</td><td>2.3</td><td>2.2</td><td>2.0</td></tr><tr><td>5</td><td>3.0</td><td>2.8</td><td>2.5</td></tr><tr><td>6</td><td>2.8</td><td>3.2</td><td>2.6</td></tr><tr><td>7</td><td>1.9</td><td>2.4</td><td>1.8</td></tr><tr><td>8</td><td>2.6</td><td>2.7</td><td>2.2</td></tr><tr><td>9</td><td>2.4</td><td>2.6</td><td>2.3</td></tr><tr><td>10</td><td>2.9</td><td>3.1</td><td>2.7</td></tr></tbody></table></div><p><strong>问题</strong>:<br>你想知道这三种饮食计划是否对体重减轻效果有显著不同的影响。</p><p><strong>解决方法</strong>:<br>由于这是同一组志愿者在三种不同条件下的重复测量数据，并且你不确定数据是否服从正态分布，可以使用 <strong>Friedman检验</strong> 来检验三种饮食计划对体重减轻效果的差异是否显著。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul><li><strong>卡方检验</strong>和<strong>Fisher精确检验</strong>用于类别数据之间的关联性检验，区别在于卡方检验更适合大样本，而Fisher精确检验更适合小样本。</li><li><strong>Mann-Whitney检验</strong>和<strong>Kruskal-Wallis检验</strong>用于比较独立样本的数据分布，Mann-Whitney检验适用于两组数据，Kruskal-Wallis检验适用于两组以上数据。</li><li><strong>Friedman检验</strong>和<strong>Wilcoxon符号秩检验</strong>用于比较相关样本的数据分布，Friedman检验适用于多组数据，Wilcoxon符号秩检验适用于两组数据。</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 假设检验 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Lasso回归与岭回归</title>
      <link href="/2024/08/16/Lasso%E5%9B%9E%E5%BD%92%E4%B8%8E%E5%B2%AD%E5%9B%9E%E5%BD%92/"/>
      <url>/2024/08/16/Lasso%E5%9B%9E%E5%BD%92%E4%B8%8E%E5%B2%AD%E5%9B%9E%E5%BD%92/</url>
      
        <content type="html"><![CDATA[<h1 id="回归问题"><a href="#回归问题" class="headerlink" title="回归问题"></a>回归问题</h1><p>回归问题一般是预测一个或多个因变量与一个或多个自变量的关系，一般的回归方法有很多种，比如线性回归，Logistic回归，又或是决策树回归，集成的随机森林回归与支持向量机回归，还有两个回归方法十分典型，一个是Lasso回归，一个是岭回归，将这两个回归方法放在一起讨论是因为它们都用到了<strong>正则化</strong>这项技术。</p><h1 id="L1与L2正则化"><a href="#L1与L2正则化" class="headerlink" title="L1与L2正则化"></a>L1与L2正则化</h1><p>L1 和 L2 正则化是两种常用的正则化方法，通常用于防止机器学习模型过拟合。它们通过在模型的损失函数中加入一个正则化项来限制模型的复杂度，从而提高模型的泛化能力。</p><p>L1 正则化的核心思想是对模型参数的绝对值进行惩罚。它在损失函数中加入一个正则化项，该项是所有模型参数绝对值之和的某个倍数，即：$\lambda \sum_{i=1}^n|\omega_i|$，其中$\lambda$是正则化的权重项，$\omega$则是参数，L1 正则化会导致某些参数被缩减为零，因此它具有内置的特征选择功能，使得它特别适合高维度数据集。通过强制一些参数为零，L1 正则化可以产生稀疏模型，更方便解释，所以一般来说，Lasso回归不仅适用于回归，也应用在一些<strong>特征降维</strong>的方面上，但是它的原理与主成分分析又不同，Lasso回归是选择一些与目标变量最相关的几个特征，而主成分分析是通过一个空间，将高维数据最大程度的映射为低维数据，所以这个过程中，Lasso回归并没有产生新的变量。</p><p>而L2 正则化的核心思想是对模型参数的平方进行惩罚。它在损失函数中加入一个正则化项，该项是所有模型参数平方和的某个倍数，即：$\lambda \sum_{i=1}^n\omega_i^2$，L2 正则化不会像 L1 正则化那样将参数缩减为零，而是会使得所有参数都趋向于较小的值，因此它不能进行特征选择。L2 正则化能够有效地减小模型的复杂度，减少对训练数据的过拟合，但保留所有的特征。</p><p>这里的正则化是最优化理论的一些概念。可以类比为一个<strong>Lp</strong>距离，对于L1正则化，其距离类似于曼哈顿距离，对L2正则化而言，距离则变为了一个完整的圆，由于圆和菱形都是一个凸优化图形，所以这方便了目标函数的最优化。</p><p>那Lasso回归与岭回归是用来解决什么问题的呢？通过约束性我们不难发现，这两种正则化回归是为了解决过拟合问题，也就是解决数据高度相关的情况下，所以当自变量高度相关时，即多重共线性，我们一般用正则化回归。</p><h1 id="多重共线性"><a href="#多重共线性" class="headerlink" title="多重共线性"></a>多重共线性</h1><p><strong>多重共线性(Multicollinearity)</strong>是指两个或更多的自变量之间存在明显的相关性。即这些自变量之间有显著的线性关系，因此它们无法为回归分析提供任何独特的信息。这样会有什么问题？很显然，这样的后果是模型无法准确的识别出是哪个变量在起作用，可解释性变差，同时数据中的共线性会增加方差并导致模型过拟合，从而导致模型在推理时对看不见的数据的性能不佳。</p><p>实际上，各种数据集都或多或少的存在部分特征共线性的情况，只不过是程度有大有小，而对于比较严重的多重共线性的情况，也就是有很多特征存在着这样的问题，所以我们要首先判断是哪些特征是共线性的，一般来说可视化方法有，相关系数矩阵的热力图，聚类图，或是VIF。</p><p>什么是VIF？方差膨胀因子（VIF）是回归分析中多重共线性程度的衡量指标。VIF用于确定一个自变量与一组其他变量之间的相关性。VIF的数值越低越好。大于4或5的值被认为是中度到高度的，大于10的值则被认为非常高。一般情况下通常将VIF = 5作为阈值，所有大于这个门槛的自变量都需要移除。虽然很多教材中只有当VIF &gt; 10时才被认为是严重的多重共线性。</p><script type="math/tex; mode=display">VIF =  \frac{1}{1-R_i^2}</script><h1 id="岭回归-Ridge-regression"><a href="#岭回归-Ridge-regression" class="headerlink" title="岭回归(Ridge regression)"></a>岭回归(Ridge regression)</h1><p>岭回归主要用在解决多重共线性问题，所以其适用于高维数据集，同时其曲线一般来说是平滑的，因为平方项的系数不容易变为0，所以一般来说不会是一条直线，而是一条曲线。</p><script type="math/tex; mode=display">min_\beta (\sum_{i=1}^n(y_i-X_i\beta)^2+\lambda\sum_{j=1}^p\beta_j^2)</script><p>其中的前面一部分就是普通的最小二乘法，后面则是L2正则化的约束项。</p><p>许多机器学习模型（如线性回归、岭回归、支持向量机等）只能处理数值数据。这些模型需要将所有输入特征转换为数值形式，我们选择一个具有多重共线性特征的数据集:BMI，并需要将 <code>&#39;Male&#39;</code> 和 <code>&#39;Female&#39;</code> 转换为数字。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> statsmodels.stats.outliers_influence <span class="keyword">import</span> variance_inflation_factor</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">url = <span class="string">&quot;https://github.com/gouravsinghbais/Detecting-and-Remedying-Multicollinearity-in-Your-Data-Analysis/raw/master/bmi.csv&quot;</span></span><br><span class="line">bmi = pd.read_csv(url)</span><br><span class="line"><span class="comment"># 将性别转换为数值</span></span><br><span class="line"><span class="comment"># 创建一个名为&quot;Gender&quot;的新列，用于存储性别的虚拟变量</span></span><br><span class="line"><span class="comment"># 将&quot;Gender&quot;列中的&quot;Male&quot;替换为0，&quot;Female&quot;替换为1，以创建性别的虚拟变量</span></span><br><span class="line">bmi[<span class="string">&#x27;Gender&#x27;</span>] = bmi[<span class="string">&#x27;Gender&#x27;</span>].<span class="built_in">map</span>(&#123;<span class="string">&#x27;Male&#x27;</span>:<span class="number">0</span>, <span class="string">&#x27;Female&#x27;</span>:<span class="number">1</span>&#125;)</span><br></pre></td></tr></table></figure><p>绘制热力图</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize = (<span class="number">6</span>, <span class="number">6</span>))</span><br><span class="line">heatmap = sns.heatmap(raw_bmi.corr(), vmin = -<span class="number">1</span>, vmax = <span class="number">1</span>, annot = <span class="literal">True</span>)  <span class="comment"># vmin和vmax参数指定颜色映射的范围为-1到1，annot参数为True表示在热力图上显示相关系数的数值</span></span><br><span class="line">heatmap.set_title(<span class="string">&#x27;BMI Correlation Heatmap&#x27;</span>, fontdict = &#123;<span class="string">&#x27;fontsize&#x27;</span> : <span class="number">18</span>&#125;, pad = <span class="number">12</span>)  <span class="comment"># 字体大小为18，标题与图像之间的间距为12像素</span></span><br></pre></td></tr></table></figure><p>绘制聚类图</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize = (<span class="number">4</span>, <span class="number">4</span>))</span><br><span class="line"><span class="comment"># 使用clustermap函数</span></span><br><span class="line">clustermap = sns.clustermap(bmi.corr(), vmin = -<span class="number">1</span>, vmax = <span class="number">1</span>, annot = <span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>计算VIF</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">X = bmi[[<span class="string">&#x27;Gender&#x27;</span>, <span class="string">&#x27;Height&#x27;</span>, <span class="string">&#x27;Weight&#x27;</span>]]</span><br><span class="line"></span><br><span class="line">vif_data = pd.DataFrame()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将自变量的名称添加到VIF数据框中</span></span><br><span class="line">vif_data[<span class="string">&quot;Feature&quot;</span>] = X.columns</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算每个自变量的VIF值</span></span><br><span class="line">vif_data[<span class="string">&quot;VIF&quot;</span>] = [variance_inflation_factor(X.values, i)</span><br><span class="line">                          <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(X.columns))]</span><br><span class="line">vif_data</span><br></pre></td></tr></table></figure><p>输出结果为:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">  Feature        VIF</span><br><span class="line">0  Gender   2.028864</span><br><span class="line">1  Height  11.623103</span><br><span class="line">2  Weight  10.688377</span><br></pre></td></tr></table></figure><p>可以发现，Height与weight之间的存在严重的共线性。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 分离特征和目标变量</span></span><br><span class="line">X = bmi.drop(columns=[<span class="string">&#x27;Index&#x27;</span>]) </span><br><span class="line">y = bmi[<span class="string">&#x27;Index&#x27;</span>] </span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">scaler = StandardScaler()</span><br><span class="line">X_train = scaler.fit_transform(X_train)</span><br><span class="line">X_test = scaler.transform(X_test)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression, Ridge</span><br><span class="line"></span><br><span class="line">lin_reg = LinearRegression()</span><br><span class="line">ridge_reg = Ridge(alpha=<span class="number">50.0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">lin_reg.fit(X_train, y_train)</span><br><span class="line">y_pred_lin = lin_reg.predict(X_test)</span><br><span class="line">ridge_reg.fit(X_train, y_train)</span><br><span class="line">y_pred_ridge = ridge_reg.predict(X_test)</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> r2_score, mean_squared_error</span><br><span class="line"></span><br><span class="line"><span class="comment"># 评估模型</span></span><br><span class="line">r2_lin = r2_score(y_test, y_pred_lin)</span><br><span class="line">mse_lin = mean_squared_error(y_test, y_pred_lin)</span><br><span class="line">r2_ridge = r2_score(y_test, y_pred_ridge)</span><br><span class="line">mse_ridge = mean_squared_error(y_test, y_pred_ridge)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;线性回归 R²: <span class="subst">&#123;r2_lin:<span class="number">.4</span>f&#125;</span>, 均方误差: <span class="subst">&#123;mse_lin:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;岭回归 R²: <span class="subst">&#123;r2_ridge:<span class="number">.4</span>f&#125;</span>, 均方误差: <span class="subst">&#123;mse_ridge:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><h1 id="Lasso回归"><a href="#Lasso回归" class="headerlink" title="Lasso回归"></a>Lasso回归</h1><p>其公式原理与岭回归基本相同，所调用函数的方法也基本相同</p><script type="math/tex; mode=display">min_\beta (\sum_{i=1}^n(y_i-X_i\beta)^2+\lambda\sum_{j=1}^p|\beta_j|)</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Lasso</span><br><span class="line"></span><br><span class="line">lasso_reg = Lasso(alpha=<span class="number">0.1</span>) </span><br><span class="line"></span><br><span class="line">lasso_reg.fit(X_train, y_train)</span><br><span class="line">y_pred_lasso = lasso_reg.predict(X_test)</span><br><span class="line">r2_lasso = r2_score(y_test, y_pred_lasso)</span><br><span class="line">mse_lasso = mean_squared_error(y_test, y_pred_lasso)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Lasso 回归 R²: <span class="subst">&#123;r2_lasso:<span class="number">.4</span>f&#125;</span>, 均方误差: <span class="subst">&#123;mse_lasso:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><p>三个模型的对比，经过微调后，对于岭回归，α适合选择为50附近，而Lasso回归则适合为0.1，其他情况会变得很糟糕，如果Lasso回归的系数过大，会导致选择特征过少，最后的误差很大，最后是三个模型的对比效果:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">线性回归 R²: 0.7963, 均方误差: 0.3394</span><br><span class="line">岭回归 R²: 0.8099, 均方误差: 0.3166</span><br><span class="line">Lasso 回归 R²: 0.8119, 均方误差: 0.3133</span><br></pre></td></tr></table></figure><p>会发现，岭回归对于解决共线性问题还是有比较好的提升的，但是由于bmi本身的特征变量比较少，所以相比于线性回归来说提升不大，同时在该场景下，Lasso回归的取值最好。</p><h1 id="学习曲线"><a href="#学习曲线" class="headerlink" title="学习曲线"></a>学习曲线</h1><p>绘制随着$\alpha$的不断变换，其Score最后的效果如何，可以用以下代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Ridge, Lasso</span><br><span class="line"></span><br><span class="line">alphas = np.logspace(-<span class="number">4</span>, <span class="number">0</span>, <span class="number">50</span>)</span><br><span class="line"></span><br><span class="line">coefs_lasso = []</span><br><span class="line">coefs_ridge = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对每个 alpha 训练 Lasso 和 Ridge 模型，并记录系数</span></span><br><span class="line"><span class="keyword">for</span> a <span class="keyword">in</span> alphas:</span><br><span class="line">    lasso = Lasso(alpha=a, max_iter=<span class="number">10000</span>)</span><br><span class="line">    ridge = Ridge(alpha=a)</span><br><span class="line">    </span><br><span class="line">    lasso.fit(X_train, y_train)</span><br><span class="line">    ridge.fit(X_train, y_train)</span><br><span class="line">    </span><br><span class="line">    coefs_lasso.append(lasso.coef_)</span><br><span class="line">    coefs_ridge.append(ridge.coef_)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">14</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">plt.plot(alphas, coefs_lasso)</span><br><span class="line">plt.xscale(<span class="string">&#x27;log&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;alpha&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Coefficients&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Lasso Coefficients Path&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;tight&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">plt.plot(alphas, coefs_ridge)</span><br><span class="line">plt.xscale(<span class="string">&#x27;log&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;alpha&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Coefficients&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Ridge Coefficients Path&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;tight&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>若是想查看拟合程度究竟如何，可以用以下代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]<span class="comment"># 避免中文乱码</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">y_pred_lasso = lasso_reg.predict(X_test)</span><br><span class="line">y_pred_ridge = ridge_reg.predict(X_test)</span><br><span class="line">y_pred_lin = lin_reg.predict(X_test)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">14</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">plt.scatter(y_test, y_pred_lasso, color=<span class="string">&#x27;blue&#x27;</span>, label=<span class="string">&#x27;Lasso 预测值&#x27;</span>)</span><br><span class="line">plt.plot([y_test.<span class="built_in">min</span>(), y_test.<span class="built_in">max</span>()], [y_test.<span class="built_in">min</span>(), y_test.<span class="built_in">max</span>()], color=<span class="string">&#x27;red&#x27;</span>, linestyle=<span class="string">&#x27;--&#x27;</span>, label=<span class="string">&#x27;理想拟合线&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;实际值&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;预测值&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Lasso 回归: 预测值 vs 实际值&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">plt.scatter(y_test, y_pred_ridge, color=<span class="string">&#x27;green&#x27;</span>, label=<span class="string">&#x27;Ridge 预测值&#x27;</span>)</span><br><span class="line">plt.plot([y_test.<span class="built_in">min</span>(), y_test.<span class="built_in">max</span>()], [y_test.<span class="built_in">min</span>(), y_test.<span class="built_in">max</span>()], color=<span class="string">&#x27;red&#x27;</span>, linestyle=<span class="string">&#x27;--&#x27;</span>, label=<span class="string">&#x27;理想拟合线&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;实际值&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;预测值&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Ridge 回归: 预测值 vs 实际值&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>模拟退火算法</title>
      <link href="/2024/08/04/%E6%A8%A1%E6%8B%9F%E9%80%80%E7%81%AB%E7%AE%97%E6%B3%95/"/>
      <url>/2024/08/04/%E6%A8%A1%E6%8B%9F%E9%80%80%E7%81%AB%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h1 id="模拟退火算法"><a href="#模拟退火算法" class="headerlink" title="模拟退火算法"></a>模拟退火算法</h1><p>模拟退火算法（Simulated Annealing, SA）是一种基于概率的全局优化算法，其核心思想是核心思想是通过在解空间中接受可能不是全局最优解的解，以一定的概率接受较差的解，逐步降低接受较差解的概率，从而在整个解空间中搜索到全局最优解。</p><h2 id="由来"><a href="#由来" class="headerlink" title="由来"></a>由来</h2><p>模拟退火算法的概念源自物理学中的退火过程，首次提出于1983年，由S. Kirkpatrick、C. D. Gelatt和M. P. Vecchi在他们的论文《Optimization by Simulated Annealing》中详细介绍。退火是指将金属加热到高温后缓慢冷却，使其内部结构达到稳定的低能态，从而增强材料的韧性和硬度。模拟退火算法通过模仿这一过程，在求解优化问题时逐步降低“温度”，以跳出局部最优解，寻找全局最优解。</p><h2 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h2><p>生成初始解，将其定作为当前最优解，开始对旧解进行随机小幅度干扰，得到新解，判断新解是否是当前最优解，若是则接受新解，若不是则按照Metropolis准则接受新解，如此循环直至最大迭代次数，如果符合条件则输出，若不符合条件则缓慢降低温度并且重置迭代次数。</p><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">T0 = <span class="number">1000</span>  <span class="comment"># 初始温度 初始温度越高，算法在初期的搜索空间越大</span></span><br><span class="line">T_min = <span class="number">1</span>  <span class="comment"># 最低温度 最低温度越低，算法更有可能找到全局最优解，但计算时间也可能增加。一般设定为一个较小的正数。</span></span><br><span class="line">alpha = <span class="number">0.9</span>  <span class="comment"># 降温系数 越接近1，降温越慢，但精度更高。一般为0.8至0.99。</span></span><br><span class="line">max_iter = <span class="number">1000</span>  <span class="comment"># 每次温度下的最大迭代次数</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">objective_function</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> x**<span class="number">2</span> + <span class="number">10</span> * np.sin(x)</span><br><span class="line"></span><br><span class="line">current_solution = np.random.uniform(-<span class="number">10</span>, <span class="number">10</span>)</span><br><span class="line">current_value = objective_function(current_solution)</span><br><span class="line">T = T0</span><br><span class="line">best_solution = current_solution</span><br><span class="line">best_value = current_value</span><br><span class="line"> </span><br><span class="line"><span class="keyword">while</span> T &gt; T_min:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(max_iter):</span><br><span class="line">        new_solution = current_solution + np.random.uniform(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        new_value = objective_function(new_solution)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> new_value &lt; current_value:</span><br><span class="line">            current_solution = new_solution</span><br><span class="line">            current_value = new_value</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            p = np.exp(-(new_value - current_value) / T)</span><br><span class="line">            <span class="keyword">if</span> np.random.rand() &lt; p:</span><br><span class="line">                current_solution = new_solution</span><br><span class="line">                current_value = new_value</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> current_value &lt; best_value:</span><br><span class="line">            best_solution = current_solution</span><br><span class="line">            best_value = current_value</span><br><span class="line"></span><br><span class="line">    T = T * alpha</span><br><span class="line"> </span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Best solution: <span class="subst">&#123;best_solution&#125;</span>, Best value: <span class="subst">&#123;best_value&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><ul><li>全局搜索能力强，更容易跳出局部解。</li><li>但是计算效率低下，需要大量的随机扰动和搜索来寻找解。</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 智能优化算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>粒子群优化算法</title>
      <link href="/2024/08/04/%E7%B2%92%E5%AD%90%E7%BE%A4%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/"/>
      <url>/2024/08/04/%E7%B2%92%E5%AD%90%E7%BE%A4%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h1 id="粒子群优化算法"><a href="#粒子群优化算法" class="headerlink" title="粒子群优化算法"></a>粒子群优化算法</h1><h2 id="由来"><a href="#由来" class="headerlink" title="由来"></a>由来</h2><p>粒子群优化（Particle Swarm Optimization，PSO）是一种源于群体智能的优化算法。它模拟鸟群觅食的行为，通过个体之间的协作和信息共享来寻找问题的最优解。PSO算法的基本思想是通过一群粒子在搜索空间中的相互作用，找到全局最优解。</p><p>鸟群在整个搜寻过程中，通过相互传递位置信息，让其他鸟了解自己的位置，通过这种协作方式来判断自己找到的是否是最优解，同时也将最优解的信息传递给整个鸟群，最终使得整个鸟群聚集在食物源周围，即找到了最优解。</p><p>在粒子群优化（PSO）算法中，每个优化问题的解在搜索空间中都相当于一只鸟，我们称之为“粒子”。所有粒子都有一个由被优化的函数决定的适应值（fitness value），每个粒子还有速度来决定它们飞行的方向和距离。粒子们通过跟随当前的最优粒子在解空间中搜索最优解。</p><p>PSO算法初始化时生成一群随机粒子（随机解），然后通过迭代找到最优解。在每次迭代中，粒子通过跟踪两个“极值”来更新自己。第一个极值是粒子自身找到的最优解，称为个体极值（pBest）；另一个极值是整个种群目前找到的最优解，称为全局极值（gBest）。在这种情况下，在所有邻居中的极值称为局部极值。</p><h2 id="理论公式"><a href="#理论公式" class="headerlink" title="理论公式"></a>理论公式</h2><script type="math/tex; mode=display">v_{i}(t+1) = \omega v_{i}(t) + c_1 r_1 (pbest_{i} - x_{i}(t)) + c_2 r_2 (gbest - x_{i}(t))</script><p>其中，$v_i$是粒子的速度，$r_1,r_2$为随机数，$c_1,c_2$为学习因子，一般均为2，$pbest_i$是个人寻得的最优解，$gbest$是全局寻得的最优解。$x_i$​是粒子当前的位置。</p><script type="math/tex; mode=display">x_i = x_i + v_i</script><p>$\omega$称为惯性因子，为非负数，当$\omega$较大时，全局寻优的能力较强，而局部寻优的能力较弱，当$\omega$较小时，全局寻优能力较弱，而局部寻优能力较强。$\omega$可以是一个预先设定好的值，也可以随着优化过程而逐渐变化，常见的一种方式叫做线性递减权值策略(Linearly Decreasing weigh，LDW)，公式为：</p><script type="math/tex; mode=display">\omega = (\omega_{ini}-\omega_{end})(G_k-g)/G_{k}+\omega_{end}</script><h2 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h2><p>先随机初始化一群粒子，开始计算每个粒子处的目标值，然后得到每个粒子的个体最优值$pbest_i$与整个群体的最优值$gbest = min{pbest_i}$，判断是否满足收敛条件，若满足则输出最优解和迭代次数，否则更新每个粒子的位置与速度矢量，如此反复迭代。</p><h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p>在数学最优化中，<strong>Rosenbrock函数</strong>是一个用来测试最优化算法性能的非凸函数，由Howard Harry Rosenbrock在1960年提出。也称为<strong>Rosenbrock山谷</strong>或<strong>Rosenbrock香蕉函数</strong>，也简称为<strong>香蕉函数</strong>。</p><p>其全局最小值位于(1,1,1,…,1)，解为0。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Particle</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, bounds</span>):</span><br><span class="line">        self.position = np.random.uniform(bounds[<span class="number">0</span>], bounds[<span class="number">1</span>], dim)</span><br><span class="line">        self.velocity = np.random.uniform(-<span class="number">1</span>, <span class="number">1</span>, dim)</span><br><span class="line">        self.best_position = self.position.copy()</span><br><span class="line">        self.best_value = <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update_velocity</span>(<span class="params">self, global_best_position, w, c1, c2</span>):</span><br><span class="line">        r1 = np.random.rand(self.position.shape[<span class="number">0</span>])</span><br><span class="line">        r2 = np.random.rand(self.position.shape[<span class="number">0</span>])</span><br><span class="line">        cognitive_velocity = c1 * r1 * (self.best_position - self.position)</span><br><span class="line">        social_velocity = c2 * r2 * (global_best_position - self.position)</span><br><span class="line">        self.velocity = w * self.velocity + cognitive_velocity + social_velocity</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update_position</span>(<span class="params">self, bounds</span>):</span><br><span class="line">        self.position += self.velocity</span><br><span class="line">        self.position = np.clip(self.position, bounds[<span class="number">0</span>], bounds[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Rosenbrock函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">rosenbrock</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> np.<span class="built_in">sum</span>(<span class="number">100.0</span>*(x[<span class="number">1</span>:] - x[:-<span class="number">1</span>]**<span class="number">2.0</span>)**<span class="number">2.0</span> + (<span class="number">1</span> - x[:-<span class="number">1</span>])**<span class="number">2.0</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">pso</span>(<span class="params">objective_function, dim, bounds, num_particles, max_iter, w, c1, c2</span>):</span><br><span class="line">    particles = [Particle(dim, bounds) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_particles)]</span><br><span class="line">    global_best_value = <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)</span><br><span class="line">    global_best_position = <span class="literal">None</span></span><br><span class="line">    fitness_values = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> iteration <span class="keyword">in</span> <span class="built_in">range</span>(max_iter):</span><br><span class="line">        <span class="keyword">for</span> particle <span class="keyword">in</span> particles:</span><br><span class="line">            fitness_value = objective_function(particle.position)</span><br><span class="line">            <span class="keyword">if</span> fitness_value &lt; particle.best_value:</span><br><span class="line">                particle.best_value = fitness_value</span><br><span class="line">                particle.best_position = particle.position.copy()</span><br><span class="line">            <span class="keyword">if</span> fitness_value &lt; global_best_value:</span><br><span class="line">                global_best_value = fitness_value</span><br><span class="line">                global_best_position = particle.position.copy()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> particle <span class="keyword">in</span> particles:</span><br><span class="line">            particle.update_velocity(global_best_position, w, c1, c2)</span><br><span class="line">            particle.update_position(bounds)</span><br><span class="line"></span><br><span class="line">        fitness_values.append(global_best_value)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> global_best_value &lt; <span class="number">1e-6</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;Converged at iteration <span class="subst">&#123;iteration&#125;</span>&#x27;</span>)</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> global_best_position, global_best_value, fitness_values</span><br><span class="line"></span><br><span class="line">dim = <span class="number">5</span> <span class="comment"># 维度</span></span><br><span class="line">bounds = [-<span class="number">5</span>, <span class="number">5</span>] <span class="comment"># 定义域范围</span></span><br><span class="line">num_particles = <span class="number">200</span> <span class="comment"># 粒子数目</span></span><br><span class="line">max_iter = <span class="number">5000</span> <span class="comment"># 最大迭代次数</span></span><br><span class="line">w = <span class="number">0.5</span> <span class="comment"># 惯性权重</span></span><br><span class="line">c1 = <span class="number">2</span> <span class="comment"># 认知学习因子</span></span><br><span class="line">c2 = <span class="number">2</span> <span class="comment"># 社会学习因子</span></span><br><span class="line"></span><br><span class="line">best_position, best_value, fitness_values = pso(rosenbrock, dim, bounds, num_particles, max_iter, w, c1, c2)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Best Position: <span class="subst">&#123;best_position&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Best Value: <span class="subst">&#123;best_value&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.plot(fitness_values)</span><br><span class="line">plt.title(<span class="string">&#x27;Fitness Value over Iterations&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Iterations&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Fitness Value&#x27;</span>)</span><br><span class="line">plt.yscale(<span class="string">&#x27;log&#x27;</span>) <span class="comment"># 使用对数坐标</span></span><br><span class="line">plt.grid(<span class="literal">True</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[best_position, best_value]</span> = <span class="title">pso</span><span class="params">(objective_function, dim, bounds, num_particles, max_iter, w, c1, c2)</span></span></span><br><span class="line">    position = <span class="built_in">repmat</span>(bounds(<span class="number">1</span>,:), num_particles, <span class="number">1</span>) + <span class="built_in">repmat</span>((bounds(<span class="number">2</span>,:) - bounds(<span class="number">1</span>,:)), num_particles, <span class="number">1</span>) .* <span class="built_in">rand</span>(num_particles, dim);</span><br><span class="line">    velocity = <span class="built_in">rand</span>(num_particles, dim);</span><br><span class="line">    best_position = position;</span><br><span class="line">    best_value = arrayfun(objective_function, best_position);</span><br><span class="line">    [global_best_value, best_idx] = <span class="built_in">min</span>(best_value);</span><br><span class="line">    global_best_position = best_position(best_idx, :);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> iter = <span class="number">1</span>:max_iter</span><br><span class="line">        <span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:num_particles</span><br><span class="line">            fitness_value = objective_function(position(<span class="built_in">i</span>, :));</span><br><span class="line">            <span class="keyword">if</span> fitness_value &lt; best_value(<span class="built_in">i</span>)</span><br><span class="line">                best_value(<span class="built_in">i</span>) = fitness_value;</span><br><span class="line">                best_position(<span class="built_in">i</span>, :) = position(<span class="built_in">i</span>, :);</span><br><span class="line">            <span class="keyword">end</span></span><br><span class="line">            <span class="keyword">if</span> fitness_value &lt; global_best_value</span><br><span class="line">                global_best_value = fitness_value;</span><br><span class="line">                global_best_position = position(<span class="built_in">i</span>, :);</span><br><span class="line">            <span class="keyword">end</span></span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:num_particles</span><br><span class="line">            r1 = <span class="built_in">rand</span>(<span class="number">1</span>, dim);</span><br><span class="line">            r2 = <span class="built_in">rand</span>(<span class="number">1</span>, dim);</span><br><span class="line">            cognitive_velocity = c1 * r1 .* (best_position(<span class="built_in">i</span>, :) - position(<span class="built_in">i</span>, :));</span><br><span class="line">            social_velocity = c2 * r2 .* (global_best_position - position(<span class="built_in">i</span>, :));</span><br><span class="line">            velocity(<span class="built_in">i</span>, :) = w * velocity(<span class="built_in">i</span>, :) + cognitive_velocity + social_velocity;</span><br><span class="line">            position(<span class="built_in">i</span>, :) = position(<span class="built_in">i</span>, :) + velocity(<span class="built_in">i</span>, :);</span><br><span class="line">            position(<span class="built_in">i</span>, :) = <span class="built_in">max</span>(<span class="built_in">min</span>(position(<span class="built_in">i</span>, :), bounds(<span class="number">2</span>, :)), bounds(<span class="number">1</span>, :));</span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> global_best_value &lt; <span class="number">1e-6</span></span><br><span class="line">            fprintf(<span class="string">&#x27;Converged at iteration %d\n&#x27;</span>, iter);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">    best_position = global_best_position;</span><br><span class="line">    best_value = global_best_value;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">dim = <span class="number">2</span>;</span><br><span class="line">bounds = [<span class="number">-10</span> <span class="number">10</span>; <span class="number">-10</span> <span class="number">10</span>];</span><br><span class="line">num_particles = <span class="number">30</span>;</span><br><span class="line">max_iter = <span class="number">100</span>;</span><br><span class="line">w = <span class="number">0.5</span>;</span><br><span class="line">c1 = <span class="number">1.5</span>;</span><br><span class="line">c2 = <span class="number">1.5</span>;</span><br><span class="line"></span><br><span class="line">objective_function = @(x) sum(x.^<span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">[best_position, best_value] = pso(objective_function, dim, bounds, num_particles, max_iter, w, c1, c2);</span><br><span class="line"></span><br><span class="line"><span class="built_in">disp</span>(<span class="string">&#x27;Best Position:&#x27;</span>);</span><br><span class="line"><span class="built_in">disp</span>(best_position);</span><br><span class="line"><span class="built_in">disp</span>(<span class="string">&#x27;Best Value:&#x27;</span>);</span><br><span class="line"><span class="built_in">disp</span>(best_value);</span><br></pre></td></tr></table></figure><p>以上分别是python和matlab代码，python代码运行后结果为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Converged at iteration 1544</span><br><span class="line">Best Position: [0.99989184 0.99978585 0.99957005 0.99913691 0.99827794]</span><br><span class="line">Best Value: 9.903569513275998e-07</span><br></pre></td></tr></table></figure><p>可以看到效果良好，非常接近于全局最优解。</p><h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><ul><li>通用性强。收敛速度快，更容易全局收敛。</li></ul><ul><li>易陷入局部最优</li><li>搜索速度不太稳定，有时会出现迭代次数较多的情况</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 智能优化算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>三大相关系数检验</title>
      <link href="/2024/08/02/%E4%B8%89%E5%A4%A7%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0%E6%A3%80%E9%AA%8C/"/>
      <url>/2024/08/02/%E4%B8%89%E5%A4%A7%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0%E6%A3%80%E9%AA%8C/</url>
      
        <content type="html"><![CDATA[<h2 id="三大相关系数"><a href="#三大相关系数" class="headerlink" title="三大相关系数"></a>三大相关系数</h2><p>三大相关系数反应的是两个变量之间变化的趋势方向及程度，取值范围在-1到-+1之间，0代表不相关，正值代表正相关，负值代表负相关，绝对值越大相关性越强,可用来衡量两个变量之间的相关性的大小。</p><p>相关系数只是用来来衡量两个变量线性相关程度的指标；即我必须<strong>先确认这两个变量是线性相关的</strong>，然后相关系数才能告诉数据的相关程度，可先通过数据可视化来确定。</p><h3 id="皮尔斯相关系数-Pearson-Correlation-Coefficient"><a href="#皮尔斯相关系数-Pearson-Correlation-Coefficient" class="headerlink" title="皮尔斯相关系数(Pearson Correlation Coefficient)"></a>皮尔斯相关系数(Pearson Correlation Coefficient)</h3><p>实验数据通常假设是成对的来自于正态分布的总体。得到皮尔逊相关性系数后，通常会用t检验等方法进行皮尔逊相关性系数检验。<br>实验数据间差距不能太大。皮尔逊相关性系数受异常值影响较大，每组样本之间是独立抽样的。</p><p><strong>零假设（H0）</strong>：变量之间没有线性关系，即皮尔斯相关系数 r=0。</p><p><strong>备择假设（H1）</strong>：变量之间有线性关系，即皮尔斯相关系数 r≠0。</p><p>公式为:</p><script type="math/tex; mode=display">r = \frac{\sum (X_i - \bar{X})(Y_i - \bar{Y})}{\sqrt{\sum (X_i - \bar{X})^2 \sum (Y_i - \bar{Y})^2}}</script><script type="math/tex; mode=display">t = r\sqrt{\frac{n-2}{1-r^2}}</script><p>根据自由度 df=n−2 查找 t 分布表确定临界值，或直接计算 p 值。如果 p 值小于显著性水平 α（如0.05），则拒绝零假设，认为变量之间存在显著的线性关系。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br><span class="line"></span><br><span class="line">x = [<span class="number">10</span>, <span class="number">20</span>, <span class="number">30</span>, <span class="number">40</span>, <span class="number">50</span>]</span><br><span class="line">y = [<span class="number">12</span>, <span class="number">24</span>, <span class="number">33</span>, <span class="number">45</span>, <span class="number">51</span>]</span><br><span class="line"><span class="comment"># 判断x,y是否是线性相关</span></span><br><span class="line">plt.scatter(x, y)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;X&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Y&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Scatter Plot&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">correlation_coefficient, p_value = stats.pearsonr(x, y)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;皮尔斯相关系数:&quot;</span>, correlation_coefficient)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;p值:&quot;</span>, p_value)</span><br><span class="line"></span><br><span class="line">alpha = <span class="number">0.05</span></span><br><span class="line"><span class="keyword">if</span> p_value &lt; alpha:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;拒绝零假设，变量之间存在显著的线性关系。&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;不拒绝零假设，变量之间没有显著的线性关系。&quot;</span>)</span><br></pre></td></tr></table></figure><p>只有当数据是连续数据，且符合正态分布与线性关系才可以用，先绘制散点图，当数据是线性时，再计算皮尔斯相关系数，经过正态分布检验后，再用假设检验判断显著性。</p><h3 id="正态分布检验"><a href="#正态分布检验" class="headerlink" title="正态分布检验"></a>正态分布检验</h3><h4 id="Jarque-Bera-检验-JB-检验"><a href="#Jarque-Bera-检验-JB-检验" class="headerlink" title="Jarque-Bera 检验 (JB 检验)"></a>Jarque-Bera 检验 (JB 检验)</h4><p><strong>适用条件</strong>：大样本(n&gt;30)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> jarque_bera</span><br><span class="line"></span><br><span class="line"><span class="comment"># 假设你的数据为 y</span></span><br><span class="line">statistic, p_value = jarque_bera(y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;JB 检验统计量:&#x27;</span>, statistic)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;p 值:&#x27;</span>, p_value)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> p_value &gt; <span class="number">0.05</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;数据符合正态分布&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;数据不符合正态分布&quot;</span>)</span><br></pre></td></tr></table></figure><h4 id="Shapiro-Wilk-检验"><a href="#Shapiro-Wilk-检验" class="headerlink" title="Shapiro-Wilk 检验"></a>Shapiro-Wilk 检验</h4><p><strong>适用条件</strong>：用于检验数据是否符合正态分布，适用于小样本数据（通常 n &lt; 50）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> shapiro</span><br><span class="line"></span><br><span class="line">statistic, p_value = shapiro(y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Shapiro-Wilk 检验统计量:&#x27;</span>, statistic)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;p 值:&#x27;</span>, p_value)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> p_value &gt; <span class="number">0.05</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;数据符合正态分布&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;数据不符合正态分布&quot;</span>)</span><br></pre></td></tr></table></figure><h4 id="Q-Q-图-Quantile-Quantile-Plot"><a href="#Q-Q-图-Quantile-Quantile-Plot" class="headerlink" title="Q-Q 图 (Quantile-Quantile Plot)"></a>Q-Q 图 (Quantile-Quantile Plot)</h4><p><strong>适用条件</strong>：数据量特别大</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> scipy.stats <span class="keyword">as</span> stats</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">stats.probplot(y, dist=<span class="string">&quot;norm&quot;</span>, plot=plt)</span><br><span class="line">plt.title(<span class="string">&#x27;Q-Q Plot&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h3 id="Spearman等级相关系数"><a href="#Spearman等级相关系数" class="headerlink" title="Spearman等级相关系数"></a>Spearman等级相关系数</h3><p>Spearman等级相关系数（Spearman’s rank correlation coefficient）是非参数统计的一种，用于测量两个变量的单调关系。它基于两个变量的排序，而不是原始数据。</p><p>小样本（n<30）:查临界值表，大样本情况（n > 30）: P值法</p><script type="math/tex; mode=display">r_s = 1 - \frac{6 \sum d_i^2}{n(n^2 - 1)}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br><span class="line"></span><br><span class="line">x = [<span class="number">10</span>, <span class="number">20</span>, <span class="number">30</span>, <span class="number">40</span>, <span class="number">50</span>, <span class="number">60</span>, <span class="number">70</span>, <span class="number">80</span>, <span class="number">90</span>, <span class="number">100</span>]</span><br><span class="line">y = [<span class="number">15</span>, <span class="number">30</span>, <span class="number">25</span>, <span class="number">35</span>, <span class="number">40</span>, <span class="number">60</span>, <span class="number">65</span>, <span class="number">70</span>, <span class="number">85</span>, <span class="number">95</span>]</span><br><span class="line"></span><br><span class="line">rho, p_value = stats.spearmanr(x, y)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Spearman相关系数:&quot;</span>, rho)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;p值:&quot;</span>, p_value)</span><br></pre></td></tr></table></figure><h3 id="Kendall等级相关系数"><a href="#Kendall等级相关系数" class="headerlink" title="Kendall等级相关系数"></a>Kendall等级相关系数</h3><p>Kendall等级相关系数（Kendall’s tau coefficient）也是一种非参数统计，用于测量两个变量之间的依赖关系。其计算公式如下：</p><script type="math/tex; mode=display">\tau = \frac{(C - D)}{\sqrt{(C + D + T) \cdot (C + D + U)}}</script><p>适用于：</p><ul><li>数据不符合正态分布</li><li>数据存在显著的异常值</li><li>变量之间的关系可能是非线性的</li><li>数据量较小的情况下，适用性较高</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br><span class="line"></span><br><span class="line">x = [<span class="number">10</span>, <span class="number">20</span>, <span class="number">30</span>, <span class="number">40</span>, <span class="number">50</span>, <span class="number">60</span>, <span class="number">70</span>, <span class="number">80</span>, <span class="number">90</span>, <span class="number">100</span>]</span><br><span class="line">y = [<span class="number">15</span>, <span class="number">30</span>, <span class="number">25</span>, <span class="number">35</span>, <span class="number">40</span>, <span class="number">60</span>, <span class="number">65</span>, <span class="number">70</span>, <span class="number">85</span>, <span class="number">95</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算Kendall相关系数和p值</span></span><br><span class="line">tau, p_value = stats.kendalltau(x, y)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Kendall相关系数:&quot;</span>, tau)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;p值:&quot;</span>, p_value)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 统计分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>t均值检验</title>
      <link href="/2024/08/02/t%E5%9D%87%E5%80%BC%E6%A3%80%E9%AA%8C/"/>
      <url>/2024/08/02/t%E5%9D%87%E5%80%BC%E6%A3%80%E9%AA%8C/</url>
      
        <content type="html"><![CDATA[<h1 id="t均值检验"><a href="#t均值检验" class="headerlink" title="t均值检验"></a>t均值检验</h1><h2 id="假设检验"><a href="#假设检验" class="headerlink" title="假设检验"></a>假设检验</h2><h3 id="1-假设检验"><a href="#1-假设检验" class="headerlink" title="1.假设检验"></a>1.假设检验</h3><p>假设检验(Hypothesis Testing)，又称统计假设检验，是用来判断样本与样本、样本与总体的差异是由抽样误差引起还是本质差别造成的统计推断方法。</p><p><strong>零假设(原假设）H0</strong>：指观察到的现象仅由随机抽样的误差所导致的，表示两个变量之间没有关系。</p><p><strong>备择假设H1</strong>：指原假设的否定，是我们想要通过样本数据来提供证据拒绝原假设，是我们想要的。</p><p><strong>P值</strong>：用来检验H0成立的概率。</p><div class="table-container"><table><thead><tr><th>P值</th><th>巧合概率</th><th>对无效假设</th><th>统计意义</th></tr></thead><tbody><tr><td>P&gt;0.05</td><td>巧合可能性大于5％</td><td>不能否定H0</td><td>两组数据差别无显著意义</td></tr><tr><td>P&lt;0.05</td><td>巧合可能性小于5％</td><td>可以否定H0</td><td>两组数据差别有显著意义</td></tr><tr><td>p&lt;0.01</td><td>巧合可能性小于1％</td><td>可以否定H0</td><td>两组数据差别有非常显著意义</td></tr></tbody></table></div><h3 id="2-两种错误"><a href="#2-两种错误" class="headerlink" title="2.两种错误"></a>2.两种错误</h3><p><strong>第一类错误</strong>：指原假设H0成立，却错误地拒绝了原假设。指即使小于显著性水平α来拒绝原假设，依旧有α的概率犯错，那么有1-α的概率正确，也称真阴性或特异性。</p><p><strong>第二类错误</strong>：指备择假设H1成立，不能拒绝原假设h0的错误概率，概率为β，则真正正确的概率为1-β，也称真阳性或灵敏度。</p><h3 id="3-三种检验"><a href="#3-三种检验" class="headerlink" title="3.三种检验"></a>3.三种检验</h3><p><strong>左尾检验</strong>：用于检验样本数据是否显著小于假设的总体参数值，如果计算得到的检验统计量小于临界值，则拒绝零假设，如果计算得到的检验统计量大于等于临界值，则不拒绝零假设。即原假设 H0:μ=0，备择假设H1:μ&lt;0。</p><p><strong>右尾检验</strong>：用于检验样本数据是否显著大于假设的总体参数值，如果计算得到的检验统计量大于临界值，则拒绝零假设，如果计算得到的检验统计量小于等于临界值，则不拒绝零假设。即原假设 H0:μ=0，备择假设H1:μ＞0。</p><p><strong>双尾检验</strong>：用于检验样本数据是否显著不同于假设的总体参数值，无论是显著大于还是显著小于，即原假设 H0:μ=0，备择假设H1:μ≠0。</p><h2 id="T检验"><a href="#T检验" class="headerlink" title="T检验"></a>T检验</h2><p><strong>t检验</strong>，又叫学生t检验，用于统计量服从正态分布，但方差未知的情况，前提是样本服从或近似服从正态分布（可利用数据变换，如取对，开根，倒数），如果不满足正态分布，则只能用非参数检验。</p><h3 id="1-单样本t检验-One-sample-t-test"><a href="#1-单样本t检验-One-sample-t-test" class="headerlink" title="1.单样本t检验(One-sample t-test)"></a>1.单样本t检验(One-sample t-test)</h3><p>检验单样本的均值与某一已知值是否有显著差异，只对一组样本进行检验。</p><p>要求总体方差未知，并且数据服从或近似服从正态分布。</p><p>比如从某高中抽几位近视学生，检验其近视度数是否高于全校学生近视平均水平。</p><p><strong>H0:样本均值与已知值相同，H1:样本均值与已知值不同</strong>，公式为：</p><script type="math/tex; mode=display">t = \frac{\overline x-μ_0}{s/\sqrt{n}}</script><p>假设我们想要检验某学校一组学生的考试成绩是否显著高于全国平均成绩。已知全国平均成绩μ0为 75 分。一组学生的考试成绩如下： 78,82,75,79,83,76,81,77,80,74。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br><span class="line"></span><br><span class="line">data = [<span class="number">78</span>, <span class="number">82</span>, <span class="number">75</span>, <span class="number">79</span>, <span class="number">83</span>, <span class="number">76</span>, <span class="number">81</span>, <span class="number">77</span>, <span class="number">80</span>, <span class="number">74</span>]</span><br><span class="line"></span><br><span class="line">sample_mean = np.mean(data)</span><br><span class="line">sample_std = np.std(data, ddof=<span class="number">1</span>)  <span class="comment"># ddof=1表示使用样本标准差</span></span><br><span class="line">n = <span class="built_in">len</span>(data)</span><br><span class="line">mu_0 = <span class="number">75</span>  <span class="comment"># 平均成绩</span></span><br><span class="line"></span><br><span class="line">t_statistic = (sample_mean - mu_0) / (sample_std / np.sqrt(n))</span><br><span class="line"></span><br><span class="line">p_value = stats.t.sf(np.<span class="built_in">abs</span>(t_statistic), df=n-<span class="number">1</span>) * <span class="number">2</span>  <span class="comment"># 双尾检验</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;样本平均值:&quot;</span>, sample_mean)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;样本标准差:&quot;</span>, sample_std)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;t值:&quot;</span>, t_statistic)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;p值:&quot;</span>, p_value)</span><br><span class="line"></span><br><span class="line">alpha = <span class="number">0.05</span></span><br><span class="line"><span class="keyword">if</span> p_value &lt; alpha:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;拒绝零假设，样本平均成绩显著不同于全国平均成绩。&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;不拒绝零假设，样本平均成绩与全国平均成绩没有显著差异。&quot;</span>)</span><br></pre></td></tr></table></figure><p>其中，<code>stats.t.sf</code> 是SciPy库中的函数，代表t分布的生存函数（survival function），也就是右尾概率。对于双尾检验，需要考虑t分布两端的概率。因此计算出右尾的概率后，将其乘以2以得到双尾的p值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">p_value = stats.t.cdf(t_statistic, df=n-<span class="number">1</span>)  <span class="comment"># 左尾检验</span></span><br><span class="line">p_value = stats.t.sf(t_statistic, df=n-<span class="number">1</span>)  <span class="comment"># 右尾检验</span></span><br></pre></td></tr></table></figure><h3 id="2-配对样本t检验（Paired-sample-t-test）"><a href="#2-配对样本t检验（Paired-sample-t-test）" class="headerlink" title="2.配对样本t检验（Paired-sample t-test）"></a>2.配对样本t检验（Paired-sample t-test）</h3><p>检验在两次不同条件下来自用一组观察对象的两组样本是否具有相同的均值,要求总体方差相等并且数据服从或近似服从正态分布，例如比较治疗前后的效果，或者比较两种不同测试方法的结果。</p><p>假设我们想要检验某种治疗方法在治疗前后是否对病人的血压有显著影响。我们有一组病人在治疗前后的血压数据。</p><p>病人治疗前后的血压数据如下：</p><ul><li>治疗前：[120, 130, 115, 140, 125, 135, 128, 150, 133, 145]</li><li>治疗后：[115, 128, 110, 138, 122, 130, 125, 145, 130, 140]</li></ul><p><strong>零假设（H0)</strong>：治疗前后的平均血压没有显著差异，即 $H_0:μ_d=0$（$μ_d$ 是差值的平均值）。</p><p><strong>备择假设（H1)</strong>：治疗前后的平均血压有显著差异，即 $H1:μ_d≠0 $</p><p>查找t分布表，使用显著性水平α/2=0.025和自由度df=n−1=9，得到临界值大约为 ±2.262。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br><span class="line"></span><br><span class="line">before_treatment = [<span class="number">120</span>, <span class="number">130</span>, <span class="number">115</span>, <span class="number">140</span>, <span class="number">125</span>, <span class="number">135</span>, <span class="number">128</span>, <span class="number">150</span>, <span class="number">133</span>, <span class="number">145</span>]</span><br><span class="line">after_treatment = [<span class="number">115</span>, <span class="number">128</span>, <span class="number">110</span>, <span class="number">138</span>, <span class="number">122</span>, <span class="number">130</span>, <span class="number">125</span>, <span class="number">145</span>, <span class="number">130</span>, <span class="number">140</span>]</span><br><span class="line"></span><br><span class="line">differences = np.array(before_treatment) - np.array(after_treatment)</span><br><span class="line"></span><br><span class="line">mean_diff = np.mean(differences)</span><br><span class="line">std_diff = np.std(differences, ddof=<span class="number">1</span>)</span><br><span class="line">n = <span class="built_in">len</span>(differences)</span><br><span class="line"></span><br><span class="line">t_statistic = mean_diff / (std_diff / np.sqrt(n))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算p值（双尾检验）</span></span><br><span class="line">p_value = stats.t.sf(np.<span class="built_in">abs</span>(t_statistic), df=n-<span class="number">1</span>) * <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;差值的平均值:&quot;</span>, mean_diff)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;差值的标准差:&quot;</span>, std_diff)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;t值:&quot;</span>, t_statistic)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;p值:&quot;</span>, p_value)</span><br><span class="line"></span><br><span class="line">alpha = <span class="number">0.05</span></span><br><span class="line"><span class="keyword">if</span> p_value &lt; alpha:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;拒绝零假设，治疗前后的平均血压有显著差异。&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;不拒绝零假设，治疗前后的平均血压没有显著差异。&quot;</span>)</span><br></pre></td></tr></table></figure><h3 id="3-独立双样本t检验-（Independent-two-sample-t-test）"><a href="#3-独立双样本t检验-（Independent-two-sample-t-test）" class="headerlink" title="3.独立双样本t检验 （Independent two-sample t-test）"></a>3.独立双样本t检验 （Independent two-sample t-test）</h3><p>检验两对独立的正态数据或近似正态的样本的均值是否相等，要求两样本独立且数据服从或近似服从正态分布。</p><p>进行独立双样本t检验之前，应该进行方差齐性检验（homogeneity of variance test），即检查两组样本的总体方差是否相同。方差齐性检验本身也是一种假设检验，通用的方法有Hartley检验、Bartlett检验和Leyene检验。</p><p>其中，合并标准差$S_p$与$t$计算公式为：</p><script type="math/tex; mode=display">S_p = \sqrt{\frac{(n_1-1)s_1^2+(n_2-1)s_2^2}{n_1+n_2-2}}\\t = \frac{\bar x_1-\bar x_2}{S_p\sqrt{1/n_1+1/n_2}}</script><p>假设检验两种不同教学方法对学生考试成绩的影响是否有显著差异。有两组学生的考试成绩数据，分别接受了两种不同的教学方法。两组学生的考试成绩如下：</p><ul><li>教学方法A组：85,90,88,92,85,87,91,89,90,86</li><li>教学方法B组：80,78,82,76,79,81,77,83,80,78</li></ul><p><strong>零假设（H0）</strong>：两组的平均成绩没有显著差异，即 $H_0:μ_1=μ_2$。</p><p><strong>备择假设（H1）</strong>：两组的平均成绩有显著差异，即 $H_0:μ_1≠μ_2$。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br><span class="line"></span><br><span class="line">group_a = [<span class="number">85</span>, <span class="number">90</span>, <span class="number">88</span>, <span class="number">92</span>, <span class="number">85</span>, <span class="number">87</span>, <span class="number">91</span>, <span class="number">89</span>, <span class="number">90</span>, <span class="number">86</span>]</span><br><span class="line">group_b = [<span class="number">80</span>, <span class="number">78</span>, <span class="number">82</span>, <span class="number">76</span>, <span class="number">79</span>, <span class="number">81</span>, <span class="number">77</span>, <span class="number">83</span>, <span class="number">80</span>, <span class="number">78</span>]</span><br><span class="line"></span><br><span class="line">mean_a = np.mean(group_a)</span><br><span class="line">mean_b = np.mean(group_b)</span><br><span class="line">std_a = np.std(group_a, ddof=<span class="number">1</span>)</span><br><span class="line">std_b = np.std(group_b, ddof=<span class="number">1</span>)</span><br><span class="line">n_a = <span class="built_in">len</span>(group_a)</span><br><span class="line">n_b = <span class="built_in">len</span>(group_b)</span><br><span class="line"></span><br><span class="line">t_statistic, p_value = stats.ttest_ind(group_a, group_b)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;组A平均值:&quot;</span>, mean_a)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;组B平均值:&quot;</span>, mean_b)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;组A标准差:&quot;</span>, std_a)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;组B标准差:&quot;</span>, std_b)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;t值:&quot;</span>, t_statistic)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;p值:&quot;</span>, p_value)</span><br><span class="line"></span><br><span class="line">alpha = <span class="number">0.05</span></span><br><span class="line"><span class="keyword">if</span> p_value &lt; alpha:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;拒绝零假设，两组的平均成绩有显著差异。&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;不拒绝零假设，两组的平均成绩没有显著差异。&quot;</span>)</span><br></pre></td></tr></table></figure><h3 id=""><a href="#" class="headerlink" title=" "></a> </h3>]]></content>
      
      
      
        <tags>
            
            <tag> 统计分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TOPSIS熵权法</title>
      <link href="/2024/07/30/TOPSIS%E7%86%B5%E6%9D%83%E6%B3%95/"/>
      <url>/2024/07/30/TOPSIS%E7%86%B5%E6%9D%83%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h1 id="TOPSIS法"><a href="#TOPSIS法" class="headerlink" title="TOPSIS法"></a>TOPSIS法</h1><p>TOPSIS（Technique for Order of Preference by Similarity to Ideal Solution，理想解逼近排序法）是一种用于多属性决策分析的排序方法。它用于评估和选择最优方案，尤其适用于当存在多个评价标准时。</p><p>TOPSIS方法通过计算各个方案与理想解和负理想解的距离来进行排序。理想解是所有标准下最好表现的方案，负理想解是所有标准下最差表现的方案。对每个方案，计算其与理想解和负理想解的欧几里得距离。然后，确定每个方案相对于这两个解的距离。通过比较方案到理想解和负理想解的距离，计算每个方案的相对接近度。相对接近度高的方案被认为更优。根据相对接近度对所有方案进行排序，选择接近理想解且远离负理想解的方案作为最优方案。</p><div class="table-container"><table><thead><tr><th style="text-align:center">姓名</th><th style="text-align:center">成绩</th><th style="text-align:center">排名</th><th style="text-align:center">SCORE</th></tr></thead><tbody><tr><td style="text-align:center">小李</td><td style="text-align:center">72</td><td style="text-align:center">2</td><td style="text-align:center">2 /10 = 0. 2</td></tr><tr><td style="text-align:center">小明</td><td style="text-align:center">56</td><td style="text-align:center">1</td><td style="text-align:center">1 / 10 = 0.1</td></tr><tr><td style="text-align:center">小华</td><td style="text-align:center">85</td><td style="text-align:center">3</td><td style="text-align:center">3 / 10 = 0.3</td></tr><tr><td style="text-align:center">小王</td><td style="text-align:center">96</td><td style="text-align:center">4</td><td style="text-align:center">4 / 10 = 0.4</td></tr></tbody></table></div><p>例如，如果按照每个人的排名来之间赋分的排名来决定<strong>SCORE</strong>值，这种方式仅考虑了排名的先后性，但却忽略了实际数值中的距离差异，比如如果小明考了20分，那他最后的SOCRE还是0.1，这就不太能满足我们实际的需求。我们需要的这个SCORE可以综合考虑多个特征值。</p><p>事实上，对于层次分析法而言，由于其主观性指标太强，有时候评价的模型很难有说服力，所以我们一般采用具有客观性指标的模型来进行评价，而TOPSIS法便能满足这一需求，TOPSIS不仅考虑了排名的先后性，也能比较数据的差异程度来进行综合评判。</p><h2 id="TOPSIS的步骤"><a href="#TOPSIS的步骤" class="headerlink" title="TOPSIS的步骤"></a>TOPSIS的步骤</h2><ul><li>将原始矩阵正向化。</li></ul><p>根据不同的数据类型，以及期望的指标类型，将进行评判的数据指标进行正向化处理，将所有指标类型统一变为极大型指标。</p><p>分为四种指标，分别是：<strong><em>极大型指标，较小型指标，中间型指标，区间型指标</em></strong>。</p><p><strong>极大型指标</strong>是指越大越好的指标，又叫效益型指标，比如经济效益，成绩等。</p><p><strong>较小型指标</strong>是指越小越好的指标。又叫成本型指标，比如污染值，成本等。</p><p><strong>中间型指标</strong>是指越贴近某个数值越好的指标，比如适合的PH值等。</p><p><strong>区间型指标</strong>是指在某个区间越好的指标，比如适合的温度区间等。</p><p>后三个指标转化成极大型指标的方法：</p><p><strong>较小型指标转换为极大型指标</strong>：</p><script type="math/tex; mode=display">\hat x_i  =max - xi \ or \ \ \frac{1}{xi}</script><p><strong>中间型指标转换为极大型指标</strong>：</p><p>假设$x_p$为最佳指标。</p><script type="math/tex; mode=display">\hat x_i = 1 - \frac{\mid x_i - x_p\mid}{max \{ \mid {x_i-x_p}\mid\}}</script><p><strong>区间型指标转换为极大型指标</strong>：</p><p>假设$[a,b]$为最佳区间。</p><script type="math/tex; mode=display">\hat x_i = \left\{\begin{align*}1 - \frac{a-x_i}{max \{ a-min(x_i),max(x_i)-b\} }  \ \ \ \ x_i\leq a\\ 1 - \frac{x_i-b}{max \{ a-min(x_i),max(x_i)-b\} }\ \ \ \ x_i>b\\ \end{align*}\right.</script><ul><li>将正向化矩阵标准化</li></ul><p>正向化矩阵用来消除不同量纲的影响。</p><script type="math/tex; mode=display">X = \begin{pmatrix}        x_{11} & x_{12} & \cdots & x_{1m}\\        x_{21} & x_{22} & \cdots & x_{2m}\\        \vdots & \vdots & \ddots & \vdots\\        x_{n1} & x_{n2} & \cdots & x_{nm}\\    \end{pmatrix}</script><p>标准化后的矩阵$Z$为：</p><script type="math/tex; mode=display">Z_{ij} = \frac{x_{ij}}{\sqrt{\sum_{i=1}^{n}x_{ij}^{2}}}</script><ul><li>计算得分并归一化</li></ul><script type="math/tex; mode=display">Z_{max} = (Z_{max}^{1},Z_{max}^{2},...,Z_{max}^{m})</script><script type="math/tex; mode=display">Z_{min} = (Z_{min}^{1},Z_{min}^{2},...,Z_{min}^{m})</script><script type="math/tex; mode=display">D_{max}^{i} = \sqrt{\sum_{j=1}^{m}\omega_{j}(Z_{max}^{j}-z_{ij})^{2}}</script><script type="math/tex; mode=display">D_{min}^{i} = \sqrt{\sum_{j=1}^{m}\omega_{j}(Z_{min}^{j}-z_{ij})^{2}}</script><p>得到每个指标的最大值$Z<em>{max}$和最小值$Z</em>{min}$后，计算$z<em>{ij}$与它们之间的距离，得到$D</em>{max}^{i}$与$D<em>{min}^{i}$，紧接着出第$i$个对象的指标评分$S_i$，其中$\omega</em>{j}$是权重。</p><script type="math/tex; mode=display">S_i = \frac{D_{min}^{i}}{D_{min}^{i}+D_{max}^{i}}</script><p>再进行归一化，得到$\hat S_{i{}}$:</p><script type="math/tex; mode=display">\hat S_i = \frac{S_i}{\sum_{i=1}^{n}S_i}</script><h2 id="权重计算：熵权法"><a href="#权重计算：熵权法" class="headerlink" title="权重计算：熵权法"></a>权重计算：熵权法</h2><p>权重的计算方式有很多，比如层次分析法，但其主观性太强，所以我们这里选择熵权法。</p><script type="math/tex; mode=display">p_{ij} = \frac{x_{ij}}{\sum_{i=1}^{m} x_{ij}}e_j = -k \sum_{i=1}^{m} p_{ij} \ln p_{ij}</script><p>$p_{ij}$ 表示第 $i$ 个方案在第 $j$ 个指标上的标准化值，是一个常数，$k = 1/ln \ m$用于保证 $e_j$ 的取值范围在 [0,1] 之间。 </p><h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 极小型转为极大型指标</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">dataDirection_1</span>(<span class="params">datas, offset=<span class="number">0</span></span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">normalization</span>(<span class="params">data</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span> / (data + offset)</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">list</span>(<span class="built_in">map</span>(normalization, datas))</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="comment"># 中间型指标转为极大型指标</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">dataDirection_2</span>(<span class="params">datas, x_min, x_max</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">normalization</span>(<span class="params">data</span>):</span><br><span class="line">        <span class="keyword">if</span> data &lt;= x_min <span class="keyword">or</span> data &gt;= x_max:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="keyword">elif</span> data &gt; x_min <span class="keyword">and</span> data &lt; (x_min + x_max) / <span class="number">2</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">2</span> * (data - x_min) / (x_max - x_min)</span><br><span class="line">        <span class="keyword">elif</span> data &lt; x_max <span class="keyword">and</span> data &gt;= (x_min + x_max) / <span class="number">2</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">2</span> * (x_max - data) / (x_max - x_min)</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">list</span>(<span class="built_in">map</span>(normalization, datas))</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 区间型指标转为极大型指标</span></span><br><span class="line"><span class="comment"># [x_min, x_max]最佳稳定区间, [x_minimum, x_maximum]容忍区间</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">dataDirection_3</span>(<span class="params">datas, x_min, x_max, x_minimum, x_maximum</span>):  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">normalization</span>(<span class="params">data</span>):</span><br><span class="line">        <span class="keyword">if</span> data &gt;= x_min <span class="keyword">and</span> data &lt;= x_max:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">        <span class="keyword">elif</span> data &lt;= x_minimum <span class="keyword">or</span> data &gt;= x_maximum:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="keyword">elif</span> data &gt; x_max <span class="keyword">and</span> data &lt; x_maximum:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span> - (data - x_max) / (x_maximum - x_max)</span><br><span class="line">        <span class="keyword">elif</span> data &lt; x_min <span class="keyword">and</span> data &gt; x_minimum:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span> - (x_min - data) / (x_min - x_minimum)</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">list</span>(<span class="built_in">map</span>(normalization, datas))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">entropyWeight</span>(<span class="params">data</span>):</span><br><span class="line">    data = np.array(data)</span><br><span class="line">    <span class="comment"># 计算第j个指标下第i个样本所占的比重，相对熵计算中用到的概率</span></span><br><span class="line">    P = data / data.<span class="built_in">sum</span>(axis=<span class="number">0</span>)  <span class="comment"># 压缩行</span></span><br><span class="line">    <span class="comment"># 计算熵值</span></span><br><span class="line">    E = np.nansum(-P * np.log(P) / np.log(<span class="built_in">len</span>(data)), axis=<span class="number">0</span>)</span><br><span class="line">    <span class="comment"># 信息效用值</span></span><br><span class="line">    d = (<span class="number">1</span> - E)</span><br><span class="line">    <span class="comment"># 计算权系数</span></span><br><span class="line">    W = d / d.<span class="built_in">sum</span>()</span><br><span class="line">    <span class="keyword">return</span> W</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 综合评价 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>决策树与随机森林</title>
      <link href="/2024/07/27/%E5%86%B3%E7%AD%96%E6%A0%91%E4%B8%8E%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/"/>
      <url>/2024/07/27/%E5%86%B3%E7%AD%96%E6%A0%91%E4%B8%8E%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/</url>
      
        <content type="html"><![CDATA[<h1 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h1><p>决策树(decision tree)是有监督学习下的一种基本的分类与回归算法，其根据特征来对实际进行if-then条件的判断来进行分类。决策树的学习包括三个步骤：特征选择，决策树的生成和裁剪。</p><h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>决策树由结点(node)和有向边(directed edge)组成，结点有两种类型：内部结点(internal node)和叶结点(leaf node)，内部结点表示一个特征或属性，叶标点表示一个类。</p><h3 id="if-then规则"><a href="#if-then规则" class="headerlink" title="if-then规则"></a>if-then规则</h3><p>if-then规则的性质是：互斥且完备，这意味着每一个实例都被一条路径或一条规则所覆盖，且只能被一条路径或一条规则所覆盖。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">         [Feature 1]</span><br><span class="line">        /           \</span><br><span class="line">   [Value A]      [Value B]</span><br><span class="line">     /               \</span><br><span class="line">[Leaf 1]         [Feature 2]</span><br><span class="line">                    /       \</span><br><span class="line">             [Value X]   [Value Y]</span><br><span class="line">               /            \</span><br><span class="line">          [Leaf 2]       [Leaf 3]</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>决策树的树概念可以以kd树为基础进行理解，在特征空间下，根据不同的特征定义不同的划分来划分为不同的单元或区域，假设$X$为表示特征的随机变量，$Y$为表示类的随机变量，那么条件概率分布表示为$P(Y\mid X)$，$X$取值于给定划分下单元的集合，$Y$取值于类的集合，各叶结点上的条件概率往往偏向于某一个类，决策树分类时将该结点的实例强行划分到条件概率大的那一类去。</p><p>与训练数据集不相矛盾的决策树可能有多个，也可能一个都没有，一般我们选择与训练数据矛盾较小且具有很好泛化能力的决策树。</p><p>决策树学习的算法通常是一个递归地选择最优特征，并根据特征来自对训练数据进行分割。</p><ul><li>构建根结点，将所有训练数据都放在根节点。</li><li>选择一个最优特征，根据特征来将训练数据划分为子集，使得每个子集有一个在当前条件下最好的分类。</li><li>如果这些子集已经能够被基本正确分类，那么构建叶结点，并将子集划分到叶节点中，如果不能被基本正确分类，那么就继续选择最优特征进行分割，直至能基本分类正确，进行递归。</li></ul><p>这样的树会有很好的分类能力，但是会出现过拟合现象，所以要剪枝来使其具有更好的泛化能力。</p><p>决策树的生成只考虑局部最优，而剪枝考虑全局最优。</p><h3 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h3><p>选取对训练数据具有分类能力的特征，而不是没有作用的特征可以提高决策树的学习效率，决策树选用信息增益准则来选择特征。</p><h4 id="信息增益准则"><a href="#信息增益准则" class="headerlink" title="信息增益准则"></a>信息增益准则</h4><p><strong>熵</strong>（entropy) 是表示随机变量不确定性的度量，设$X$是一个取有限个值的离散随机变量，其概率分布为:$P(X=x<em>i)=p_i$，则随机变量$X$的熵定义为:$H(X)=-\sum</em>{i=1}^{n}p_ilogp_i$。一般对数以2或$e$为底，此时单位分布为比特(bit)或纳特(nat)，所以熵只依赖于$X$的分布而与$X$的取值无关，记作$H(p)$。熵越大，随机变量的不确定性越大，有$0\leq H(p)\leq log\ n$。</p><p>例如，当随机变量只有0，1时，$P(X=1)=p,P(X=0)=1-p$，此时$H(p)$的图像呈现向下的二次函数形式，当时$p=0$或$p=1$时，随机变量完全没有不确定性，当$p=0.5$时，$H(p)=1$，熵值最大。</p><p>设随机变量$(X,Y)$，其概率分布为$P(X=x<em>i,Y=y_i)=p</em>{ij}$，条件熵$H(Y\mid X)$表示在已知随机变量X的条件下随机变量$Y$的不确定性。其中：</p><script type="math/tex; mode=display">H(Y\mid X) = \sum_{i=1}^{n}p_iH(Y\mid X=x_i)</script><p>这里的$p_i=P(X=x_i)$。</p><p>当熵和条件熵中的概率由数据估计（特别是极大似然估计）得到的时候，所对应的值分布称为经验熵（empirical entropy)和经验条件熵(empirical conditional entropy)。</p><p><strong>信息增益</strong>表示得知特征$X$的信息而使类$Y$的信息不确定性减少的程度，定义为$g(D, A)$</p><script type="math/tex; mode=display">g(D,A)=H(D)-H(D\mid A)</script><p>一般地，熵$H(Y)$与条件熵$H(Y\mid X)$之差称为互信息，信息增益越大越好。</p><h2 id="信息增益算法"><a href="#信息增益算法" class="headerlink" title="信息增益算法"></a>信息增益算法</h2><p>假设训练数据集为$D$，$\mid D \mid$表示其样本容量，即样本个数，设有$K$个类$C<em>k,k=0,1,2,…$，$\mid C_k \mid$为属于类$C_k$的样本个数，$\sum</em>{k=1}^K \mid C<em>k\mid = \mid D \mid$。设有特征$A$有$n$个不同的取值${a_1,a_2,…,a_n}$，根据特征$A$的取值将$D$划分为$n$个子集$D_1,D_2,…,D_n$，$\mid D_i \mid$为$D_i$的个样本个数，$\sum</em>{i=1}^n \mid D<em>i\mid =\mid D \mid$，记子集$D_i$中属于类$C_k$的样本集合为$D</em>{ik}$，即$D<em>{ik}=Di\cap C_k$，$\mid D</em>{ik}\mid$为$D_ik$的样本个数。</p><p>首先输入训练数据集$D$和特征$A$，来输出特征$A$对$D$的信息增益$g(D,A)$。</p><ul><li><p>计算经验熵$H(D)$，有$H(D)=-\sum_{k=1}^K \frac{\mid C_k \mid}{\mid D \mid}log_2\frac{\mid C_k\mid}{\mid D\mid}$</p></li><li><p>$H(D\mid A)=\sum<em>{i=1}^{n}\frac{\mid D_i\mid}{\mid D\mid}H(D_i)=-\sum</em>{i=1}^{n}\frac{\mid D<em>i\mid}{\mid D\mid}\sum</em>{k=1}^K \frac{\mid C_k \mid}{\mid D \mid}log_2\frac{\mid C_k\mid}{\mid D\mid}$​</p></li><li>计算信息增益$g(D,A)=H(D)-H(D\mid A)$​</li></ul><p>此外，还有<strong>信息增益比</strong>的概念</p><h2 id="决策树的生成"><a href="#决策树的生成" class="headerlink" title="决策树的生成"></a>决策树的生成</h2><h3 id="ID3算法"><a href="#ID3算法" class="headerlink" title="ID3算法"></a>ID3算法</h3><h3 id="ID4-5算法"><a href="#ID4-5算法" class="headerlink" title="ID4.5算法"></a>ID4.5算法</h3><h2 id="CART树"><a href="#CART树" class="headerlink" title="CART树"></a>CART树</h2><h1 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h1><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score, classification_report, confusion_matrix</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_wine</span><br><span class="line">data = load_wine()</span><br><span class="line"></span><br><span class="line">X = data.data</span><br><span class="line">y = data.target</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.3</span>, random_state=<span class="number">42</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看特征名称和前五个样本</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Feature names:&quot;</span>, data.feature_names)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;First 5 samples of X:\n&quot;</span>, X[:<span class="number">5</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看目标类别名称和前五个标签</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Target names:&quot;</span>, data.target_names)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;First 5 samples of y:\n&quot;</span>, y[:<span class="number">5</span>])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">clf = RandomForestClassifier(n_estimators=<span class="number">100</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">clf.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">y_pred = clf.predict(X_test)</span><br><span class="line"><span class="comment"># 输出特征重要性</span></span><br><span class="line">importances = clf.feature_importances_</span><br><span class="line">feature_importance = pd.Series(importances, index=data.feature_names)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Feature importances:\n&quot;</span>, feature_importance.sort_values(ascending=<span class="literal">False</span>))</span><br><span class="line">accuracy = accuracy_score(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Accuracy: <span class="subst">&#123;accuracy:<span class="number">.2</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\nClassification Report:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Confusion Matrix:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(confusion_matrix(y_test, y_pred))</span><br></pre></td></tr></table></figure><p>绘制特征重要性图</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">importances = clf.feature_importances_</span><br><span class="line">feature_importance = pd.Series(importances, index=data.feature_names)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制特征重要性条形图</span></span><br><span class="line">feature_importance.sort_values(ascending=<span class="literal">False</span>).plot(kind=<span class="string">&#x27;bar&#x27;</span>, figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">plt.title(<span class="string">&#x27;Feature Importances&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Importance Score&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line">cm = confusion_matrix(y_test, y_pred)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制热图</span></span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>, <span class="number">6</span>))</span><br><span class="line">sns.heatmap(cm, annot=<span class="literal">True</span>, fmt=<span class="string">&#x27;d&#x27;</span>, cmap=<span class="string">&#x27;Blues&#x27;</span>, xticklabels=data.target_names, yticklabels=data.target_names)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Predicted&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Actual&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Confusion Matrix&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>朴素贝叶斯算法及实现</title>
      <link href="/2024/07/27/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%AE%97%E6%B3%95%E5%8F%8A%E5%AE%9E%E7%8E%B0/"/>
      <url>/2024/07/27/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%AE%97%E6%B3%95%E5%8F%8A%E5%AE%9E%E7%8E%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="朴素贝叶斯"><a href="#朴素贝叶斯" class="headerlink" title="朴素贝叶斯"></a>朴素贝叶斯</h1><p>朴素贝叶斯(naive Bayes)法是基于贝叶斯定理与特征条件独立假设的分类方法，对于给定训练数据集，基于特征条件独立假设学习输入输出的联合概率分布，然后基于此模型对给定的输入 x ，利用贝叶斯定理求出后验概率最大的输出 y 。</p><h2 id="贝叶斯定理"><a href="#贝叶斯定理" class="headerlink" title="贝叶斯定理"></a>贝叶斯定理</h2><p>贝叶斯定理（Bayes’ Theorem）是概率论中的一个重要公式，用于计算在已知某些事件发生的情况下，另一事件发生的概率。它建立了后验概率（posterior probability）和先验概率（prior probability）、条件概率（conditional probability）之间的关系。</p><script type="math/tex; mode=display">\begin{align*}P(A \mid B) = \frac{P(B \mid A) \, P(A)}{P(B)}\end{align*}</script><p>其中，P(A∣B) 是在事件 B 发生后事件 A 发生的后验概率，P(A) 是事件 A 的先验概率，P(B∣A) 是在事件 A 发生的情况下事件 B 发生的条件概率，P(B) 是事件 B 的边缘概率。</p><h2 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h2><p>我们将类别设为C，输入特征向量为 x = {x1,x2,…,xn}，那么根据贝叶斯定理：</p><script type="math/tex; mode=display">\begin{equation}P(C \mid \mathbf{x}) = \frac{P(\mathbf{x} \mid C) P(C)}{P(\mathbf{x})}\end{equation}</script><p>其中，P(x) 是特征向量 x 的边缘概率， P(C) 是类别的先验概率，P(x∣C) 是似然函数，即在给定类别 C 的情况下，观察到特征向量 x 的概率，P(C∣x) 是后验概率，即在给定特征向量 x 的情况下，类别 C 的概率。</p><p>在朴素贝叶斯模型中，假设特征是条件独立的,故P(C|x)正比于这些单独条件概率的乘积。</p><script type="math/tex; mode=display">\begin{equation}P(C \mid \mathbf{x}) \propto P(C) \prod_{i=1}^{n} P(x_i \mid C)\end{equation}</script><p>为了分类，我们选择具有最大后验概率的类别 CMAP,将其作为x的类输出，后验概率计算：</p><script type="math/tex; mode=display">\begin{equation}C_{\text{MAP}} = \arg\max_C P(C \mid \mathbf{x}) = \arg\max_C P(C) \prod_{i=1}^{n} P(x_i \mid C)\end{equation}</script><h2 id="后验概率最大化"><a href="#后验概率最大化" class="headerlink" title="后验概率最大化"></a>后验概率最大化</h2><p>可以看到，朴素贝叶斯将实例分到了后验概率最大的类中，其等于期望风险最小化。</p><p>定义0-1损失函数:</p><script type="math/tex; mode=display">L(Y,f(X)) = \left\{\begin{align*}1,Y≠f(X)\\0,Y=f(X)\end{align*}\right.</script><p>其中，f(X)是分类决策函数，此时的期望风险函数为:$R_{exp}(f) = E[L(Y,f(X))]$，这里如果f(X)的类和 Y 不同，那么则定为1，这样不同的类数越多，损失函数越大。期望是对联合分布$P(X,Y)$​取的，所以条件期望变为：</p><script type="math/tex; mode=display">\begin{equation}R_{exp}(f) = E_{X}\sum_{k=1}^{K} [L(c_{k},f(X))]P(c_{k}|X)\end{equation}</script><p>为了使期望风险最小化，只需对X=x逐个极小化。</p><script type="math/tex; mode=display">f(x) = argmin_{y∈Y}\sum_{k=1}^{K} L(c_{k},y)P(c_{k}|X=x)\\=argmin_{y∈Y}(1-\sum_{k=1}^{K}P(y≠c_{k}|X=x))\\=argmax_{y∈Y}P(y=c_{k}|X=x)</script><p>这样，期望风险最小化准则就变成了后验概率最大化准则，即朴素贝叶斯采用的原理。</p><h2 id="参数估计"><a href="#参数估计" class="headerlink" title="参数估计"></a>参数估计</h2><h3 id="极大似然估计"><a href="#极大似然估计" class="headerlink" title="极大似然估计"></a>极大似然估计</h3><script type="math/tex; mode=display">P(Y = C_{k}) = \frac{ \sum_{i=1}^{N} I(y_i=C_k)}{N}</script><p>其中，$I(y_i=c_k)$判断是否属于$C_k$类，求和后除以总数N便是类别$C_k$的先验概率。</p><p>紧接着计算条件概率:</p><script type="math/tex; mode=display">P(X^{j}=a_{jl} \mid Y = c_k) = \frac{\sum_{i=1}^{N}I(x_i^{(j)}=a_{jl},y_i=c_k)}{\sum_{i=1}^{N}I(y_i=c_k)}</script><p>其中，$x<em>i$ 是数据集，而 $x_i^{(j)}$ 是指第 $i$ 个样本的第 $j$ 个特征，$a</em>{jl}$ 是第 $ j$ 个特征可能取的第 $l$ 个值。</p><p>这样来计算：</p><script type="math/tex; mode=display">P(Y=c_k)\prod_{j=1}^{n}P(X^{(j)}=x^{(j)} \mid Y = c_k)</script><p>最后在取后验概率最大值就可以了。</p><h3 id="贝叶斯估计"><a href="#贝叶斯估计" class="headerlink" title="贝叶斯估计"></a>贝叶斯估计</h3><p>用极大似然估计可能会出现概率值为0的情况，所以为了解决这一问题，引入一个正数 $\lambda$，变为</p><script type="math/tex; mode=display">P(X^{j}=a_{jl} \mid Y = c_k) = \frac{\sum_{i=1}^{N}I(x_i^{(j)}=a_{jl},y_i=c_k)+\lambda}{\sum_{i=1}^{N}I(y_i=c_k)+S_j\lambda}</script><p>当$\lambda$ = 1时，称为拉普拉斯平滑(Laplacian smoothing)，一般也取为1。</p><h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p>工具箱一般有MultinomialNB，BernoulliNB()，其中alpha参数便是上述的$\lambda$，一般取<code>α=1.0</code>。GaussianNB()，其自动通过高斯分布来估计。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> MultinomialNB</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里选择经典的iris数据集</span></span><br><span class="line">data = load_iris()</span><br><span class="line">X = data.data</span><br><span class="line">y = data.target</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.3</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">model = MultinomialNB()</span><br><span class="line"></span><br><span class="line">model.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">y_pred = model.predict(X_test)</span><br><span class="line"></span><br><span class="line">accuracy = accuracy_score(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Accuracy: <span class="subst">&#123;accuracy:<span class="number">.2</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>最后准确率为0.96，还是比较高的。</p><h2 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h2><p>当特征在给定类别的条件下近似独立时，朴素贝叶斯分类器的假设较为合理，如果特征之间有很强的相关性，存在强依赖关系或交互作用，朴素贝叶斯的假设可能会导致性能下降。</p><p>如果数据特征非常复杂且不能被简单的条件独立假设捕捉，则需要考虑其他更复杂的模型（如决策树、随机森林），朴素贝叶斯分类器最适合高维、稀疏的离散数据。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>KNN算法及其实现</title>
      <link href="/2024/07/27/KNN%E7%AE%97%E6%B3%95%E5%8F%8A%E5%85%B6%E5%AE%9E%E7%8E%B0/"/>
      <url>/2024/07/27/KNN%E7%AE%97%E6%B3%95%E5%8F%8A%E5%85%B6%E5%AE%9E%E7%8E%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="KNN算法"><a href="#KNN算法" class="headerlink" title="KNN算法"></a>KNN算法</h1><p>K近邻算法 (K-nearest neighbor, K-NN)，是一种基本的分类与回归算法，其不具有显式的学习过程，利用训练数据集对特征向量空间进行划分，并作为分类的模型。</p><h2 id="算法实现"><a href="#算法实现" class="headerlink" title="算法实现"></a>算法实现</h2><p>KNN通过给定一个训练数据集，对新的输入实例，在训练数据集中找到与其最邻近的k个实例，如果这k个实例的多数属于某个类，那么就把这个新输入的实例划分为这个类。</p><p>通过给定输入训练数据集:<em>T = {( (X1,Y1),(X2,Y2),(Xn,Yn) )}</em>，来输出实例x所属的类y。</p><ul><li>根据给定的距离量度，在训练数据集T中找出与x最近邻的k个点，涵盖这k个点的x邻域称为Nk(x)</li><li>在Nk(x)中根据分类决策规则来决定x的类别y</li></ul><p>当 k=1 时，称为最近邻算法。</p><h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>本质上是对训练的特征空间进行划分，定义每个训练点<em>x_{i}</em>，距离该点比其他点更近的所有点组成的一个区域叫做单元(cell)。对于给定新的输入实例点，kNN都能根据规则和模型来唯一确定这个点所属的类。</p><h2 id="距离量度"><a href="#距离量度" class="headerlink" title="距离量度"></a>距离量度</h2><p>那么如何区分两个实例点之间的相似程度呢？这里可以用多个方法，比如Lp（Lp distance)距离与Minkowski距离，以下是Lp距离的公式：</p><script type="math/tex; mode=display">\begin{align*}L_p(\mathbf{x}, \mathbf{y}) = \left( \sum_{i=1}^n \left| x_i - y_i \right|^p \right)^{\frac{1}{p}}\end{align*}</script><ul><li>p = 2时，称为欧氏距离(Euclidean distance)，常用于一般情况下分析两点之间的相似程度。</li><li><p>p = 1时，称为曼哈顿距离(Manhatten distance)，一般用于城市规划等。</p></li><li><p>p = ∞时，它是各个坐标距离的最大值。</p></li></ul><p>k值的选择会对结果产生重大影响，当k值选择的较小，其近似误差会减小，但是估计误差会增大，其会导致对近邻点敏感，所以如果数据集中存在噪声点，会对输出结果造成极大影响，模型会变得复杂与过拟合。</p><p>如果k值选择较大，那么近似误差会增大，估计误差会减小，此时模型会变得简单，较远的点也会对分类造成影响，</p><p>一般来说，k值选择较小的数值。用交叉验证法来选取最优的值。</p><h2 id="分类决策规则"><a href="#分类决策规则" class="headerlink" title="分类决策规则"></a>分类决策规则</h2><p>k近邻一般采用多数表决策略，多数表决规则等价于经验风险最小化。</p><h2 id="kd树"><a href="#kd树" class="headerlink" title="kd树"></a>kd树</h2><p>一般来说，训练数据可能过大，而又不可能对每一个点进行距离的计算，那样计算量会特别大，为了减少计算量，可以采用特殊的存储结构来存储训练的数据，其中之一便是kd树 (kd tree) 方法。</p><h4 id="kd树的构建"><a href="#kd树的构建" class="headerlink" title="kd树的构建"></a>kd树的构建</h4><ul><li>首先，选择轴，如果是二维平面，那么第一层使用X轴来进行数据点的分割，第二层使用Y轴，然后再回到X轴，以此类推。</li><li>其次，在每一曾上选择一个点作为分割点，并将其他点分为两个子集，这里有点类似于二分查找的思想，即为了保证树的平衡性，我们一般选择这一层上的中位点作为数据分割点。</li><li>然后，对每个子集进行重复上述操作，不断分割递归，直至每个子集只包含一个点或达到某个停止条件。</li></ul><h4 id="kd树的查找"><a href="#kd树的查找" class="headerlink" title="kd树的查找"></a>kd树的查找</h4><ul><li>先从根节点开始，检查分割点与查询点的距离。如果查询点在分割点的左侧，我们首先搜索左子树，否则搜索右子树。</li><li>在搜索过程中，我们递归地访问子树，并计算每个点到查询点的距离。每次访问一个节点时，我们会检查是否有可能存在比当前找到的最近邻更接近的点。</li><li>在搜索过程剪枝掉不必要的部分。如果某个子树的分割超球体与查询点的距离大于当前已知的最近邻距离，便可以跳过这个子树的搜索，以此加速查找过程。</li></ul><figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">    <span class="built_in">D</span>(<span class="number">7</span>, <span class="number">7</span>)</span><br><span class="line">   / </span><br><span class="line">  <span class="selector-tag">B</span>(<span class="number">3</span>, <span class="number">5</span>)</span><br><span class="line"> / \</span><br><span class="line"><span class="selector-tag">A</span>(<span class="number">1</span>, <span class="number">2</span>) <span class="built_in">C</span>(<span class="number">4</span>, <span class="number">2</span>)</span><br></pre></td></tr></table></figure><p>比如，我们有一个输入点E (5,5)，然后选择D (7,7)作为起始根结点，发现B点更接近E点，此时将最近点更新为B，这时发现B点生成的叶结点就只剩A与C，再将A,C分别与D对比，最后判断D的类,更新最近邻为 C，因为 C 比 B更接近 (5, 5)。</p><h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p>我们可以使用Sklearn工具箱来调用knn算法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"></span><br><span class="line">X = np.array([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">2</span>, <span class="number">3</span>], [<span class="number">3</span>, <span class="number">4</span>], [<span class="number">5</span>, <span class="number">5</span>], [<span class="number">6</span>, <span class="number">6</span>]])</span><br><span class="line">y = np.array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># k=3</span></span><br><span class="line">knn = KNeighborsClassifier(n_neighbors=<span class="number">3</span>)</span><br><span class="line">knn.fit(X, y)</span><br><span class="line"></span><br><span class="line">test_points = np.array([[<span class="number">4</span>, <span class="number">4</span>]])</span><br><span class="line">predictions = knn.predict(test_points)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, point <span class="keyword">in</span> <span class="built_in">enumerate</span>(X):</span><br><span class="line">    plt.scatter(point[<span class="number">0</span>], point[<span class="number">1</span>], c=<span class="string">&#x27;red&#x27;</span> <span class="keyword">if</span> y[i] == <span class="number">0</span> <span class="keyword">else</span> <span class="string">&#x27;blue&#x27;</span>, label=<span class="string">f&#x27;Class <span class="subst">&#123;y[i]&#125;</span>&#x27;</span> <span class="keyword">if</span> i == <span class="number">0</span> <span class="keyword">else</span> <span class="string">&quot;&quot;</span>)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">for</span> i, point <span class="keyword">in</span> <span class="built_in">enumerate</span>(test_points):</span><br><span class="line">    plt.scatter(point[<span class="number">0</span>], point[<span class="number">1</span>], c=<span class="string">&#x27;green&#x27;</span>, marker=<span class="string">&#x27;x&#x27;</span>, s=<span class="number">100</span>, label=<span class="string">&#x27;Test Point&#x27;</span> <span class="keyword">if</span> i == <span class="number">0</span> <span class="keyword">else</span> <span class="string">&quot;&quot;</span>)</span><br><span class="line">    plt.text(point[<span class="number">0</span>] + <span class="number">0.1</span>, point[<span class="number">1</span>], <span class="string">f&#x27;Prediction: <span class="subst">&#123;predictions[i]&#125;</span>&#x27;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line">plt.xlabel(<span class="string">&#x27;Feature 1&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Feature 2&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.title(<span class="string">&#x27;kNN Classification with scikit-learn&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>我们也可以根据原理来写一下内部代码是什么样的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算欧氏距离</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">euclidean_distance</span>(<span class="params">point1, point2</span>):</span><br><span class="line">    <span class="keyword">return</span> np.sqrt(np.<span class="built_in">sum</span>((point1 - point2) ** <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">k_nearest_neighbors</span>(<span class="params">X, y, test_point, k=<span class="number">3</span></span>):</span><br><span class="line">    distances = [euclidean_distance(x, test_point) <span class="keyword">for</span> x <span class="keyword">in</span> X]</span><br><span class="line">    k_indices = np.argsort(distances)[:k]</span><br><span class="line">    k_nearest_labels = [y[i] <span class="keyword">for</span> i <span class="keyword">in</span> k_indices]</span><br><span class="line">    most_common = Counter(k_nearest_labels).most_common(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> most_common[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">X = np.array([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">2</span>, <span class="number">3</span>], [<span class="number">3</span>, <span class="number">4</span>], [<span class="number">5</span>, <span class="number">5</span>], [<span class="number">6</span>, <span class="number">6</span>]])</span><br><span class="line">y = np.array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">test_points = np.array([[<span class="number">4</span>, <span class="number">4</span>]])</span><br><span class="line">predictions = [k_nearest_neighbors(X, y, tp, k=<span class="number">3</span>) <span class="keyword">for</span> tp <span class="keyword">in</span> test_points]</span><br></pre></td></tr></table></figure><h2 id="可改进点"><a href="#可改进点" class="headerlink" title="可改进点"></a>可改进点</h2><p>比如进行具体的距离规划，而不是统一的简单的欧式距离。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RNN与LSTM原理及代码实现</title>
      <link href="/2024/07/08/RNN-%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/"/>
      <url>/2024/07/08/RNN-%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="RNN与LSTM"><a href="#RNN与LSTM" class="headerlink" title="RNN与LSTM"></a>RNN与LSTM</h1><h2 id="一个关于RNN由来的例子"><a href="#一个关于RNN由来的例子" class="headerlink" title="一个关于RNN由来的例子"></a>一个关于RNN由来的例子</h2><p><img src="imgs\image-20240708212505196.png" alt="image-20240708212505196"></p><p>如果想解决词汇编码的问题，可以通过Word hashing来表示。</p><p><img src="imgs\image-20240708212659170.png" alt="image-20240708212659170"></p><p>对于简单的这种网络，只能简单识别出Taipei是目的地或是出发地，而不是精准的判断Taipei到底是出发地还是目的地，对于leave和arrive这两个词被划分到了’other’维度，所以想要解决这个问题，就需要一个有记忆力的神经网络，这就是Recurrent Neural Network(RNN)。</p><h2 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h2><p><img src="imgs\image-20240708213056663.png" alt="image-20240708213056663"></p><p>那么，需要创建新的a1与a2，来分别存储hidden layer的output，并且，下一次hidden layer的input不光是x1和x2的输入，还包括a1和a2的输入。</p><p><img src="imgs\image-20240708213531877.png" alt="image-20240708213531877"></p><p>这样的话，就可以实现一整个语句的输入了。</p><p><img src="imgs\image-20240708213742365.png" alt="image-20240708213742365"></p><p>当然也可以实现更深的RNN。</p><p><img src="imgs\image-20240708213814636.png" alt="image-20240708213814636"></p><p>另外还有两种Network，一个是Elman Network和Jordan Network，Jordan Network是根据前一个的最后输出来进行存储。</p><p><img src="imgs\image-20240708214010297.png" alt="image-20240708214010297"></p><p>此外还有双向的RNN，即考虑了正向和反向，并将两者的output输出，得到Yt,这样的话范围更广。</p><p><img src="imgs\image-20240708214359660.png" alt="image-20240708214359660"></p><p>LSTM（Long short-term Memory）则是一个更加复杂的RNN，其中有四个input和一个output，分别有输出门，输入门和遗忘门来控制信号是否输入。</p><p><img src="imgs\image-20240708215757390.png" alt="image-20240708215757390"></p><p>对于上面的流程，先对z信息输入，经过simoid function得到g(z)，然后与Input Gate输出的f(zi)相乘，得到g(z)f(zi)，中间Cell存储的初值为c，再经过Forget Gate的输出后，相乘得到cf(zf)，这样与前面的值相加，得到c`，接着再通过sigmoid function，输出结果与Output Gate的输出相乘，得到α。</p><p><img src="imgs\image-20240708220212126.png" alt="image-20240708220212126"></p><p>这是一个简短的举例，如果x2=1，那么将x1的值添加到Memory中，若x2=-1，则释放掉Memory，如果x3=1，那么将Memory中储存的值输出出来，可以看到3+4=7。</p><h2 id="具体计算过程"><a href="#具体计算过程" class="headerlink" title="具体计算过程"></a>具体计算过程</h2><p><img src="imgs\image-20240708220653433.png" alt="image-20240708220653433"></p><p>这个是LSTM一个Cell的最初形态，即x1,x2,x3和bias为1的输入，那么对于右下角的序列输入，可具体展示为以下过程：</p><p><img src="imgs\image-20240708222500230.png" alt="image-20240708222500230"></p><p>首先输入序列为3，1，0，计算过程如图所示，Input Gate的信号最后输出为1，这样的话与3相乘后结果依旧为3，实现了输入门的使能功能，接着，Forget Gate也输出1，代表没有遗忘，最后与原cell中的值相加后，得到3，最后的Output Gate为0，代表输出信号禁止选通，最后实际输出0，但是cell的值已经从0变化到了3，后面的步骤依次类推。</p><p><img src="imgs\image-20240708222947885.png" alt="image-20240708222947885"></p><p><img src="imgs\image-20240708223017862.png" alt="image-20240708223017862"></p><p><img src="imgs\image-20240708223035398.png" alt="image-20240708223035398"></p><p><img src="imgs\image-20240708223056973.png" alt="image-20240708223056973"></p><h2 id="总体展示"><a href="#总体展示" class="headerlink" title="总体展示"></a>总体展示</h2><p><img src="imgs\image-20240708221858291.png" alt="image-20240708221858291"></p><p><img src="imgs\image-20240708221935324.png" alt="image-20240708221935324"></p><p>这样的话就可以实现LSTM，将上一个的输出接到下一个的输入，同时考虑Xt信息中的门控信号和锁存信号，类似于时序逻辑电路。</p><p><img src="imgs\image-20240708222110442.png" alt="image-20240708222110442"></p><p><img src="imgs\image-20240708222221308.png" alt="image-20240708222221308"></p><p>以上是LSTM并联的完整体，即输入信息还额外包括了C与H信息，也叫peephole。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>自注意力机制(Self-Attention)</title>
      <link href="/2024/07/08/%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6-Self-Attention/"/>
      <url>/2024/07/08/%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6-Self-Attention/</url>
      
        <content type="html"><![CDATA[<h1 id="自注意力机制-Self-Attention"><a href="#自注意力机制-Self-Attention" class="headerlink" title="自注意力机制(Self-Attention)"></a>自注意力机制(Self-Attention)</h1><p>该笔记的资料与图片来源于台湾大学李宏毅教授的机器学习课程。</p><h2 id="原理讲解"><a href="#原理讲解" class="headerlink" title="原理讲解"></a>原理讲解</h2><p>自注意力机制应用于多个向量输入并输出信息。</p><p><img src="D:\BlogFile\source\_posts\自注意力机制-Self-Attention.assets\b252ecea4d2f109cef89a77069faf61d.png" alt="b252ecea4d2f109cef89a77069faf61d"></p><p>比如有语音辨识场景，文字聊天，Graph图等场景，一般来说对于词义表示有One-Hot Encoding（独热编码)或是Word Embedding，对于语音辨识则有frame滑动。</p><p>对于输出而言，则有以下几种场景：</p><ul><li>输入的input数量和输出的output数量相同，比如说POS tagging(词性标注)，Social Network等</li></ul><p><img src="D:\BlogFile\source\_posts\自注意力机制-Self-Attention.assets\bfda8ed45180b27278da3bac1be3e5ec.png" alt="bfda8ed45180b27278da3bac1be3e5ec"></p><ul><li>Model仅输出一个label，比如Sentiment Analysis(情感分析)</li></ul><p><img src="D:\BlogFile\source\_posts\自注意力机制-Self-Attention.assets\519dc35935218cfa1aab2922b9c1d566.png" alt="519dc35935218cfa1aab2922b9c1d566"></p><ul><li><p>机器自己决定输出的output数量，又叫Seq2Seq任务</p><p><img src="D:\BlogFile\source\_posts\自注意力机制-Self-Attention.assets\fc0e73b3b63ab324047ee54838ffa6b8.png" alt="fc0e73b3b63ab324047ee54838ffa6b8"></p></li></ul><p>对于以往的情况，若是直接运用Fully connected network，则会出现输入信息无顺序性的情况，这种情况就不能运用有顺序的信息，如语句、时序信息等，</p><p><img src="D:\BlogFile\source\_posts\自注意力机制-Self-Attention.assets\image-20240708203700532.png" alt="image-20240708203700532"></p><p>为了解决这个问题，在Fully connected network前面加入一个Self-attention机制，这样就可以考虑输入信号的Sequence连贯性，不是信息的局部性而是整体性。而且Self-attention模块并不仅仅只能加入到整个模型的最前方，在FC与FC之间也可以添加。</p><p><img src="D:\BlogFile\source\_posts\自注意力机制-Self-Attention.assets\image-20240708204027574.png" alt="image-20240708204027574"></p><p>如图，这是Self-attention内部的简单实现，这样就可以考虑整个Sequence来输出一个Sequence。</p><p><img src="D:\BlogFile\source\_posts\自注意力机制-Self-Attention.assets\image-20240708204208371.png" alt="image-20240708204208371"></p><p>若想得到输出的信息，如b1向量，需要找出a1和其他哪些信息是相关的，相关的程度α大小是多少。</p><p>计算相关度的方法，可以由以下模块来实现</p><p><img src="D:\BlogFile\source\_posts\自注意力机制-Self-Attention.assets\image-20240708204430516.png" alt="image-20240708204430516"></p><p>左面是最常用的方法，对于两个输入信息，分别进行Wq与Wk的矩阵相乘，得到q与k，再进行点乘，得到α，右边则将两个矩阵相乘的结果进行相加后放入到tanh函数中，来与W矩阵相乘得到α。</p><p><img src="D:\BlogFile\source\_posts\自注意力机制-Self-Attention.assets\image-20240708204818516.png" alt="image-20240708204818516"></p><p>dot-product中的query和key是通过将a1和Wq相乘，得到q1，Wk和a2相乘得到k2，再让q1和k2点乘得到α1,2（叫做attention score），最后再接一个softmax模块来标准化得到α`，但是softmax模块并不是必须的，也可以接Relu等。</p><p><img src="D:\BlogFile\source\_posts\自注意力机制-Self-Attention.assets\image-20240708205229517.png" alt="image-20240708205229517"></p><p>为了提取出相关性，再将a与Wv相乘，得到v信息，然后再将v与α相乘再相加，得到b信息。</p><p><img src="D:\BlogFile\source\_posts\自注意力机制-Self-Attention.assets\image-20240708205419310.png" alt="image-20240708205419310"></p><p>对于b1，b2，b3等信息，它们是并行输出的，故没有先后的顺序性。</p><p><img src="D:\BlogFile\source\_posts\自注意力机制-Self-Attention.assets\image-20240708205850709.png" alt="image-20240708205850709"></p><p>根据q，k，v的计算公式，将其整合为一个矩阵，得到Q，K，V矩阵，</p><p><img src="D:\BlogFile\source\_posts\自注意力机制-Self-Attention.assets\image-20240708210101186.png" alt="image-20240708210101186"></p><p>接着将K矩阵转置后与Q相乘，得到分数矩阵A，再进行softmax得到A`。</p><p><img src="D:\BlogFile\source\_posts\自注意力机制-Self-Attention.assets\image-20240708210238361.png" alt="image-20240708210238361"></p><p>再将V矩阵和A`矩阵相乘，最后得到O矩阵，这样就得到了b信息的输出了，这个过程中的W矩阵是模型训练得到的。</p><p><img src="D:\BlogFile\source\_posts\自注意力机制-Self-Attention.assets\image-20240708210557402.png" alt="image-20240708210557402"></p><p>对于Multi-head Self-attention的话，则需要更多的qkv来表示新的种类。</p><p>但是以上这种方式也缺少了位置信息，故采用Postional Encoding方法来解决这个问题，即向a信息上添加e信息。</p><p><img src="D:\BlogFile\source\_posts\自注意力机制-Self-Attention.assets\image-20240708211233152.png" alt="image-20240708211233152"></p><p>对于语音辨识时，可能有时候不需要考虑整个声音信号，只需要考虑一部分，这样可以减少计算量，叫做Truncated Self-attention，一般来说Self-attention广泛应用在Transformer和Bert上。</p><p>Self-attention和CNN之间也有一些区别，CNN的receptive field是部分范围的，而Self-attention是整体的，可以说CNN是简化版的Self-attention，或者说Self-attention是复杂版的CNN。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CNN卷积神经网络</title>
      <link href="/2024/07/05/CNN%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
      <url>/2024/07/05/CNN%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
      
        <content type="html"><![CDATA[<h1 id="CNN神经网络"><a href="#CNN神经网络" class="headerlink" title="CNN神经网络"></a>CNN神经网络</h1><h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><h3 id="相关包的导入"><a href="#相关包的导入" class="headerlink" title="相关包的导入"></a>相关包的导入</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> ConcatDataset, DataLoader, Subset, Dataset</span><br><span class="line"><span class="keyword">from</span> torchvision.datasets <span class="keyword">import</span> DatasetFolder, VisionDataset</span><br><span class="line"><span class="keyword">from</span> tqdm.auto <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line">myseed = <span class="number">6666</span></span><br></pre></td></tr></table></figure><p>导入经典的数据分析包。torch包的整体导入，并且导入nn模块与优化器，导入data类，并设置种子。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">test_tfm = transforms.Compose([</span><br><span class="line">    transforms.Resize((<span class="number">128</span>, <span class="number">128</span>)),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">])</span><br></pre></td></tr></table></figure><p>构建<code>test_tfm()</code>，其是一个transform的组合结构，包括将图片大小强制转换为128*128，同时将图像的通道顺序从 HWC（高度、宽度、通道）转换为 CHW（通道、高度、宽度），变为tensor张量类型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">train_tfm = transforms.Compose([</span><br><span class="line">    transforms.Resize((<span class="number">128</span>, <span class="number">128</span>)),</span><br><span class="line">     transforms.RandomChoice(transforms=[</span><br><span class="line">        transforms.TrivialAugmentWide(),</span><br><span class="line">        transforms.Lambda(<span class="keyword">lambda</span> x: x),</span><br><span class="line">    ],</span><br><span class="line">                            p=[<span class="number">0.9</span>, <span class="number">0.1</span>]),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">])</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><code>transforms.TrivialAugmentWide()</code>：使用 TrivialAugmentWide 方法对图像进行数据增强。这种方法会随机应用各种图像增强操作，如旋转、翻转、颜色调整等。<code>transforms.Lambda(lambda x: x)</code>：返回原始图像，即不做任何变换。概率分别为0.9和0.1。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">FoodDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,path,tfm=test_tfm,files = <span class="literal">None</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(FoodDataset).__init__()</span><br><span class="line">        self.path = path</span><br><span class="line">        self.files = <span class="built_in">sorted</span>([os.path.join(path,x) <span class="keyword">for</span> x <span class="keyword">in</span> os.listdir(path) <span class="keyword">if</span> x.endswith(<span class="string">&quot;.jpg&quot;</span>)])</span><br><span class="line">        <span class="keyword">if</span> files != <span class="literal">None</span>:</span><br><span class="line">            self.files = files</span><br><span class="line">            </span><br><span class="line">        self.transform = tfm</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.files)</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self,idx</span>):</span><br><span class="line">        fname = self.files[idx]</span><br><span class="line">        im = Image.<span class="built_in">open</span>(fname)</span><br><span class="line">        im = self.transform(im)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            label = <span class="built_in">int</span>(fname.split(<span class="string">&quot;/&quot;</span>)[-<span class="number">1</span>].split(<span class="string">&quot;_&quot;</span>)[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            label = -<span class="number">1</span> </span><br><span class="line">            </span><br><span class="line">        <span class="keyword">return</span> im,label</span><br></pre></td></tr></table></figure><p>定义<code>FoodDataset</code>类，<code>__init__()</code>析构函数用来初始化数据，<code>__len__()</code>用来获得数据集的整个大小，<code>__getitem__()</code>用来获得具体index下的数据文件，并返回transform后的图像。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Classifier</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Classifier, self).__init__()</span><br><span class="line">        <span class="comment"># torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)</span></span><br><span class="line">        <span class="comment"># torch.nn.MaxPool2d(kernel_size, stride, padding)</span></span><br><span class="line">        <span class="comment"># input 維度 [3, 128, 128]</span></span><br><span class="line">        self.cnn = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">3</span>, <span class="number">64</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>),  <span class="comment"># [64, 128, 128]</span></span><br><span class="line">            nn.BatchNorm2d(<span class="number">64</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>),      <span class="comment"># [64, 64, 64]</span></span><br><span class="line"></span><br><span class="line">            nn.Conv2d(<span class="number">64</span>, <span class="number">128</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>), <span class="comment"># [128, 64, 64]</span></span><br><span class="line">            nn.BatchNorm2d(<span class="number">128</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>),      <span class="comment"># [128, 32, 32]</span></span><br><span class="line"></span><br><span class="line">            nn.Conv2d(<span class="number">128</span>, <span class="number">256</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>), <span class="comment"># [256, 32, 32]</span></span><br><span class="line">            nn.BatchNorm2d(<span class="number">256</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>),      <span class="comment"># [256, 16, 16]</span></span><br><span class="line"></span><br><span class="line">            nn.Conv2d(<span class="number">256</span>, <span class="number">512</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>), <span class="comment"># [512, 16, 16]</span></span><br><span class="line">            nn.BatchNorm2d(<span class="number">512</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>),       <span class="comment"># [512, 8, 8]</span></span><br><span class="line">            </span><br><span class="line">            nn.Conv2d(<span class="number">512</span>, <span class="number">512</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>), <span class="comment"># [512, 8, 8]</span></span><br><span class="line">            nn.BatchNorm2d(<span class="number">512</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>),       <span class="comment"># [512, 4, 4]</span></span><br><span class="line">        )</span><br><span class="line">        self.fc = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">512</span>*<span class="number">4</span>*<span class="number">4</span>, <span class="number">1024</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">1024</span>, <span class="number">512</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">11</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        out = self.cnn(x)</span><br><span class="line">        out = out.view(out.size()[<span class="number">0</span>], -<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> self.fc(out)</span><br></pre></td></tr></table></figure><p>定义CNN的model</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">device = <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span></span><br><span class="line">model = Classifier().to(device)</span><br><span class="line">batch_size = <span class="number">64</span></span><br><span class="line">n_epochs = <span class="number">24</span> </span><br><span class="line">patience = <span class="number">300</span></span><br><span class="line">loss_fn = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=<span class="number">0.0003</span>, weight_decay=<span class="number">1e-5</span>)</span><br></pre></td></tr></table></figure><p>如果电脑有cuda，那么用cuda来训练，否则用cpu，同时定义model对象，batch_size，n_epoches与patience，定义Adam优化器来优化，其中学习率为0.0003，传播率为0.00001，patience为耐心轮数，loss_fn为损失函数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train_set = FoodDataset(<span class="string">&quot;.../train&quot;</span>, tfm=train_tfm)</span><br><span class="line">train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=<span class="literal">True</span>, num_workers=<span class="number">0</span>, pin_memory=<span class="literal">True</span>)</span><br><span class="line">valid_set = FoodDataset(<span class="string">&quot;.../valid&quot;</span>, tfm=test_tfm)</span><br><span class="line">valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=<span class="literal">True</span>, num_workers=<span class="number">0</span>, pin_memory=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>定义train_set和loader，valid_set和loader，分别为训练集和验证集。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line">stale = <span class="number">0</span></span><br><span class="line">best_acc = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(n_epochs):</span><br><span class="line"></span><br><span class="line">    model.train()</span><br><span class="line"></span><br><span class="line">    train_loss = []</span><br><span class="line">    train_accs = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> batch <span class="keyword">in</span> tqdm(train_loader):</span><br><span class="line"></span><br><span class="line">        imgs, labels = batch</span><br><span class="line"></span><br><span class="line">        logits = model(imgs.to(device))</span><br><span class="line"></span><br><span class="line">        loss = criterion(logits, labels.to(device))</span><br><span class="line"></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line"></span><br><span class="line">        grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=<span class="number">10</span>)</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        acc = (logits.argmax(dim=-<span class="number">1</span>) == labels.to(device)).<span class="built_in">float</span>().mean()</span><br><span class="line"></span><br><span class="line">        train_loss.append(loss.item())</span><br><span class="line">        train_accs.append(acc)</span><br><span class="line">        </span><br><span class="line">    train_loss = <span class="built_in">sum</span>(train_loss) / <span class="built_in">len</span>(train_loss)</span><br><span class="line">    train_acc = <span class="built_in">sum</span>(train_accs) / <span class="built_in">len</span>(train_accs)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;[ Train | <span class="subst">&#123;epoch + <span class="number">1</span>:03d&#125;</span>/<span class="subst">&#123;n_epochs:03d&#125;</span> ] loss = <span class="subst">&#123;train_loss:<span class="number">.5</span>f&#125;</span>, acc = <span class="subst">&#123;train_acc:<span class="number">.5</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    valid_loss = []</span><br><span class="line">    valid_accs = []</span><br><span class="line">    <span class="keyword">for</span> imgs, labels <span class="keyword">in</span> tqdm(valid_loader):</span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            logits = model(imgs.to(device))</span><br><span class="line">        loss = loss_fn(logits, labels.to(device))</span><br><span class="line">        acc = (logits.argmax(dim=-<span class="number">1</span>) == labels.to(device)).<span class="built_in">float</span>().mean()</span><br><span class="line"></span><br><span class="line">        valid_loss.append(loss.item())</span><br><span class="line">        valid_accs.append(acc)</span><br><span class="line"></span><br><span class="line">    valid_loss = <span class="built_in">sum</span>(valid_loss) / <span class="built_in">len</span>(valid_loss)</span><br><span class="line">    valid_acc = <span class="built_in">sum</span>(valid_accs) / <span class="built_in">len</span>(valid_accs)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;[ Valid | <span class="subst">&#123;epoch + <span class="number">1</span>:03d&#125;</span>/<span class="subst">&#123;n_epochs:03d&#125;</span> ] loss = <span class="subst">&#123;valid_loss:<span class="number">.5</span>f&#125;</span>, acc = <span class="subst">&#123;valid_acc:<span class="number">.5</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> valid_acc &gt; best_acc:</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">f&quot;./<span class="subst">&#123;_exp_name&#125;</span>_log.txt&quot;</span>,<span class="string">&quot;a&quot;</span>):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;[ Valid | <span class="subst">&#123;epoch + <span class="number">1</span>:03d&#125;</span>/<span class="subst">&#123;n_epochs:03d&#125;</span> ] loss = <span class="subst">&#123;valid_loss:<span class="number">.5</span>f&#125;</span>, acc = <span class="subst">&#123;valid_acc:<span class="number">.5</span>f&#125;</span> -&gt; best&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">f&quot;./<span class="subst">&#123;_exp_name&#125;</span>_log.txt&quot;</span>,<span class="string">&quot;a&quot;</span>):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;[ Valid | <span class="subst">&#123;epoch + <span class="number">1</span>:03d&#125;</span>/<span class="subst">&#123;n_epochs:03d&#125;</span> ] loss = <span class="subst">&#123;valid_loss:<span class="number">.5</span>f&#125;</span>, acc = <span class="subst">&#123;valid_acc:<span class="number">.5</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> valid_acc &gt; best_acc:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Best model found at epoch <span class="subst">&#123;epoch&#125;</span>, saving model&quot;</span>)</span><br><span class="line">        torch.save(model.state_dict(), <span class="string">f&quot;<span class="subst">&#123;_exp_name&#125;</span>_best.ckpt&quot;</span>)</span><br><span class="line">        best_acc = valid_acc</span><br><span class="line">        stale = <span class="number">0</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        stale += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> stale &gt; patience:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;No improvment <span class="subst">&#123;patience&#125;</span> consecutive epochs, early stopping&quot;</span>)</span><br><span class="line">            <span class="keyword">break</span></span><br></pre></td></tr></table></figure><p>开始训练,<code>stale</code>：记录连续未改善的epoch次数，用于早停机制。<code>best_acc</code>用于记录最佳验证集准确率,使用 <code>nn.utils.clip_grad_norm_</code> 可以有效防止梯度爆炸问题，确保训练过程更加稳定和收敛。这个函数通过限制梯度的最大范数，使得每次参数更新不会因为过大的梯度而发生剧烈变化。如果停滞轮数大于耐心轮数，那么终止训练，否则保存模型。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>动态数组</title>
      <link href="/2024/06/28/%E5%8A%A8%E6%80%81%E6%95%B0%E7%BB%84/"/>
      <url>/2024/06/28/%E5%8A%A8%E6%80%81%E6%95%B0%E7%BB%84/</url>
      
        <content type="html"><![CDATA[<h1 id="动态数组"><a href="#动态数组" class="headerlink" title="动态数组"></a>动态数组</h1><p>数组是一组元素组成的数据结构，每个元素至少有一个index或key来标识。</p><p>数组的元素是连续存储，所以地址可以通过index索引来计算出来。</p><p>通过数组的起始地址<em>BaseAddress</em>，我们可以通过公式<em>BaseAddress</em> + i*size来计算出索引i元素的地址，其中i位索引，size为每个元素所占字节大小。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span>[] array = &#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>&#125;;</span><br></pre></td></tr></table></figure><h1 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h1><h2 id="空间占用"><a href="#空间占用" class="headerlink" title="空间占用"></a>空间占用</h2><p>Java中数组结构有8字节的markword，4字节的class指针，4字节的数组大小（Java中所有对象大小都是8字节的整数倍，不足的话要对齐字节补足）</p><p>例如</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span>[] array = &#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>&#125;;</span><br></pre></td></tr></table></figure><p>那么其大小为40字节，8 + 4 + 4 + 5*4 + 4(alignment)，其中的alignment是用补充整体为8的倍数的。</p><h2 id="随机访问"><a href="#随机访问" class="headerlink" title="随机访问"></a>随机访问</h2><p>根据索引查找元素，时间复杂度为O(1)。</p><h1 id="基础代码实现"><a href="#基础代码实现" class="headerlink" title="基础代码实现"></a>基础代码实现</h1><p>如果想实现一个最基本的动态数组，那么其中要有的属性有：这个动态数组的容量大小与实际逻辑大小，而静态数组往往是已经设定好，且不可以扩容的，为此我们若想用静态数组为根本来实现动态数组，我们需要判断如果逻辑大小大于容量大小，则需要创建一个新的静态数组，且这个新的静态数组的容量大小要大于所需数组的逻辑大小，其中我们用到的一个方法叫做<em>arraycopy( )</em>，使用用法为：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">System.arraycopy(ori_array, ori_index, new_array, new_index, size);</span><br></pre></td></tr></table></figure><p>其中<code>ori_array</code>为源数组，<code>ori_index</code>为复制的起始index，<code>new_array</code>为目标数组，<code>new_index</code>为要复制到的目标index，<code>size</code>为要复制的大小。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">DynamicArray</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> <span class="variable">size</span> <span class="operator">=</span> <span class="number">0</span>; <span class="comment">// 逻辑大小</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> <span class="variable">capacity</span> <span class="operator">=</span> <span class="number">8</span>; <span class="comment">// 容量</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span>[] array = <span class="keyword">new</span> <span class="title class_">int</span>[capacity];</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">addLast</span><span class="params">(<span class="type">int</span> element)</span>&#123;</span><br><span class="line">        add(size,element);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">add</span><span class="params">(<span class="type">int</span> index,<span class="type">int</span> element)</span>&#123; <span class="comment">// index为要插入的位置</span></span><br><span class="line">        <span class="keyword">if</span>(index &gt;= <span class="number">0</span> &amp;&amp; index &lt; size) &#123;</span><br><span class="line">            System.arraycopy(array, index, array, index + <span class="number">1</span>, size - index); </span><br><span class="line">        &#125; <span class="comment">// 这里的add方法包括了addLast方法</span></span><br><span class="line">        array[index] = element;</span><br><span class="line">        size++;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>arraycopy方法从index开始拷贝，目标数组还是array，拷贝到目标数组的起始位置为index + 1，拷贝的元素为index后面的元素均右移一位，故size - index个数，这样实现了要插入的数组的初始化，即从原来的(1,2,3,4,5,6)变为了(1,2,3,3,4,5,6)，这里假设index为2，然后在index=2处插入你想要的元素。</p><h2 id="功能拓展"><a href="#功能拓展" class="headerlink" title="功能拓展"></a>功能拓展</h2><p>为了想看明白这个数组的实现情况，我们想知道内部究竟发生了什么，但又不能直接将私有属性capacity与size展示出来，为此我们提供两种方法来对外展示，一种是遍历循环，另一种是索引查找。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="type">int</span> <span class="title function_">get</span><span class="params">(<span class="type">int</span> index)</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> array[index];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">forEach</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; size; i++) &#123;</span><br><span class="line">            System.out.println(array[i]);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>get方法用来实现特定index的元素查询，而forEach方法实现所有元素的查看</p>]]></content>
      
      
      
        <tags>
            
            <tag> 数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习的一般框架（鸟与飞机举例）</title>
      <link href="/2024/06/04/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%B8%80%E8%88%AC%E6%A1%86%E6%9E%B6%EF%BC%88%E9%B8%9F%E4%B8%8E%E9%A3%9E%E6%9C%BA%E4%B8%BE%E4%BE%8B%EF%BC%89/"/>
      <url>/2024/06/04/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%B8%80%E8%88%AC%E6%A1%86%E6%9E%B6%EF%BC%88%E9%B8%9F%E4%B8%8E%E9%A3%9E%E6%9C%BA%E4%B8%BE%E4%BE%8B%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h1 id="深度学习"><a href="#深度学习" class="headerlink" title="深度学习"></a>深度学习</h1><h2 id="相关包的导入与种子设置"><a href="#相关包的导入与种子设置" class="headerlink" title="相关包的导入与种子设置"></a>相关包的导入与种子设置</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> collections</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line">torch.set_printoptions(edgeitems=<span class="number">2</span>)</span><br><span class="line">torch.manual_seed(<span class="number">123</span>)</span><br></pre></td></tr></table></figure><h2 id="类名规定"><a href="#类名规定" class="headerlink" title="类名规定"></a>类名规定</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">class_names = [<span class="string">&#x27;airplane&#x27;</span>,<span class="string">&#x27;automobile&#x27;</span>,<span class="string">&#x27;bird&#x27;</span>,<span class="string">&#x27;cat&#x27;</span>,<span class="string">&#x27;deer&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;dog&#x27;</span>,<span class="string">&#x27;frog&#x27;</span>,<span class="string">&#x27;horse&#x27;</span>,<span class="string">&#x27;ship&#x27;</span>,<span class="string">&#x27;truck&#x27;</span>]</span><br></pre></td></tr></table></figure><h2 id="构建训练集与测试集"><a href="#构建训练集与测试集" class="headerlink" title="构建训练集与测试集"></a>构建训练集与测试集</h2><p>这里为了简化，将tranform提供的转换张量与标准化直接放在数据集cifar10中，其为训练集，若地址中没有该数据则Pytorch自动下载。划分两种集合类别的参数为train是否为False或True。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, transforms</span><br><span class="line">data_path = <span class="string">&#x27;../data/&#x27;</span></span><br><span class="line">cifar10 = datasets.CIFAR10(</span><br><span class="line">    data_path, train=<span class="literal">True</span>, download=<span class="literal">True</span>,</span><br><span class="line">    transform=transforms.Compose([</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize((<span class="number">0.4915</span>, <span class="number">0.4823</span>, <span class="number">0.4468</span>),</span><br><span class="line">                             (<span class="number">0.2470</span>, <span class="number">0.2435</span>, <span class="number">0.2616</span>))</span><br><span class="line">    ]))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cifar10_val = datasets.CIFAR10(</span><br><span class="line">    data_path, train=<span class="literal">False</span>, download=<span class="literal">True</span>,</span><br><span class="line">    transform=transforms.Compose([</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize((<span class="number">0.4915</span>, <span class="number">0.4823</span>, <span class="number">0.4468</span>),</span><br><span class="line">                             (<span class="number">0.2470</span>, <span class="number">0.2435</span>, <span class="number">0.2616</span>))</span><br><span class="line">    ]))</span><br></pre></td></tr></table></figure><p>因为这里仅仅是鸟与飞机的划分，而cifar10是一个包含很多种类的数据集，故进行切割</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">label_map = &#123;<span class="number">0</span>: <span class="number">0</span>, <span class="number">2</span>: <span class="number">1</span>&#125;</span><br><span class="line">class_names = [<span class="string">&#x27;airplane&#x27;</span>, <span class="string">&#x27;bird&#x27;</span>]</span><br><span class="line">cifar2 = [(img, label_map[label])</span><br><span class="line">          <span class="keyword">for</span> img, label <span class="keyword">in</span> cifar10</span><br><span class="line">          <span class="keyword">if</span> label <span class="keyword">in</span> [<span class="number">0</span>, <span class="number">2</span>]]</span><br><span class="line">cifar2_val = [(img, label_map[label])</span><br><span class="line">              <span class="keyword">for</span> img, label <span class="keyword">in</span> cifar10_val</span><br><span class="line">              <span class="keyword">if</span> label <span class="keyword">in</span> [<span class="number">0</span>, <span class="number">2</span>]]</span><br></pre></td></tr></table></figure><p>以下是自定义一个自己的模块</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Net</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">16</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">16</span>, <span class="number">8</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">8</span> * <span class="number">8</span> * <span class="number">8</span>, <span class="number">32</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">32</span>, <span class="number">2</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        out = F.max_pool2d(torch.tanh(self.conv1(x)), <span class="number">2</span>)</span><br><span class="line">        out = F.max_pool2d(torch.tanh(self.conv2(out)), <span class="number">2</span>)</span><br><span class="line">        out = out.view(-<span class="number">1</span>, <span class="number">8</span> * <span class="number">8</span> * <span class="number">8</span>)</span><br><span class="line">        out = torch.tanh(self.fc1(out))</span><br><span class="line">        out = self.fc2(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure><p>以下代码为核心循环步骤</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">model = Net()</span><br><span class="line"><span class="keyword">import</span> datetime  </span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">training_loop</span>(<span class="params">n_epochs, optimizer, model, loss_fn, train_loader</span>):</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n_epochs + <span class="number">1</span>): </span><br><span class="line">        loss_train = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> imgs, labels <span class="keyword">in</span> train_loader:  </span><br><span class="line">            </span><br><span class="line">            outputs = model(imgs) </span><br><span class="line">            loss = loss_fn(outputs, labels)  </span><br><span class="line">            optimizer.zero_grad()  </span><br><span class="line">            loss.backward()  </span><br><span class="line">            optimizer.step()  </span><br><span class="line">            loss_train += loss.item()  </span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> epoch == <span class="number">1</span> <span class="keyword">or</span> epoch % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;&#123;&#125; Epoch &#123;&#125;, Training loss &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">                datetime.datetime.now(), epoch,</span><br><span class="line">                loss_train / <span class="built_in">len</span>(train_loader))) </span><br><span class="line">            </span><br><span class="line">train_loader = torch.utils.data.DataLoader(cifar2, batch_size=<span class="number">64</span>,</span><br><span class="line">                                           shuffle=<span class="literal">True</span>) </span><br><span class="line"></span><br><span class="line">model = Net()  </span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="number">1e-2</span>)  </span><br><span class="line">loss_fn = nn.CrossEntropyLoss()  </span><br><span class="line"></span><br><span class="line">training_loop(  </span><br><span class="line">    n_epochs = <span class="number">100</span>,</span><br><span class="line">    optimizer = optimizer,</span><br><span class="line">    model = model,</span><br><span class="line">    loss_fn = loss_fn,</span><br><span class="line">    train_loader = train_loader,</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>验证函数代码为</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">train_loader = torch.utils.data.DataLoader(cifar2, batch_size=<span class="number">64</span>,</span><br><span class="line">                                           shuffle=<span class="literal">False</span>)</span><br><span class="line">val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=<span class="number">64</span>,</span><br><span class="line">                                         shuffle=<span class="literal">False</span>)</span><br><span class="line">all_acc_dict = collections.OrderedDict()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">validate</span>(<span class="params">model, train_loader, val_loader</span>):</span><br><span class="line">    accdict = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> name, loader <span class="keyword">in</span> [(<span class="string">&quot;train&quot;</span>, train_loader), (<span class="string">&quot;val&quot;</span>, val_loader)]:</span><br><span class="line">        correct = <span class="number">0</span></span><br><span class="line">        total = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            <span class="keyword">for</span> imgs, labels <span class="keyword">in</span> loader:</span><br><span class="line">                imgs = imgs.to(device=device)</span><br><span class="line">                labels = labels.to(device=device)</span><br><span class="line">                outputs = model(imgs)</span><br><span class="line">                _, predicted = torch.<span class="built_in">max</span>(outputs, dim=<span class="number">1</span>) <span class="comment"># &lt;1&gt;</span></span><br><span class="line">                total += labels.shape[<span class="number">0</span>]</span><br><span class="line">                correct += <span class="built_in">int</span>((predicted == labels).<span class="built_in">sum</span>())</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Accuracy &#123;&#125;: &#123;:.2f&#125;&quot;</span>.<span class="built_in">format</span>(name , correct / total))</span><br><span class="line">        accdict[name] = correct / total</span><br><span class="line">    <span class="keyword">return</span> accdict</span><br><span class="line"></span><br><span class="line">all_acc_dict[<span class="string">&quot;baseline&quot;</span>] = validate(model, train_loader, val_loader)</span><br></pre></td></tr></table></figure><p>这是另一个自定义模块</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">NetResDeep</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, n_chans1=<span class="number">32</span>, n_blocks=<span class="number">10</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.n_chans1 = n_chans1</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>, n_chans1, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.resblocks = nn.Sequential(</span><br><span class="line">            *(n_blocks * [ResBlock(n_chans=n_chans1)]))</span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">8</span> * <span class="number">8</span> * n_chans1, <span class="number">32</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">32</span>, <span class="number">2</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        out = F.max_pool2d(torch.relu(self.conv1(x)), <span class="number">2</span>)</span><br><span class="line">        out = self.resblocks(out)</span><br><span class="line">        out = F.max_pool2d(out, <span class="number">2</span>)</span><br><span class="line">        out = out.view(-<span class="number">1</span>, <span class="number">8</span> * <span class="number">8</span> * self.n_chans1)</span><br><span class="line">        out = torch.relu(self.fc1(out))</span><br><span class="line">        out = self.fc2(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">model = NetResDeep(n_chans1=<span class="number">32</span>, n_blocks=<span class="number">100</span>).to(device=device)</span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="number">3e-3</span>)</span><br><span class="line">loss_fn = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line">training_loop(</span><br><span class="line">    n_epochs = <span class="number">100</span>,</span><br><span class="line">    optimizer = optimizer,</span><br><span class="line">    model = model,</span><br><span class="line">    loss_fn = loss_fn,</span><br><span class="line">    train_loader = train_loader,</span><br><span class="line">)</span><br><span class="line">all_acc_dict[<span class="string">&quot;res deep&quot;</span>] = validate(model, train_loader, val_loader)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于Python的推箱子小游戏实现</title>
      <link href="/2024/05/30/%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E6%8E%A8%E7%AE%B1%E5%AD%90%E5%B0%8F%E6%B8%B8%E6%88%8F%E5%AE%9E%E7%8E%B0/"/>
      <url>/2024/05/30/%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E6%8E%A8%E7%AE%B1%E5%AD%90%E5%B0%8F%E6%B8%B8%E6%88%8F%E5%AE%9E%E7%8E%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="推箱子小游戏项目的实现"><a href="#推箱子小游戏项目的实现" class="headerlink" title="推箱子小游戏项目的实现"></a>推箱子小游戏项目的实现</h1><p>项目来源：四川大学2023-2024年Python程序设计基础的期末大作业，素材均为学校提供。</p><h4 id="代码："><a href="#代码：" class="headerlink" title="代码："></a>代码：</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> pygame</span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">pygame.init()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 常量定义</span></span><br><span class="line">SUM = <span class="number">0</span></span><br><span class="line">TILE_SIZE = <span class="number">33</span></span><br><span class="line">SCREEN_WIDTH = <span class="number">462</span>  <span class="comment"># 14个横格</span></span><br><span class="line">WIDTH_NUM = SCREEN_WIDTH // TILE_SIZE</span><br><span class="line">SCREEN_HEIGHT = <span class="number">330</span>  <span class="comment"># 10个竖格</span></span><br><span class="line">HEIGHT_NUM = SCREEN_HEIGHT // TILE_SIZE</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取对象</span></span><br><span class="line">player_image = pygame.transform.scale(pygame.image.load(<span class="string">r&#x27;C:\Users\赵洪锐\Downloads\bmp\bmp\Bmp14.gif&#x27;</span>),</span><br><span class="line">                                      (TILE_SIZE, TILE_SIZE))</span><br><span class="line">box_image = pygame.transform.scale(pygame.image.load(<span class="string">r&#x27;C:\Users\赵洪锐\Downloads\bmp\bmp\Bmp3.gif&#x27;</span>),</span><br><span class="line">                                   (TILE_SIZE, TILE_SIZE))</span><br><span class="line">target_image = pygame.transform.scale(pygame.image.load(<span class="string">r&#x27;C:\Users\赵洪锐\Downloads\bmp\bmp\Bmp5.gif&#x27;</span>),</span><br><span class="line">                                      (TILE_SIZE, TILE_SIZE))</span><br><span class="line">wall_image = pygame.transform.scale(pygame.image.load(<span class="string">r&#x27;C:\Users\赵洪锐\Downloads\bmp\bmp\Bmp1.gif&#x27;</span>),</span><br><span class="line">                                    (TILE_SIZE, TILE_SIZE))</span><br><span class="line">floor_image = pygame.transform.scale(pygame.image.load(<span class="string">r&#x27;C:\Users\赵洪锐\Downloads\bmp\bmp\Bmp2.gif&#x27;</span>),</span><br><span class="line">                                     (TILE_SIZE, TILE_SIZE))</span><br><span class="line">background_image = pygame.transform.scale(pygame.image.load(<span class="string">r&#x27;C:\Users\赵洪锐\Downloads\bmp\bmp\Bmp0.gif&#x27;</span>),</span><br><span class="line">                                          (TILE_SIZE, TILE_SIZE))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 窗口展示</span></span><br><span class="line">screen = pygame.display.set_mode((SCREEN_WIDTH, SCREEN_HEIGHT))</span><br><span class="line">pygame.display.set_caption(<span class="string">&#x27;推箱子の小游戏&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 关卡变量  0表示地板 1表示墙 2表示目标 3表示箱子 4表示玩家 5表示背景</span></span><br><span class="line">levels = [</span><br><span class="line">    [[<span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>]],</span><br><span class="line"></span><br><span class="line">    [[<span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>]],</span><br><span class="line"></span><br><span class="line">    [[<span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>,<span class="number">5</span>]],</span><br><span class="line"></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 当前关卡</span></span><br><span class="line">current_level = <span class="number">0</span></span><br><span class="line"><span class="built_in">map</span> = copy.deepcopy(levels[current_level])</span><br></pre></td></tr></table></figure><p>引入Python的标准库sys、copy和time，以及第三方库pygame。这些库提供了如系统退出、对象深拷贝和时间记录的功能，并且初始化Pygame库，准备使用其功能。</p><p>1.1定义常量：</p><p>TILE_SIZE表示每个图块的尺寸。</p><p>SCREEN_WIDTH和SCREEN_HEIGHT表示窗口的宽和高。</p><p>WIDTH_NUM和HEIGHT_NUM通过屏幕尺寸除以图块尺寸计算出屏幕可以容纳的横向和纵向图块数。</p><p>1.2 导入图片：</p><p>使用Pygame的pygame.image.load函数加载游戏所需的图像资源。</p><p>使用pygame.transform.scale函数将这些图像缩放到合适的大小（即图块大小TILE_SIZE）。</p><p>1.3 备注说明：</p><p>由于Bmp图片中大多数格式的像素为33x33，而少部分图片的像素尺寸不统一，比如有34x37，为统一格式，便在导入图片的时候进行图片裁剪，使所有导入的图片均为33x33，这样在设定屏幕长度与宽度时可以更方便的计算图块，避免出现白边的情况发生。并且文件夹中存在重复的图片，故从中任意选择一个。</p><p>pygame.display.set_mode创建一个窗口，大小SCREEN_WIDTH与SCREEN_HEIGHT。</p><p>pygame.display.set_caption是设置窗口的标题，命名为”推箱子の小游戏”。</p><p>定义多个关卡，每个关卡使用一个二维列表表示，其中数字表示不同类型的地块。使用copy.deepcopy复制选定的关卡数据，防止后续修改影响原始数据。这里设置初始的三关，后续可在其中进行拓展添加。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 物体替换</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">movePlayer</span>(<span class="params">dx, dy</span>):</span><br><span class="line">    <span class="keyword">global</span> player_pos</span><br><span class="line">    new_x = player_pos[<span class="number">1</span>] + dx</span><br><span class="line">    new_y = player_pos[<span class="number">0</span>] + dy</span><br><span class="line">    <span class="keyword">if</span> new_x &lt; <span class="number">0</span> <span class="keyword">or</span> new_x &gt;= WIDTH_NUM <span class="keyword">or</span> new_y &lt; <span class="number">0</span> <span class="keyword">or</span> new_y &gt;= HEIGHT_NUM:</span><br><span class="line">        <span class="keyword">return</span>  <span class="comment"># 边界检查</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">map</span>[new_y][new_x] == <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span>  <span class="comment"># 遇到墙，停止移动</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">map</span>[new_y][new_x] == <span class="number">3</span>:  <span class="comment"># 遇到箱子</span></span><br><span class="line">        box_new_x = new_x + dx</span><br><span class="line">        box_new_y = new_y + dy</span><br><span class="line">        <span class="keyword">if</span> box_new_x &lt; <span class="number">0</span> <span class="keyword">or</span> box_new_x &gt;= WIDTH_NUM <span class="keyword">or</span> box_new_y &lt; <span class="number">0</span> <span class="keyword">or</span> box_new_y &gt;= HEIGHT_NUM:</span><br><span class="line">            <span class="keyword">return</span>  <span class="comment"># 边界检查</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">map</span>[box_new_y][box_new_x] <span class="keyword">in</span> [<span class="number">0</span>, <span class="number">2</span>]:  <span class="comment"># 箱子前面是地板或目标</span></span><br><span class="line">            <span class="built_in">map</span>[box_new_y][box_new_x] = <span class="number">3</span></span><br><span class="line">            <span class="built_in">map</span>[new_y][new_x] = <span class="number">0</span> <span class="keyword">if</span> levels[current_level][new_y][new_x] != <span class="number">2</span> <span class="keyword">else</span> <span class="number">2</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span>  <span class="comment"># 箱子前面是墙或另一个箱子，停止移动</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">map</span>[player_pos[<span class="number">0</span>]][player_pos[<span class="number">1</span>]] = <span class="number">0</span> <span class="keyword">if</span> levels[current_level][player_pos[<span class="number">0</span>]][player_pos[<span class="number">1</span>]] != <span class="number">2</span> <span class="keyword">else</span> <span class="number">2</span>  <span class="comment"># 恢复地板或目标</span></span><br><span class="line">    player_pos = [new_y, new_x]</span><br><span class="line">    <span class="built_in">map</span>[player_pos[<span class="number">0</span>]][player_pos[<span class="number">1</span>]] = <span class="number">4</span>  <span class="comment"># 更新玩家新位置</span></span><br></pre></td></tr></table></figure><p>movePlayer（）是实现玩家的移动逻辑的函数，其职责是实现玩家角色的移动逻辑，包括边界检查、碰撞检测和更新地图状态。函数接受两个参数 dx 和 dy，分别表示玩家在x轴和y轴上的移动距离。</p><p>1.1参数定义和初始位置计算：</p><p>函数接受两个参数 dx 和 dy，分别表示玩家在x轴和y轴上的移动距离。通过这两个参数，函数计算出玩家的新位置 new_x 和 new_y。</p><p>1.2 边界检查与碰撞检测（墙壁）：</p><p>首先，函数检查玩家的新位置是否超出地图边界。如果新位置超出边界，函数立即返回，停止移动。接着，函数检查玩家的新位置是否遇到墙壁（值为1）。如果新位置是墙壁，函数 返回，停止移动。</p><p>1.3 碰撞检测（箱子）与地图更新：</p><p>如果玩家的新位置是箱子（值为3），函数需要进一步检查箱子的前方位置是否为空地或目标点（值为0或2）。如果箱子前方位置有效，则移动箱子，否则停止移动。如果玩家的新位置是空地或目标点，函数会更新当前地图状态，将玩家的当前位置从地图上移除，恢复为原地图上的地板或目标点。然后更新玩家的新位置。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获得玩家初始位置</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getPlayerPosition</span>():</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> <span class="built_in">range</span>(HEIGHT_NUM):</span><br><span class="line">        <span class="keyword">for</span> col <span class="keyword">in</span> <span class="built_in">range</span>(WIDTH_NUM):</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">map</span>[row][col] == <span class="number">4</span>:</span><br><span class="line">                <span class="keyword">return</span> [row, col]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">player_pos = getPlayerPosition()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获得关卡目标数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">targetNum</span>():</span><br><span class="line">    targetNums = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> <span class="built_in">range</span>(HEIGHT_NUM):</span><br><span class="line">        <span class="keyword">for</span> col <span class="keyword">in</span> <span class="built_in">range</span>(WIDTH_NUM):</span><br><span class="line">            <span class="keyword">if</span> levels[current_level][row][col] == <span class="number">2</span>:</span><br><span class="line">                targetNums += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> targetNums</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>   getPlayerPosition ( )函数是用来负责实时获得玩家坐标的函数，通过嵌套循环遍历map来得到具体玩家位置，调用后返回具体坐标。</p><p>   targetNum ( )函数是负责遍历整个levels来得到目标点位置的函数，如果发现元素中的目标点后，targetNums会自增，调用后返回目标点或箱子的总数量。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">isAllGet</span>():</span><br><span class="line">    SUM = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> <span class="built_in">range</span>(HEIGHT_NUM):</span><br><span class="line">        <span class="keyword">for</span> col <span class="keyword">in</span> <span class="built_in">range</span>(WIDTH_NUM):</span><br><span class="line">            <span class="keyword">if</span> levels[current_level][row][col] == <span class="number">2</span> <span class="keyword">and</span> <span class="built_in">map</span>[row][col] == <span class="number">3</span>:</span><br><span class="line">                SUM += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> SUM == targetNum()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 背景替换</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">backGround</span>():</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, SCREEN_HEIGHT, TILE_SIZE):</span><br><span class="line">        <span class="keyword">for</span> col <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, SCREEN_WIDTH, TILE_SIZE):</span><br><span class="line">            screen.blit(background_image, (col, row))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印玩家</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">drawPlayer</span>():</span><br><span class="line">    screen.blit(player_image, (player_pos[<span class="number">1</span>] * TILE_SIZE, player_pos[<span class="number">0</span>] * TILE_SIZE))</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 地图布局</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mapSet</span>():</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> <span class="built_in">range</span>(HEIGHT_NUM):</span><br><span class="line">        <span class="keyword">for</span> col <span class="keyword">in</span> <span class="built_in">range</span>(WIDTH_NUM):</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">map</span>[row][col] == <span class="number">0</span>:</span><br><span class="line">                screen.blit(floor_image, (col * TILE_SIZE, row * TILE_SIZE))</span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">map</span>[row][col] == <span class="number">1</span>:</span><br><span class="line">                screen.blit(wall_image, (col * TILE_SIZE, row * TILE_SIZE))</span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">map</span>[row][col] == <span class="number">2</span>:</span><br><span class="line">                screen.blit(target_image, (col * TILE_SIZE, row * TILE_SIZE))</span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">map</span>[row][col] == <span class="number">3</span>:</span><br><span class="line">                screen.blit(box_image, (col * TILE_SIZE, row * TILE_SIZE))</span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">map</span>[row][col] == <span class="number">4</span>:</span><br><span class="line">                screen.blit(player_image, (col * TILE_SIZE, row * TILE_SIZE))</span><br></pre></td></tr></table></figure><p>mapSet ( )函数是负责实现地图元素的摆放，先通过col与row的嵌套循环（Nested Loop）实现二维数组map的遍历，得到map每个元素是多少，其次再根据if,elif 选择语句来判断不同的数字兵插入相应不同的图片，通过screen.blit ( image , ( x , y ) )来实现。x,y是在整个窗口上的坐标位置，而不是Level的位置，故要在x,y本身的基础上乘以TILE_SIZE实现元素铺垫。</p><p>backGround ( )函数是负责整体背景的铺垫的，先通过嵌套循环使用background_image进行整体窗口的摆放，之后MapSet ( )函数在其上进行细节元素的布置。</p><p>drawPlayer ( )函数是玩家绘制函数，因为本项目的逻辑是玩家的地址单独抽离出来保存在player_pos中，所以每次循环后要实时更新玩家的图像位置，这时就要调用drawPlayer ( )函数来进行更新。</p><p>isAllGet ( )_函数是用来判断游戏成功条件的，首先分别整体遍历Map副本地图与原地图Levels，这样得到原地图的目标点位置，如果在相互对应的位置上Map副本是箱子元素，Levels是目标点元素，则证明箱子推到了目标点，SUM初值为0，是用来计算箱子推到目标点的数量，推到目标点后SUM自增1，如果SUM与targetNum ( )函数返回值相同，即地图上所有的目标点都被推到了，那么游戏成功。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 游戏主循环</span></span><br><span class="line">running = <span class="literal">True</span></span><br><span class="line">paused = <span class="literal">False</span></span><br><span class="line">start_time = time.time()</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> running:</span><br><span class="line">    <span class="keyword">for</span> event <span class="keyword">in</span> pygame.event.get():</span><br><span class="line">        <span class="keyword">if</span> event.<span class="built_in">type</span> == pygame.QUIT:</span><br><span class="line">            running = <span class="literal">False</span></span><br><span class="line">        <span class="keyword">elif</span> event.<span class="built_in">type</span> == pygame.KEYDOWN:</span><br><span class="line">            <span class="keyword">if</span> event.key == pygame.K_UP:</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> paused:</span><br><span class="line">                    movePlayer(<span class="number">0</span>, -<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">elif</span> event.key == pygame.K_DOWN:</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> paused:</span><br><span class="line">                    movePlayer(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">            <span class="keyword">elif</span> event.key == pygame.K_LEFT:</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> paused:</span><br><span class="line">                    movePlayer(-<span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">elif</span> event.key == pygame.K_RIGHT:</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> paused:</span><br><span class="line">                    movePlayer(<span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">elif</span> event.key == pygame.K_r:</span><br><span class="line">                resetLevel()</span><br><span class="line">            <span class="keyword">elif</span> event.key == pygame.K_p:</span><br><span class="line">                paused = <span class="keyword">not</span> paused</span><br><span class="line">            <span class="keyword">elif</span> event.key == pygame.K_1:</span><br><span class="line">                current_level = <span class="number">0</span></span><br><span class="line">                resetLevel()</span><br><span class="line">            <span class="keyword">elif</span> event.key == pygame.K_2:</span><br><span class="line">                current_level = <span class="number">1</span></span><br><span class="line">                resetLevel()</span><br><span class="line">            <span class="keyword">elif</span> event.key == pygame.K_3:</span><br><span class="line">                current_level = <span class="number">2</span></span><br><span class="line">                resetLevel()</span><br><span class="line"></span><br><span class="line">    screen.fill((<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>))</span><br><span class="line">    backGround()</span><br><span class="line">    mapSet()</span><br><span class="line">    drawPlayer()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 显示时间和评分</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> paused:</span><br><span class="line">        elapsed_time = time.time() - start_time</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        elapsed_time = elapsed_time  <span class="comment"># 暂停时保持时间不变</span></span><br><span class="line"></span><br><span class="line">    font = pygame.font.Font(<span class="literal">None</span>, <span class="number">36</span>)</span><br><span class="line">    time_text = font.render(<span class="string">f&quot;Time: <span class="subst">&#123;<span class="built_in">int</span>(elapsed_time)&#125;</span>s&quot;</span>, <span class="literal">True</span>, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>))</span><br><span class="line">    screen.blit(time_text, (<span class="number">10</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">    rank = score(elapsed_time)</span><br><span class="line">    rank_text = font.render(<span class="string">f&quot;Rank: <span class="subst">&#123;rank&#125;</span>&quot;</span>, <span class="literal">True</span>, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>))</span><br><span class="line">    screen.blit(rank_text, (<span class="number">10</span>, <span class="number">50</span>))</span><br><span class="line"></span><br><span class="line">    pygame.display.flip()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> isAllGet():</span><br><span class="line">        current_level += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> current_level &lt; <span class="built_in">len</span>(levels):</span><br><span class="line">            resetLevel()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            running = <span class="literal">False</span>  <span class="comment"># 所有关卡完成，退出游戏</span></span><br></pre></td></tr></table></figure><p>本项目在原有基本的推箱子基础上，添加了暂停，选关，计时与评分功能</p><p>事件监听：使用 pygame.event.get() 获取当前发生的所有事件。遍历事件列表，判断事件类型。如果事件类型是 pygame.QUIT，表示用户关闭了游戏窗口，则设置 running 变量为 False，终止主循环，游戏结束。如果事件类型是 pygame.KEYDOWN，表示用户按下了键盘按键，根据按键的不同触发相应的操作。</p><p>处理键盘事件：根据用户按下的键盘按键，调用相应的移动函数。如果按下的是上、下、左、右键，则调用 movePlayer() 函数进行玩家移动。如果按下的是其他键，可以添加额外的功能，如关卡选择等。</p><p>更新游戏状态：根据用户的操作更新游戏状态，包括玩家位置、箱子位置等。调用相关的更新函数，如更新玩家位置、更新箱子位置等。</p><p>绘制游戏画面：使用 screen.fill() 方法清空屏幕。调用绘制函数 backGround() 绘制游戏背景。调用绘制函数 mapSet() 绘制游戏地图。调用绘制函数 drawPlayer() 绘制玩家。</p><p>更新屏幕：使用 pygame.display.flip() 更新屏幕显示，将绘制的画面呈现在屏幕上。</p><p>检查游戏是否结束：调用函数 isAllGet() 检查游戏是否胜利，即是否完成了所有目标。如果游戏胜利，则结束主循环，游戏结束。如果游戏尚未结束，则继续等待事件。</p><h1 id="个人创新点"><a href="#个人创新点" class="headerlink" title="个人创新点"></a>个人创新点</h1><p>​        本项目采用双地图设计，即游戏地图分为实际游戏地图和状态记录地图两部分。在游戏进行过程中，实际游戏地图用于绘制游戏画面和控制玩家操作，而状态记录地图用于记录游戏状态和判断游戏胜利条件。这种设计使得游戏逻辑更加清晰，代码结构更加模块化。</p><p>​        同时加有计时功能与选关等按键操作，在一定时间范围内可以得到该关卡目前的评分等级是多少，按下数字键1，2，3可以实现关卡1，2，3的选择，每完成一关后将自动进入下一个。后续的地图更新可以添加到Level中，与最后的选关设计，代码的可维护性强。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Python实践 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LC 34</title>
      <link href="/2024/05/27/LC-34%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/"/>
      <url>/2024/05/27/LC-34%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/</url>
      
        <content type="html"><![CDATA[<h1 id="在排序数组中查找元素的第一个和最后一个位置"><a href="#在排序数组中查找元素的第一个和最后一个位置" class="headerlink" title="在排序数组中查找元素的第一个和最后一个位置"></a>在排序数组中查找元素的第一个和最后一个位置</h1><p>题目描述:给你一个按照非递减顺序排列的整数数组 <code>nums</code>，和一个目标值 <code>target</code>。请你找出给定目标值在数组中的开始位置和结束位置。</p><p>如果数组中不存在目标值 <code>target</code>，返回 <code>[-1, -1]</code>。</p><p>你必须设计并实现时间复杂度为 <code>O(log n)</code> 的算法解决此问题。</p><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入：nums = [5,7,7,8,8,10], target = 8</span><br><span class="line">输出：[3,4]</span><br></pre></td></tr></table></figure></blockquote><p>答案:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span>[] searchRange(<span class="type">int</span>[] nums, <span class="type">int</span> target) &#123;</span><br><span class="line">        <span class="type">int</span> <span class="variable">len</span> <span class="operator">=</span> nums.length;</span><br><span class="line">        <span class="type">int</span> <span class="variable">left</span> <span class="operator">=</span> <span class="number">0</span>, right = len - <span class="number">1</span>;</span><br><span class="line">        <span class="type">int</span> <span class="variable">start</span> <span class="operator">=</span> -<span class="number">1</span>, end = -<span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (left &lt;= right) &#123;</span><br><span class="line">            <span class="type">int</span> <span class="variable">mid</span> <span class="operator">=</span> (left + right) &gt;&gt; <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">if</span> (nums[mid] &lt; target) &#123;</span><br><span class="line">                left = mid + <span class="number">1</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (nums[mid] &gt; target) &#123;</span><br><span class="line">                right = mid - <span class="number">1</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                start = mid;</span><br><span class="line">                end = mid;</span><br><span class="line">                <span class="keyword">while</span> (start &gt; left &amp;&amp; nums[start - <span class="number">1</span>] == target) &#123;</span><br><span class="line">                    start--;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">while</span> (end &lt; right &amp;&amp; nums[end + <span class="number">1</span>] == target) &#123;</span><br><span class="line">                    end++;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">int</span>[]&#123;start, end&#125;;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">int</span>[]&#123;-<span class="number">1</span>, -<span class="number">1</span>&#125;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>​    题目的关键在于当数组的中间值等于target后要怎么处理，首先应当初始化start与end,紧接着分别排查，如果说start值大于最左边值的话，并且start值左边的值也等于target，那么start应该减少，直至边界left，右边也是同理，所以得到以下代码:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 找到目标值后，向左扩展以找到起始位置</span></span><br><span class="line"><span class="keyword">while</span> (start &gt; left &amp;&amp; nums[start - <span class="number">1</span>] == target) &#123;</span><br><span class="line">    start--;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 找到目标值后，向右扩展以找到结束位置</span></span><br><span class="line"><span class="keyword">while</span> (end &lt; right &amp;&amp; nums[end + <span class="number">1</span>] == target) &#123;</span><br><span class="line">    end++;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以发现这个算法是极其优秀的</p><p><img src="D:\BlogFile\source\_posts\LC-34二分查找.assets\092115caaf721652fce1cb5426d0ac22.png" alt="092115caaf721652fce1cb5426d0ac22"></p>]]></content>
      
      
      
        <tags>
            
            <tag> LeetCode刷题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>查找算法</title>
      <link href="/2024/05/27/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE%E7%AE%97%E6%B3%95/"/>
      <url>/2024/05/27/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h1 id="线性查找算法-Linear-Search"><a href="#线性查找算法-Linear-Search" class="headerlink" title="线性查找算法(Linear Search)"></a>线性查找算法(Linear Search)</h1><p>这是一种最简单最暴力的查找算法，要求：线性表必须采用顺序存储结构，而且表中元素按关键字有序排列。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> BinarySearch;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">BinarySearchBasic</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">int</span> b[] = &#123;<span class="number">1</span>, <span class="number">3</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">12</span>, <span class="number">14</span>, <span class="number">16</span>, <span class="number">45</span>&#125;;</span><br><span class="line">        <span class="type">int</span> <span class="variable">result</span> <span class="operator">=</span> linearSearch(b, <span class="number">7</span>);</span><br><span class="line">        System.out.println(result);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="type">int</span> <span class="title function_">linearSearch</span><span class="params">(<span class="type">int</span>[] a,<span class="type">int</span> target)</span>&#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>;i&lt;a.length;i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(a[i] == target)&#123;</span><br><span class="line">                <span class="keyword">return</span> i;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">    线性查找；</span></span><br><span class="line"><span class="comment">    数据元素个数n</span></span><br><span class="line"><span class="comment">    int i = 0;       1</span></span><br><span class="line"><span class="comment">    i&lt;a.length;    n+1</span></span><br><span class="line"><span class="comment">    i++;             n</span></span><br><span class="line"><span class="comment">    a[i] == target   n</span></span><br><span class="line"><span class="comment">    return -1        1</span></span><br><span class="line"><span class="comment">    总次数：3*n +3</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="二分查找算法-Binary-Search"><a href="#二分查找算法-Binary-Search" class="headerlink" title="二分查找算法(Binary Search)"></a>二分查找算法(Binary Search)</h1><p>要求与线性查找算法一样。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> BinarySearch;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">BinarySearchBasic</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">int</span> b[] = &#123;<span class="number">1</span>, <span class="number">3</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">12</span>, <span class="number">14</span>, <span class="number">16</span>, <span class="number">45</span>&#125;;</span><br><span class="line">        <span class="type">int</span> <span class="variable">result</span> <span class="operator">=</span> binarySearchBasic(b, <span class="number">7</span>);</span><br><span class="line">        System.out.println(result);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="type">int</span> <span class="title function_">binarySearchBasic</span><span class="params">(<span class="type">int</span>[] a, <span class="type">int</span> target)</span> &#123;</span><br><span class="line">        <span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>, j = a.length - <span class="number">1</span>;<span class="comment">//改进 :j = a.length;</span></span><br><span class="line">        <span class="keyword">while</span> (i &lt;= j) &#123;<span class="comment">// 范围内有数值 改进 :i&lt;j</span></span><br><span class="line">            <span class="type">int</span> <span class="variable">m</span> <span class="operator">=</span> (i + j) &gt;&gt;&gt; <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">if</span> (target &lt; a[m]) &#123; <span class="comment">//目标在左边</span></span><br><span class="line">                j = m - <span class="number">1</span>; <span class="comment">//改进 :j=m;</span></span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (a[m] &lt; target) &#123; <span class="comment">//目标在右边</span></span><br><span class="line">                i = m + <span class="number">1</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">return</span> m;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/* 问题1：while循环里面为什么是i&lt;=j，而不是i&lt;j?</span></span><br><span class="line"><span class="comment">     在位置0处，i与j共同指向的元素也是要找的元素，但是循环条件是i&lt;j，故少了一次比较</span></span><br><span class="line"><span class="comment">     i = j : 它们指向的元素也会参与比较</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/* 问题2：(i+j)/2 有没有问题？</span></span><br><span class="line"><span class="comment">    若 j = Integer.MAX_VALUE - 1;第二次后i要变为m+1,m = (i + j)/2 其中(i+j)超出了最大范围，输出结果为负数</span></span><br><span class="line"><span class="comment">    0100 0000 0000 0000 0000 0000 0000 0000</span></span><br><span class="line"><span class="comment">    0111 1111 1111 1111 1111 1111 1111 1111</span></span><br><span class="line"><span class="comment">    相加后溢出</span></span><br><span class="line"><span class="comment">    使用无符号右移 &gt;&gt;&gt;</span></span><br><span class="line"><span class="comment">    0000 0111 &gt;&gt;&gt; 1 : 0000 0011 使得二进制结果变为除以二后的最小整数 右移一位相对于/2</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">    二分查找:</span></span><br><span class="line"><span class="comment">    int i = 0,j = a.length-1;   2</span></span><br><span class="line"><span class="comment">    return -1                   1</span></span><br><span class="line"><span class="comment">    循环次数L = floor(log_2(n)) + 1</span></span><br><span class="line"><span class="comment">    i&lt;=j                      L+1</span></span><br><span class="line"><span class="comment">    int m = (i + j) &gt;&gt;&gt;1 ;     L</span></span><br><span class="line"><span class="comment">    target &lt; a[m]              L</span></span><br><span class="line"><span class="comment">    a[m] &gt; target              L</span></span><br><span class="line"><span class="comment">    总次数:(floor(log_2(n))+1)*5 + 4</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">    二分查找的空间复杂度是O(1)  i,j,m三个常数指针</span></span><br><span class="line"><span class="comment">    时间复杂度最差是O(log(n))</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>额外的算法变式，如寻找右边最大，左边最小等等。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> BinarySearch;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">BinarySearchLeftmost</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[]args)</span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="type">int</span> <span class="title function_">binarySearchLeft1</span><span class="params">(<span class="type">int</span>[] a, <span class="type">int</span> target)</span> &#123;<span class="comment">//返回值无用</span></span><br><span class="line">        <span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>, j = a.length - <span class="number">1</span>;</span><br><span class="line">        <span class="type">int</span> <span class="variable">candidate</span> <span class="operator">=</span> -<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span> (i &lt;= j) &#123;<span class="comment">// 范围内有数值 改进 :i&lt;j</span></span><br><span class="line">            <span class="type">int</span> <span class="variable">m</span> <span class="operator">=</span> (i + j) &gt;&gt;&gt; <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">if</span> (target &lt; a[m]) &#123; <span class="comment">//目标在左边</span></span><br><span class="line">                j = m - <span class="number">1</span>; <span class="comment">//改进 :j=m;</span></span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (a[m] &lt; target) &#123; <span class="comment">//目标在右边</span></span><br><span class="line">                i = m + <span class="number">1</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="comment">//记录候选位置</span></span><br><span class="line">                candidate = m;</span><br><span class="line">                j = m - <span class="number">1</span>;<span class="comment">// i = m + 1; RightMost</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> candidate;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="type">int</span> <span class="title function_">binarySearchLeft2</span><span class="params">(<span class="type">int</span>[] a, <span class="type">int</span> target)</span> &#123;<span class="comment">//返回值无用</span></span><br><span class="line">        <span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>, j = a.length - <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span> (i &lt;= j) &#123;<span class="comment">// 范围内有数值 改进 :i&lt;j</span></span><br><span class="line">            <span class="type">int</span> <span class="variable">m</span> <span class="operator">=</span> (i + j) &gt;&gt;&gt; <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">if</span> (target &lt;= a[m]) &#123; <span class="comment">//目标在左边</span></span><br><span class="line">                j = m - <span class="number">1</span>; <span class="comment">//改进 :j=m;</span></span><br><span class="line">            &#125; <span class="keyword">else</span>&#123; <span class="comment">//目标在右边</span></span><br><span class="line">                i = m + <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> i;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="type">int</span> <span class="title function_">binarySearchRight</span><span class="params">(<span class="type">int</span>[] a, <span class="type">int</span> target)</span> &#123;<span class="comment">//返回值无用</span></span><br><span class="line">        <span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>, j = a.length - <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span> (i &lt;= j) &#123;<span class="comment">// 范围内有数值 改进 :i&lt;j</span></span><br><span class="line">            <span class="type">int</span> <span class="variable">m</span> <span class="operator">=</span> (i + j) &gt;&gt;&gt; <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">if</span> (target &lt; a[m]) &#123; <span class="comment">//目标在左边</span></span><br><span class="line">                j = m - <span class="number">1</span>; <span class="comment">//改进 :j=m;</span></span><br><span class="line">            &#125; <span class="keyword">else</span>&#123; <span class="comment">//目标在右边</span></span><br><span class="line">                i = m + <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> i - <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//求排名 leftmost_result + 1</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 数据结构与算法分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LC 1</title>
      <link href="/2024/05/26/LC-1-4/"/>
      <url>/2024/05/26/LC-1-4/</url>
      
        <content type="html"><![CDATA[<h1 id="LeetCode算法题练习笔记"><a href="#LeetCode算法题练习笔记" class="headerlink" title="LeetCode算法题练习笔记"></a>LeetCode算法题练习笔记</h1><h2 id="1-两数相加"><a href="#1-两数相加" class="headerlink" title="1.两数相加"></a>1.两数相加</h2><blockquote><p>给定一个整数数组 <code>nums</code> 和一个整数目标值 <code>target</code>，请你在该数组中找出 <strong>和为目标值</strong> <em><code>target</code></em> 的那 <strong>两个</strong> 整数，并返回它们的数组下标。</p><p>你可以假设每种输入只会对应一个答案。但是，数组中同一个元素在答案里不能重复出现。</p><p>你可以按任意顺序返回答案。</p><p><strong>示例 1：</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">输入：nums = [<span class="number">2</span>,<span class="number">7</span>,<span class="number">11</span>,<span class="number">15</span>], target = <span class="number">9</span></span><br><span class="line">输出：[<span class="number">0</span>,<span class="number">1</span>]</span><br><span class="line">解释：因为 nums[<span class="number">0</span>] + nums[<span class="number">1</span>] == <span class="number">9</span> ，返回 [<span class="number">0</span>, <span class="number">1</span>] 。</span><br></pre></td></tr></table></figure></blockquote><p>我的代码:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span>[] twoSum(<span class="type">int</span>[] nums, <span class="type">int</span> target) &#123;</span><br><span class="line">        <span class="type">int</span> <span class="variable">length</span> <span class="operator">=</span> nums.length;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; length; i++) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">j</span> <span class="operator">=</span> i + <span class="number">1</span>; j &lt; length; j++) &#123;</span><br><span class="line">                <span class="keyword">if</span> (nums[i] + nums[j] == target) &#123;</span><br><span class="line">                    <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">int</span>[]&#123;i, j&#125;;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">int</span>[<span class="number">0</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>显而易见，这是一个很粗糙的暴力算法，通过双指针，每次循环下i变量和j变量相加来判断是否有满足题意的条件，如果有则返回[i,j]，否则返回[0]。这个算法用时仅击败30.79％的java用户，内存占用击败了67.13％的用户，可见这个方案的效率很低，时间较长。</p><p>优秀的算法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span>[] twoSum(<span class="type">int</span>[] nums, <span class="type">int</span> target) &#123;</span><br><span class="line">        Map&lt;Integer, Integer&gt; hashtable = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;Integer, Integer&gt;();</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; nums.length; ++i) &#123;</span><br><span class="line">            <span class="keyword">if</span> (hashtable.containsKey(target - nums[i])) &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">int</span>[]&#123;hashtable.get(target - nums[i]), i&#125;;</span><br><span class="line">            &#125;</span><br><span class="line">            hashtable.put(nums[i], i);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">int</span>[<span class="number">0</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个方案用到了哈希表，用空间来换时间，因此这个方案的时间异常的少，超过了99.57％的用户，但是在内存方面却仅击败了21.59％的用户。</p>]]></content>
      
      
      
        <tags>
            
            <tag> LeetCode刷题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>单链表与双链表</title>
      <link href="/2024/05/25/%E5%8D%95%E9%93%BE%E8%A1%A8%E4%B8%8E%E5%8F%8C%E9%93%BE%E8%A1%A8/"/>
      <url>/2024/05/25/%E5%8D%95%E9%93%BE%E8%A1%A8%E4%B8%8E%E5%8F%8C%E9%93%BE%E8%A1%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="单链表"><a href="#单链表" class="headerlink" title="单链表"></a>单链表</h1><h3 id="内存结构"><a href="#内存结构" class="headerlink" title="内存结构"></a>内存结构</h3><ul><li><strong>数组</strong>：数组在内存中是一块连续的区域。这意味着所有元素在内存中是连续存储的，并且每个元素都可以通过计算基地址和索引来直接访问。</li><li><strong>链表</strong>：链表由一系列节点组成，每个节点包含数据和一个指向下一个节点的引用。节点在内存中不一定是连续的，它们可以分布在内存的任意位置。</li></ul><h3 id="查询速度"><a href="#查询速度" class="headerlink" title="查询速度"></a>查询速度</h3><ul><li><p>数组查询</p><p>由于数组在内存中是连续存储的，任何位置的元素都可以通过索引直接访问，时间复杂度是 O(1)。</p></li><li><p>链表查询</p><p>链表的查询需要从头节点开始，逐个访问节点，直到找到所需的节点，时间复杂度是 O(n)。</p></li></ul><h3 id="添加和删除速度"><a href="#添加和删除速度" class="headerlink" title="添加和删除速度"></a>添加和删除速度</h3><p><strong>数组添加和删除</strong></p><ul><li><strong>添加</strong>：如果在数组中间添加元素，需要将该位置之后的所有元素向后移动，以腾出空间，时间复杂度是 O(n)。</li><li><strong>删除</strong>：如果在数组中间删除元素，需要将该位置之后的所有元素向前移动，以填补空缺，时间复杂度是 O(n)。</li></ul><p><strong>链表添加和删除</strong></p><ul><li><strong>添加</strong>：在链表的任意位置添加元素只需调整前一个节点的指针指向新节点，时间复杂度是 O(1)。</li><li><strong>删除</strong>：在链表的任意位置删除元素只需调整前一个节点的指针绕过被删除的节点，时间复杂度是 O(1)。</li></ul><h3 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h3><p>单链表一般有头指针，即整个链表开始的地址，并且每个节点有其存储的元素与next域，next域中存储着下一个节点的地址。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 数据结构 基础 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>栈与线性结构</title>
      <link href="/2024/05/24/%E6%A0%88%E4%B8%8E%E7%BA%BF%E6%80%A7%E7%BB%93%E6%9E%84/"/>
      <url>/2024/05/24/%E6%A0%88%E4%B8%8E%E7%BA%BF%E6%80%A7%E7%BB%93%E6%9E%84/</url>
      
        <content type="html"><![CDATA[<h1 id="数据结构与算法分析笔记"><a href="#数据结构与算法分析笔记" class="headerlink" title="数据结构与算法分析笔记"></a>数据结构与算法分析笔记</h1><p>​       数据结构与算法分析的学习对于提高编程技能和解决复杂问题至关重要。在实际应用中，选择合适的数据结构和算法可以大大提高程序的运行效率和内存使用效率。</p><h2 id="线性结构与非线性结构"><a href="#线性结构与非线性结构" class="headerlink" title="线性结构与非线性结构"></a>线性结构与非线性结构</h2><p>​       线性结构分为两种不同的存储结构，分别是顺序存储结构与链式存储结构，顺序存储的线性表称为顺序表，顺序表内的存储元素是连续的，链式存储的线性表称为链表，其存储元素不一定是连续的，元素节点存放数据元素与相邻元素的地址信息。</p><p>​       一对一线性的存储结构称为线性存储结构（分为连续与不连续），比如数组，链表，队列等。例如(1,2,3,4)与(1,?,?,2,3,?,?,?,4)。</p><p>​       对于非线性结构，常见的有：二维数组，广义表，树结构，图结构等</p><h2 id="栈"><a href="#栈" class="headerlink" title="栈"></a>栈</h2><p>​       基础概念微机原理与接口技术中已讲，故略。</p><p>​       栈是一个表，所以任何可以实现表的方法都可以用来实现栈，主要是链表实现与数组实现。</p><h4 id="1-链表实现栈"><a href="#1-链表实现栈" class="headerlink" title="1.链表实现栈"></a>1.链表实现栈</h4><p>​       单链表实现栈，通过在链表顶端插入一个元素来实现<strong>PUSH入栈</strong>，通过删除链表的顶端元素来实现<strong>POP出栈</strong>，使用链表方式实现的栈叫做动态栈，动态栈有链表的部分特性，元素与元素之间在物理存储上可以不连续，功能受限，只能在栈顶进行PUSH和POP，而不是在栈中或栈尾实现插入与删除。</p><h4 id="2-数组实现栈"><a href="#2-数组实现栈" class="headerlink" title="2.数组实现栈"></a>2.数组实现栈</h4><p>数组实现的栈又叫静态栈。</p><p>基础的代码实现如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ArrayStack</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> maxSize;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span>[] stack;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> <span class="variable">top</span> <span class="operator">=</span> -<span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">ArrayStack</span><span class="params">(<span class="type">int</span> size)</span> &#123;</span><br><span class="line">        maxSize = size;</span><br><span class="line">        stack = <span class="keyword">new</span> <span class="title class_">int</span>[maxSize];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">isEmpty</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> top == -<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">isFull</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> top == maxSize - <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">push</span><span class="params">(<span class="type">int</span> value)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (isFull()) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(<span class="string">&quot;Stack is full&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        stack[++top] = value;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">pop</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (isEmpty()) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(<span class="string">&quot;Stack is empty&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> stack[top--];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">peek</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (isEmpty()) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(<span class="string">&quot;Stack is empty&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> stack[top];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">isOper</span><span class="params">(<span class="type">char</span> val)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> val == <span class="string">&#x27;+&#x27;</span> || val == <span class="string">&#x27;-&#x27;</span> || val == <span class="string">&#x27;*&#x27;</span> || val == <span class="string">&#x27;/&#x27;</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">priority</span><span class="params">(<span class="type">int</span> oper)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (oper == <span class="string">&#x27;*&#x27;</span> || oper == <span class="string">&#x27;/&#x27;</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (oper == <span class="string">&#x27;+&#x27;</span> || oper == <span class="string">&#x27;-&#x27;</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">length</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> stack.length+<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">calculate</span><span class="params">(<span class="type">int</span> num1, <span class="type">int</span> num2, <span class="type">int</span> oper)</span> &#123;</span><br><span class="line">        <span class="type">int</span> <span class="variable">result</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">switch</span> (oper) &#123;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&#x27;+&#x27;</span>:</span><br><span class="line">                result = num1 + num2;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&#x27;-&#x27;</span>:</span><br><span class="line">                result = num2 - num1;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&#x27;*&#x27;</span>:</span><br><span class="line">                result = num1 * num2;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&#x27;/&#x27;</span>:</span><br><span class="line">                <span class="keyword">if</span> (num1 == <span class="number">0</span>) &#123;</span><br><span class="line">                    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">ArithmeticException</span>(<span class="string">&quot;/ by zero&quot;</span>);</span><br><span class="line">                &#125;</span><br><span class="line">                result = num2 / num1;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="stack的实例1-回文数"><a href="#stack的实例1-回文数" class="headerlink" title="stack的实例1:回文数"></a>stack的实例1:回文数</h3><blockquote><p>使用stack数组来判断一个字符串是否是回文数，回文数比如:abcdcba</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ArrayStack</span> &#123;</span><br><span class="line">    <span class="comment">// 定义栈的大小</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> maxStack;</span><br><span class="line">    <span class="comment">// 定义数组来模拟栈</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span>[] stack;</span><br><span class="line">    <span class="comment">// 定义栈顶位置，默认情况如果没有数据，则定义为-1</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> <span class="variable">top</span> <span class="operator">=</span> -<span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">ArrayStack</span><span class="params">(<span class="type">int</span> maxStack)</span>&#123;</span><br><span class="line">        <span class="built_in">this</span>.maxStack = maxStack;</span><br><span class="line">        stack = <span class="keyword">new</span> <span class="title class_">int</span>[maxStack];</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 判断是否满栈</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">isFull</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">this</span>.top == <span class="built_in">this</span>.maxStack - <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 是否为空</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">isEmpty</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">this</span>.top == -<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">push</span><span class="params">(<span class="type">int</span> value)</span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(isFull())&#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(<span class="string">&quot;此栈已满&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        top++;</span><br><span class="line">        stack[top] = value;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">pop</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(isEmpty())&#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(<span class="string">&quot;次栈为空&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="type">int</span> <span class="variable">value</span> <span class="operator">=</span> stack[top];</span><br><span class="line"></span><br><span class="line">        top--;</span><br><span class="line">        <span class="keyword">return</span> value;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">list</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(isEmpty())&#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(<span class="string">&quot;无数据&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>;i&lt;stack.length;i++)&#123;</span><br><span class="line">            System.out.printf(<span class="string">&quot;Stack[%d]=%d&quot;</span>,i,stack[i]);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">length</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">this</span>.top + <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 判断是否为运算符 + - * %</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">isOper</span><span class="params">(<span class="type">char</span> v)</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> v==<span class="string">&#x27;+&#x27;</span>||v==<span class="string">&#x27;-&#x27;</span>||v==<span class="string">&#x27;*&#x27;</span>||v==<span class="string">&#x27;%&#x27;</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//获取栈的容量</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">stackLength</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">this</span>.stack.length;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//获取栈顶数据</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">peek</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">this</span>.stack[top];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 判断运算符优先级</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">priority</span><span class="params">(<span class="type">int</span> oper)</span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(oper == <span class="string">&#x27;*&#x27;</span>||oper == <span class="string">&#x27;%&#x27;</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span>(oper == <span class="string">&#x27;+&#x27;</span>||oper == <span class="string">&#x27;-&#x27;</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">            <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 计算函数</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">calculate</span><span class="params">(<span class="type">int</span> num1,<span class="type">int</span> num2,<span class="type">int</span> oper)</span>&#123;</span><br><span class="line">        <span class="type">int</span> <span class="variable">result</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">switch</span> (oper)&#123;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&#x27;+&#x27;</span>:</span><br><span class="line">                result = num1 + num2;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&#x27;-&#x27;</span>:</span><br><span class="line">                result = num2 - num1;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&#x27;*&#x27;</span>:</span><br><span class="line">                result = num1 * num2;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&#x27;/&#x27;</span>:</span><br><span class="line">                result = num2/num1;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="stack的实例2：完成表达式的计算"><a href="#stack的实例2：完成表达式的计算" class="headerlink" title="stack的实例2：完成表达式的计算"></a>stack的实例2：完成表达式的计算</h3><blockquote><p>String val = “4 + 3 + 2 + 1*5”的结果</p></blockquote><p>大致思路；循环遍历字符串中的每一个数字，并且按照元素的种类分别压入数字栈或符号栈，若符号栈为空，压入的符号则直接入栈，若不为空则先比较栈中符号的优先级别，如果优先级小于等于栈中的符号，则需要计算原来数字栈的数据，再压入数字栈，再把符号压入到符号栈中，如果优先级大于原来栈中符号，则符号直接入栈即可。</p><p>设计的原因：</p><ul><li><strong>保持顺序</strong>：通过使用两个栈，能够按照表达式中出现的顺序处理数字和操作符。</li><li><strong>处理优先级</strong>：通过比较优先级并决定是否计算，可以确保更高优先级的操作符在较低优先级的操作符之前被处理，保证计算的正确性。</li><li><strong>计算简化</strong>：这种方法使得每次计算都比较简单，只需要关注栈顶的两个数字和一个操作符，而不是整个表达式。</li></ul><p>代码如下:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TestStack</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line"></span><br><span class="line">        <span class="type">String</span> <span class="variable">str</span> <span class="operator">=</span> <span class="string">&quot;4+3+2*3-5&quot;</span>;</span><br><span class="line">        <span class="type">ArrayStack</span> <span class="variable">numStack</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ArrayStack</span>(<span class="number">10</span>);</span><br><span class="line">        <span class="type">ArrayStack</span> <span class="variable">symbolStack</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ArrayStack</span>(<span class="number">10</span>);</span><br><span class="line"></span><br><span class="line">        <span class="type">int</span> <span class="variable">temp1</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">        <span class="type">int</span> <span class="variable">temp2</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">        <span class="type">int</span> <span class="variable">symbolChar</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">        <span class="type">int</span> <span class="variable">result</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">        <span class="type">String</span> <span class="variable">values</span> <span class="operator">=</span> <span class="string">&quot;&quot;</span>;</span><br><span class="line">        <span class="type">int</span> <span class="variable">length</span> <span class="operator">=</span> str.length();</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; length; i++) &#123;</span><br><span class="line">            <span class="type">char</span> <span class="variable">c</span> <span class="operator">=</span> str.charAt(i);</span><br><span class="line">            <span class="keyword">if</span> (symbolStack.isOper(c)) &#123;</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> (!symbolStack.isEmpty()) &#123;</span><br><span class="line">                    <span class="comment">// 比较优先级</span></span><br><span class="line">                    <span class="keyword">while</span> (!symbolStack.isEmpty() &amp;&amp; symbolStack.priority(c) &lt;= symbolStack.priority(symbolStack.peek())) &#123;</span><br><span class="line">                        <span class="comment">// 符号栈获取栈顶符号</span></span><br><span class="line">                        <span class="comment">// 数字栈获取两个数字</span></span><br><span class="line">                        temp1 = numStack.pop();</span><br><span class="line">                        temp2 = numStack.pop();</span><br><span class="line">                        symbolChar = symbolStack.pop();</span><br><span class="line">                        result = numStack.calculate(temp1, temp2, symbolChar);</span><br><span class="line">                        <span class="comment">// 运算结果入栈</span></span><br><span class="line">                        numStack.push(result);</span><br><span class="line">                    &#125;</span><br><span class="line">                    symbolStack.push(c);</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    <span class="comment">// 如果空符号栈，则直接压栈</span></span><br><span class="line">                    symbolStack.push(c);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                values += c;</span><br><span class="line">                <span class="keyword">if</span> (i == length - <span class="number">1</span> || symbolStack.isOper(str.charAt(i + <span class="number">1</span>))) &#123;</span><br><span class="line">                    numStack.push(Integer.parseInt(values));</span><br><span class="line">                    values = <span class="string">&quot;&quot;</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (!symbolStack.isEmpty()) &#123;</span><br><span class="line">            temp1 = numStack.pop();</span><br><span class="line">            temp2 = numStack.pop();</span><br><span class="line">            symbolChar = symbolStack.pop();</span><br><span class="line">            result = numStack.calculate(temp1, temp2, symbolChar);</span><br><span class="line">            numStack.push(result);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="type">int</span> <span class="variable">res</span> <span class="operator">=</span> numStack.pop();</span><br><span class="line">        System.out.println(<span class="string">&quot;结果是: &quot;</span> + res);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 数据结构 基础 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
    
  
</search>
