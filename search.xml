<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Lasso回归与岭回归</title>
      <link href="/2024/08/16/Lasso%E5%9B%9E%E5%BD%92%E4%B8%8E%E5%B2%AD%E5%9B%9E%E5%BD%92/"/>
      <url>/2024/08/16/Lasso%E5%9B%9E%E5%BD%92%E4%B8%8E%E5%B2%AD%E5%9B%9E%E5%BD%92/</url>
      
        <content type="html"><![CDATA[<h1 id="回归问题"><a href="#回归问题" class="headerlink" title="回归问题"></a>回归问题</h1><p>回归问题一般是预测一个或多个因变量与一个或多个自变量的关系，一般的回归方法有很多种，比如线性回归，Logistic回归，又或是决策树回归，集成的随机森林回归与支持向量机回归，还有两个回归方法十分典型，一个是Lasso回归，一个是岭回归，将这两个回归方法放在一起讨论是因为它们都用到了<strong>正则化</strong>这项技术。</p><h1 id="L1与L2正则化"><a href="#L1与L2正则化" class="headerlink" title="L1与L2正则化"></a>L1与L2正则化</h1><p>L1 和 L2 正则化是两种常用的正则化方法，通常用于防止机器学习模型过拟合。它们通过在模型的损失函数中加入一个正则化项来限制模型的复杂度，从而提高模型的泛化能力。</p><p>L1 正则化的核心思想是对模型参数的绝对值进行惩罚。它在损失函数中加入一个正则化项，该项是所有模型参数绝对值之和的某个倍数，即：$\lambda \sum_{i=1}^n|\omega_i|$，其中$\lambda$是正则化的权重项，$\omega$则是参数，L1 正则化会导致某些参数被缩减为零，因此它具有内置的特征选择功能，使得它特别适合高维度数据集。通过强制一些参数为零，L1 正则化可以产生稀疏模型，更方便解释，所以一般来说，Lasso回归不仅适用于回归，也应用在一些<strong>特征降维</strong>的方面上，但是它的原理与主成分分析又不同，Lasso回归是选择一些与目标变量最相关的几个特征，而主成分分析是通过一个空间，将高维数据最大程度的映射为低维数据，所以这个过程中，Lasso回归并没有产生新的变量。</p><p>而L2 正则化的核心思想是对模型参数的平方进行惩罚。它在损失函数中加入一个正则化项，该项是所有模型参数平方和的某个倍数，即：$\lambda \sum_{i=1}^n\omega_i^2$，L2 正则化不会像 L1 正则化那样将参数缩减为零，而是会使得所有参数都趋向于较小的值，因此它不能进行特征选择。L2 正则化能够有效地减小模型的复杂度，减少对训练数据的过拟合，但保留所有的特征。</p><p>这里的正则化是最优化理论的一些概念。可以类比为一个<strong>Lp</strong>距离，对于L1正则化，其距离类似于曼哈顿距离，对L2正则化而言，距离则变为了一个完整的圆，由于圆和菱形都是一个凸优化图形，所以这方便了目标函数的最优化。</p><p>那Lasso回归与岭回归是用来解决什么问题的呢？通过约束性我们不难发现，这两种正则化回归是为了解决过拟合问题，也就是解决数据高度相关的情况下，所以当自变量高度相关时，即多重共线性，我们一般用正则化回归。</p><h1 id="多重共线性"><a href="#多重共线性" class="headerlink" title="多重共线性"></a>多重共线性</h1><p><strong>多重共线性(Multicollinearity)</strong>是指两个或更多的自变量之间存在明显的相关性。即这些自变量之间有显著的线性关系，因此它们无法为回归分析提供任何独特的信息。这样会有什么问题？很显然，这样的后果是模型无法准确的识别出是哪个变量在起作用，可解释性变差，同时数据中的共线性会增加方差并导致模型过拟合，从而导致模型在推理时对看不见的数据的性能不佳。</p><p>实际上，各种数据集都或多或少的存在部分特征共线性的情况，只不过是程度有大有小，而对于比较严重的多重共线性的情况，也就是有很多特征存在着这样的问题，所以我们要首先判断是哪些特征是共线性的，一般来说可视化方法有，相关系数矩阵的热力图，聚类图，或是VIF。</p><p>什么是VIF？方差膨胀因子（VIF）是回归分析中多重共线性程度的衡量指标。VIF用于确定一个自变量与一组其他变量之间的相关性。VIF的数值越低越好。大于4或5的值被认为是中度到高度的，大于10的值则被认为非常高。一般情况下通常将VIF = 5作为阈值，所有大于这个门槛的自变量都需要移除。虽然很多教材中只有当VIF &gt; 10时才被认为是严重的多重共线性。</p><script type="math/tex; mode=display">VIF =  \frac{1}{1-R_i^2}</script><h1 id="岭回归-Ridge-regression"><a href="#岭回归-Ridge-regression" class="headerlink" title="岭回归(Ridge regression)"></a>岭回归(Ridge regression)</h1><p>岭回归主要用在解决多重共线性问题，所以其适用于高维数据集，同时其曲线一般来说是平滑的，因为平方项的系数不容易变为0，所以一般来说不会是一条直线，而是一条曲线。</p><script type="math/tex; mode=display">min_\beta (\sum_{i=1}^n(y_i-X_i\beta)^2+\lambda\sum_{j=1}^p\beta_j^2)</script><p>其中的前面一部分就是普通的最小二乘法，后面则是L2正则化的约束项。</p><p>许多机器学习模型（如线性回归、岭回归、支持向量机等）只能处理数值数据。这些模型需要将所有输入特征转换为数值形式，我们选择一个具有多重共线性特征的数据集:BMI，并需要将 <code>&#39;Male&#39;</code> 和 <code>&#39;Female&#39;</code> 转换为数字。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> statsmodels.stats.outliers_influence <span class="keyword">import</span> variance_inflation_factor</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">url = <span class="string">&quot;https://github.com/gouravsinghbais/Detecting-and-Remedying-Multicollinearity-in-Your-Data-Analysis/raw/master/bmi.csv&quot;</span></span><br><span class="line">bmi = pd.read_csv(url)</span><br><span class="line"><span class="comment"># 将性别转换为数值</span></span><br><span class="line"><span class="comment"># 创建一个名为&quot;Gender&quot;的新列，用于存储性别的虚拟变量</span></span><br><span class="line"><span class="comment"># 将&quot;Gender&quot;列中的&quot;Male&quot;替换为0，&quot;Female&quot;替换为1，以创建性别的虚拟变量</span></span><br><span class="line">bmi[<span class="string">&#x27;Gender&#x27;</span>] = bmi[<span class="string">&#x27;Gender&#x27;</span>].<span class="built_in">map</span>(&#123;<span class="string">&#x27;Male&#x27;</span>:<span class="number">0</span>, <span class="string">&#x27;Female&#x27;</span>:<span class="number">1</span>&#125;)</span><br></pre></td></tr></table></figure><p>绘制热力图</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize = (<span class="number">6</span>, <span class="number">6</span>))</span><br><span class="line">heatmap = sns.heatmap(raw_bmi.corr(), vmin = -<span class="number">1</span>, vmax = <span class="number">1</span>, annot = <span class="literal">True</span>)  <span class="comment"># vmin和vmax参数指定颜色映射的范围为-1到1，annot参数为True表示在热力图上显示相关系数的数值</span></span><br><span class="line">heatmap.set_title(<span class="string">&#x27;BMI Correlation Heatmap&#x27;</span>, fontdict = &#123;<span class="string">&#x27;fontsize&#x27;</span> : <span class="number">18</span>&#125;, pad = <span class="number">12</span>)  <span class="comment"># 字体大小为18，标题与图像之间的间距为12像素</span></span><br></pre></td></tr></table></figure><p>绘制聚类图</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize = (<span class="number">4</span>, <span class="number">4</span>))</span><br><span class="line"><span class="comment"># 使用clustermap函数</span></span><br><span class="line">clustermap = sns.clustermap(bmi.corr(), vmin = -<span class="number">1</span>, vmax = <span class="number">1</span>, annot = <span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>计算VIF</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">X = bmi[[<span class="string">&#x27;Gender&#x27;</span>, <span class="string">&#x27;Height&#x27;</span>, <span class="string">&#x27;Weight&#x27;</span>]]</span><br><span class="line"></span><br><span class="line">vif_data = pd.DataFrame()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将自变量的名称添加到VIF数据框中</span></span><br><span class="line">vif_data[<span class="string">&quot;Feature&quot;</span>] = X.columns</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算每个自变量的VIF值</span></span><br><span class="line">vif_data[<span class="string">&quot;VIF&quot;</span>] = [variance_inflation_factor(X.values, i)</span><br><span class="line">                          <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(X.columns))]</span><br><span class="line">vif_data</span><br></pre></td></tr></table></figure><p>输出结果为:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">  Feature        VIF</span><br><span class="line">0  Gender   2.028864</span><br><span class="line">1  Height  11.623103</span><br><span class="line">2  Weight  10.688377</span><br></pre></td></tr></table></figure><p>可以发现，Height与weight之间的存在严重的共线性。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 分离特征和目标变量</span></span><br><span class="line">X = bmi.drop(columns=[<span class="string">&#x27;Index&#x27;</span>]) </span><br><span class="line">y = bmi[<span class="string">&#x27;Index&#x27;</span>] </span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">scaler = StandardScaler()</span><br><span class="line">X_train = scaler.fit_transform(X_train)</span><br><span class="line">X_test = scaler.transform(X_test)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression, Ridge</span><br><span class="line"></span><br><span class="line">lin_reg = LinearRegression()</span><br><span class="line">ridge_reg = Ridge(alpha=<span class="number">50.0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">lin_reg.fit(X_train, y_train)</span><br><span class="line">y_pred_lin = lin_reg.predict(X_test)</span><br><span class="line">ridge_reg.fit(X_train, y_train)</span><br><span class="line">y_pred_ridge = ridge_reg.predict(X_test)</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> r2_score, mean_squared_error</span><br><span class="line"></span><br><span class="line"><span class="comment"># 评估模型</span></span><br><span class="line">r2_lin = r2_score(y_test, y_pred_lin)</span><br><span class="line">mse_lin = mean_squared_error(y_test, y_pred_lin)</span><br><span class="line">r2_ridge = r2_score(y_test, y_pred_ridge)</span><br><span class="line">mse_ridge = mean_squared_error(y_test, y_pred_ridge)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;线性回归 R²: <span class="subst">&#123;r2_lin:<span class="number">.4</span>f&#125;</span>, 均方误差: <span class="subst">&#123;mse_lin:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;岭回归 R²: <span class="subst">&#123;r2_ridge:<span class="number">.4</span>f&#125;</span>, 均方误差: <span class="subst">&#123;mse_ridge:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><h1 id="Lasso回归"><a href="#Lasso回归" class="headerlink" title="Lasso回归"></a>Lasso回归</h1><p>其公式原理与岭回归基本相同，所调用函数的方法也基本相同</p><script type="math/tex; mode=display">min_\beta (\sum_{i=1}^n(y_i-X_i\beta)^2+\lambda\sum_{j=1}^p|\beta_j|)</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Lasso</span><br><span class="line"></span><br><span class="line">lasso_reg = Lasso(alpha=<span class="number">0.1</span>) </span><br><span class="line"></span><br><span class="line">lasso_reg.fit(X_train, y_train)</span><br><span class="line">y_pred_lasso = lasso_reg.predict(X_test)</span><br><span class="line">r2_lasso = r2_score(y_test, y_pred_lasso)</span><br><span class="line">mse_lasso = mean_squared_error(y_test, y_pred_lasso)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Lasso 回归 R²: <span class="subst">&#123;r2_lasso:<span class="number">.4</span>f&#125;</span>, 均方误差: <span class="subst">&#123;mse_lasso:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><p>三个模型的对比，经过微调后，对于岭回归，α适合选择为50附近，而Lasso回归则适合为0.1，其他情况会变得很糟糕，如果Lasso回归的系数过大，会导致选择特征过少，最后的误差很大，最后是三个模型的对比效果:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">线性回归 R²: 0.7963, 均方误差: 0.3394</span><br><span class="line">岭回归 R²: 0.8099, 均方误差: 0.3166</span><br><span class="line">Lasso 回归 R²: 0.8119, 均方误差: 0.3133</span><br></pre></td></tr></table></figure><p>会发现，岭回归对于解决共线性问题还是有比较好的提升的，但是由于bmi本身的特征变量比较少，所以相比于线性回归来说提升不大，同时在该场景下，Lasso回归的取值最好。</p><h1 id="学习曲线"><a href="#学习曲线" class="headerlink" title="学习曲线"></a>学习曲线</h1><p>绘制随着$\alpha$的不断变换，其Score最后的效果如何，可以用以下代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Ridge, Lasso</span><br><span class="line"></span><br><span class="line">alphas = np.logspace(-<span class="number">4</span>, <span class="number">0</span>, <span class="number">50</span>)</span><br><span class="line"></span><br><span class="line">coefs_lasso = []</span><br><span class="line">coefs_ridge = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对每个 alpha 训练 Lasso 和 Ridge 模型，并记录系数</span></span><br><span class="line"><span class="keyword">for</span> a <span class="keyword">in</span> alphas:</span><br><span class="line">    lasso = Lasso(alpha=a, max_iter=<span class="number">10000</span>)</span><br><span class="line">    ridge = Ridge(alpha=a)</span><br><span class="line">    </span><br><span class="line">    lasso.fit(X_train, y_train)</span><br><span class="line">    ridge.fit(X_train, y_train)</span><br><span class="line">    </span><br><span class="line">    coefs_lasso.append(lasso.coef_)</span><br><span class="line">    coefs_ridge.append(ridge.coef_)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">14</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">plt.plot(alphas, coefs_lasso)</span><br><span class="line">plt.xscale(<span class="string">&#x27;log&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;alpha&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Coefficients&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Lasso Coefficients Path&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;tight&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">plt.plot(alphas, coefs_ridge)</span><br><span class="line">plt.xscale(<span class="string">&#x27;log&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;alpha&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Coefficients&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Ridge Coefficients Path&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;tight&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>若是想查看拟合程度究竟如何，可以用以下代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]<span class="comment"># 避免中文乱码</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">y_pred_lasso = lasso_reg.predict(X_test)</span><br><span class="line">y_pred_ridge = ridge_reg.predict(X_test)</span><br><span class="line">y_pred_lin = lin_reg.predict(X_test)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">14</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">plt.scatter(y_test, y_pred_lasso, color=<span class="string">&#x27;blue&#x27;</span>, label=<span class="string">&#x27;Lasso 预测值&#x27;</span>)</span><br><span class="line">plt.plot([y_test.<span class="built_in">min</span>(), y_test.<span class="built_in">max</span>()], [y_test.<span class="built_in">min</span>(), y_test.<span class="built_in">max</span>()], color=<span class="string">&#x27;red&#x27;</span>, linestyle=<span class="string">&#x27;--&#x27;</span>, label=<span class="string">&#x27;理想拟合线&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;实际值&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;预测值&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Lasso 回归: 预测值 vs 实际值&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">plt.scatter(y_test, y_pred_ridge, color=<span class="string">&#x27;green&#x27;</span>, label=<span class="string">&#x27;Ridge 预测值&#x27;</span>)</span><br><span class="line">plt.plot([y_test.<span class="built_in">min</span>(), y_test.<span class="built_in">max</span>()], [y_test.<span class="built_in">min</span>(), y_test.<span class="built_in">max</span>()], color=<span class="string">&#x27;red&#x27;</span>, linestyle=<span class="string">&#x27;--&#x27;</span>, label=<span class="string">&#x27;理想拟合线&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;实际值&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;预测值&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Ridge 回归: 预测值 vs 实际值&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>拉格朗日乘子法与KKT</title>
      <link href="/2024/08/07/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95%E4%B8%8EKKT/"/>
      <url>/2024/08/07/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95%E4%B8%8EKKT/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>模拟退火算法</title>
      <link href="/2024/08/04/%E6%A8%A1%E6%8B%9F%E9%80%80%E7%81%AB%E7%AE%97%E6%B3%95/"/>
      <url>/2024/08/04/%E6%A8%A1%E6%8B%9F%E9%80%80%E7%81%AB%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h1 id="模拟退火算法"><a href="#模拟退火算法" class="headerlink" title="模拟退火算法"></a>模拟退火算法</h1><p>模拟退火算法（Simulated Annealing, SA）是一种基于概率的全局优化算法，其核心思想是核心思想是通过在解空间中接受可能不是全局最优解的解，以一定的概率接受较差的解，逐步降低接受较差解的概率，从而在整个解空间中搜索到全局最优解。</p><h2 id="由来"><a href="#由来" class="headerlink" title="由来"></a>由来</h2><p>模拟退火算法的概念源自物理学中的退火过程，首次提出于1983年，由S. Kirkpatrick、C. D. Gelatt和M. P. Vecchi在他们的论文《Optimization by Simulated Annealing》中详细介绍。退火是指将金属加热到高温后缓慢冷却，使其内部结构达到稳定的低能态，从而增强材料的韧性和硬度。模拟退火算法通过模仿这一过程，在求解优化问题时逐步降低“温度”，以跳出局部最优解，寻找全局最优解。</p><h2 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h2><p>生成初始解，将其定作为当前最优解，开始对旧解进行随机小幅度干扰，得到新解，判断新解是否是当前最优解，若是则接受新解，若不是则按照Metropolis准则接受新解，如此循环直至最大迭代次数，如果符合条件则输出，若不符合条件则缓慢降低温度并且重置迭代次数。</p><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">T0 = <span class="number">1000</span>  <span class="comment"># 初始温度 初始温度越高，算法在初期的搜索空间越大</span></span><br><span class="line">T_min = <span class="number">1</span>  <span class="comment"># 最低温度 最低温度越低，算法更有可能找到全局最优解，但计算时间也可能增加。一般设定为一个较小的正数。</span></span><br><span class="line">alpha = <span class="number">0.9</span>  <span class="comment"># 降温系数 越接近1，降温越慢，但精度更高。一般为0.8至0.99。</span></span><br><span class="line">max_iter = <span class="number">1000</span>  <span class="comment"># 每次温度下的最大迭代次数</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">objective_function</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> x**<span class="number">2</span> + <span class="number">10</span> * np.sin(x)</span><br><span class="line"></span><br><span class="line">current_solution = np.random.uniform(-<span class="number">10</span>, <span class="number">10</span>)</span><br><span class="line">current_value = objective_function(current_solution)</span><br><span class="line">T = T0</span><br><span class="line">best_solution = current_solution</span><br><span class="line">best_value = current_value</span><br><span class="line"> </span><br><span class="line"><span class="keyword">while</span> T &gt; T_min:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(max_iter):</span><br><span class="line">        new_solution = current_solution + np.random.uniform(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        new_value = objective_function(new_solution)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> new_value &lt; current_value:</span><br><span class="line">            current_solution = new_solution</span><br><span class="line">            current_value = new_value</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            p = np.exp(-(new_value - current_value) / T)</span><br><span class="line">            <span class="keyword">if</span> np.random.rand() &lt; p:</span><br><span class="line">                current_solution = new_solution</span><br><span class="line">                current_value = new_value</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> current_value &lt; best_value:</span><br><span class="line">            best_solution = current_solution</span><br><span class="line">            best_value = current_value</span><br><span class="line"></span><br><span class="line">    T = T * alpha</span><br><span class="line"> </span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Best solution: <span class="subst">&#123;best_solution&#125;</span>, Best value: <span class="subst">&#123;best_value&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><ul><li>全局搜索能力强，更容易跳出局部解。</li><li>但是计算效率低下，需要大量的随机扰动和搜索来寻找解。</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 智能优化算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>粒子群优化算法</title>
      <link href="/2024/08/04/%E7%B2%92%E5%AD%90%E7%BE%A4%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/"/>
      <url>/2024/08/04/%E7%B2%92%E5%AD%90%E7%BE%A4%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h1 id="粒子群优化算法"><a href="#粒子群优化算法" class="headerlink" title="粒子群优化算法"></a>粒子群优化算法</h1><h2 id="由来"><a href="#由来" class="headerlink" title="由来"></a>由来</h2><p>粒子群优化（Particle Swarm Optimization，PSO）是一种源于群体智能的优化算法。它模拟鸟群觅食的行为，通过个体之间的协作和信息共享来寻找问题的最优解。PSO算法的基本思想是通过一群粒子在搜索空间中的相互作用，找到全局最优解。</p><p>鸟群在整个搜寻过程中，通过相互传递位置信息，让其他鸟了解自己的位置，通过这种协作方式来判断自己找到的是否是最优解，同时也将最优解的信息传递给整个鸟群，最终使得整个鸟群聚集在食物源周围，即找到了最优解。</p><p>在粒子群优化（PSO）算法中，每个优化问题的解在搜索空间中都相当于一只鸟，我们称之为“粒子”。所有粒子都有一个由被优化的函数决定的适应值（fitness value），每个粒子还有速度来决定它们飞行的方向和距离。粒子们通过跟随当前的最优粒子在解空间中搜索最优解。</p><p>PSO算法初始化时生成一群随机粒子（随机解），然后通过迭代找到最优解。在每次迭代中，粒子通过跟踪两个“极值”来更新自己。第一个极值是粒子自身找到的最优解，称为个体极值（pBest）；另一个极值是整个种群目前找到的最优解，称为全局极值（gBest）。在这种情况下，在所有邻居中的极值称为局部极值。</p><h2 id="理论公式"><a href="#理论公式" class="headerlink" title="理论公式"></a>理论公式</h2><script type="math/tex; mode=display">v_{i}(t+1) = \omega v_{i}(t) + c_1 r_1 (pbest_{i} - x_{i}(t)) + c_2 r_2 (gbest - x_{i}(t))</script><p>其中，$v_i$是粒子的速度，$r_1,r_2$为随机数，$c_1,c_2$为学习因子，一般均为2，$pbest_i$是个人寻得的最优解，$gbest$是全局寻得的最优解。$x_i$​是粒子当前的位置。</p><script type="math/tex; mode=display">x_i = x_i + v_i</script><p>$\omega$称为惯性因子，为非负数，当$\omega$较大时，全局寻优的能力较强，而局部寻优的能力较弱，当$\omega$较小时，全局寻优能力较弱，而局部寻优能力较强。$\omega$可以是一个预先设定好的值，也可以随着优化过程而逐渐变化，常见的一种方式叫做线性递减权值策略(Linearly Decreasing weigh，LDW)，公式为：</p><script type="math/tex; mode=display">\omega = (\omega_{ini}-\omega_{end})(G_k-g)/G_{k}+\omega_{end}</script><h2 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h2><p>先随机初始化一群粒子，开始计算每个粒子处的目标值，然后得到每个粒子的个体最优值$pbest_i$与整个群体的最优值$gbest = min{pbest_i}$，判断是否满足收敛条件，若满足则输出最优解和迭代次数，否则更新每个粒子的位置与速度矢量，如此反复迭代。</p><h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p>在数学最优化中，<strong>Rosenbrock函数</strong>是一个用来测试最优化算法性能的非凸函数，由Howard Harry Rosenbrock在1960年提出。也称为<strong>Rosenbrock山谷</strong>或<strong>Rosenbrock香蕉函数</strong>，也简称为<strong>香蕉函数</strong>。</p><p>其全局最小值位于(1,1,1,…,1)，解为0。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Particle</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, bounds</span>):</span><br><span class="line">        self.position = np.random.uniform(bounds[<span class="number">0</span>], bounds[<span class="number">1</span>], dim)</span><br><span class="line">        self.velocity = np.random.uniform(-<span class="number">1</span>, <span class="number">1</span>, dim)</span><br><span class="line">        self.best_position = self.position.copy()</span><br><span class="line">        self.best_value = <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update_velocity</span>(<span class="params">self, global_best_position, w, c1, c2</span>):</span><br><span class="line">        r1 = np.random.rand(self.position.shape[<span class="number">0</span>])</span><br><span class="line">        r2 = np.random.rand(self.position.shape[<span class="number">0</span>])</span><br><span class="line">        cognitive_velocity = c1 * r1 * (self.best_position - self.position)</span><br><span class="line">        social_velocity = c2 * r2 * (global_best_position - self.position)</span><br><span class="line">        self.velocity = w * self.velocity + cognitive_velocity + social_velocity</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update_position</span>(<span class="params">self, bounds</span>):</span><br><span class="line">        self.position += self.velocity</span><br><span class="line">        self.position = np.clip(self.position, bounds[<span class="number">0</span>], bounds[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Rosenbrock函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">rosenbrock</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> np.<span class="built_in">sum</span>(<span class="number">100.0</span>*(x[<span class="number">1</span>:] - x[:-<span class="number">1</span>]**<span class="number">2.0</span>)**<span class="number">2.0</span> + (<span class="number">1</span> - x[:-<span class="number">1</span>])**<span class="number">2.0</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">pso</span>(<span class="params">objective_function, dim, bounds, num_particles, max_iter, w, c1, c2</span>):</span><br><span class="line">    particles = [Particle(dim, bounds) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_particles)]</span><br><span class="line">    global_best_value = <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)</span><br><span class="line">    global_best_position = <span class="literal">None</span></span><br><span class="line">    fitness_values = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> iteration <span class="keyword">in</span> <span class="built_in">range</span>(max_iter):</span><br><span class="line">        <span class="keyword">for</span> particle <span class="keyword">in</span> particles:</span><br><span class="line">            fitness_value = objective_function(particle.position)</span><br><span class="line">            <span class="keyword">if</span> fitness_value &lt; particle.best_value:</span><br><span class="line">                particle.best_value = fitness_value</span><br><span class="line">                particle.best_position = particle.position.copy()</span><br><span class="line">            <span class="keyword">if</span> fitness_value &lt; global_best_value:</span><br><span class="line">                global_best_value = fitness_value</span><br><span class="line">                global_best_position = particle.position.copy()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> particle <span class="keyword">in</span> particles:</span><br><span class="line">            particle.update_velocity(global_best_position, w, c1, c2)</span><br><span class="line">            particle.update_position(bounds)</span><br><span class="line"></span><br><span class="line">        fitness_values.append(global_best_value)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> global_best_value &lt; <span class="number">1e-6</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;Converged at iteration <span class="subst">&#123;iteration&#125;</span>&#x27;</span>)</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> global_best_position, global_best_value, fitness_values</span><br><span class="line"></span><br><span class="line">dim = <span class="number">5</span> <span class="comment"># 维度</span></span><br><span class="line">bounds = [-<span class="number">5</span>, <span class="number">5</span>] <span class="comment"># 定义域范围</span></span><br><span class="line">num_particles = <span class="number">200</span> <span class="comment"># 粒子数目</span></span><br><span class="line">max_iter = <span class="number">5000</span> <span class="comment"># 最大迭代次数</span></span><br><span class="line">w = <span class="number">0.5</span> <span class="comment"># 惯性权重</span></span><br><span class="line">c1 = <span class="number">2</span> <span class="comment"># 认知学习因子</span></span><br><span class="line">c2 = <span class="number">2</span> <span class="comment"># 社会学习因子</span></span><br><span class="line"></span><br><span class="line">best_position, best_value, fitness_values = pso(rosenbrock, dim, bounds, num_particles, max_iter, w, c1, c2)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Best Position: <span class="subst">&#123;best_position&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Best Value: <span class="subst">&#123;best_value&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.plot(fitness_values)</span><br><span class="line">plt.title(<span class="string">&#x27;Fitness Value over Iterations&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Iterations&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Fitness Value&#x27;</span>)</span><br><span class="line">plt.yscale(<span class="string">&#x27;log&#x27;</span>) <span class="comment"># 使用对数坐标</span></span><br><span class="line">plt.grid(<span class="literal">True</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[best_position, best_value]</span> = <span class="title">pso</span><span class="params">(objective_function, dim, bounds, num_particles, max_iter, w, c1, c2)</span></span></span><br><span class="line">    position = <span class="built_in">repmat</span>(bounds(<span class="number">1</span>,:), num_particles, <span class="number">1</span>) + <span class="built_in">repmat</span>((bounds(<span class="number">2</span>,:) - bounds(<span class="number">1</span>,:)), num_particles, <span class="number">1</span>) .* <span class="built_in">rand</span>(num_particles, dim);</span><br><span class="line">    velocity = <span class="built_in">rand</span>(num_particles, dim);</span><br><span class="line">    best_position = position;</span><br><span class="line">    best_value = arrayfun(objective_function, best_position);</span><br><span class="line">    [global_best_value, best_idx] = <span class="built_in">min</span>(best_value);</span><br><span class="line">    global_best_position = best_position(best_idx, :);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> iter = <span class="number">1</span>:max_iter</span><br><span class="line">        <span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:num_particles</span><br><span class="line">            fitness_value = objective_function(position(<span class="built_in">i</span>, :));</span><br><span class="line">            <span class="keyword">if</span> fitness_value &lt; best_value(<span class="built_in">i</span>)</span><br><span class="line">                best_value(<span class="built_in">i</span>) = fitness_value;</span><br><span class="line">                best_position(<span class="built_in">i</span>, :) = position(<span class="built_in">i</span>, :);</span><br><span class="line">            <span class="keyword">end</span></span><br><span class="line">            <span class="keyword">if</span> fitness_value &lt; global_best_value</span><br><span class="line">                global_best_value = fitness_value;</span><br><span class="line">                global_best_position = position(<span class="built_in">i</span>, :);</span><br><span class="line">            <span class="keyword">end</span></span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:num_particles</span><br><span class="line">            r1 = <span class="built_in">rand</span>(<span class="number">1</span>, dim);</span><br><span class="line">            r2 = <span class="built_in">rand</span>(<span class="number">1</span>, dim);</span><br><span class="line">            cognitive_velocity = c1 * r1 .* (best_position(<span class="built_in">i</span>, :) - position(<span class="built_in">i</span>, :));</span><br><span class="line">            social_velocity = c2 * r2 .* (global_best_position - position(<span class="built_in">i</span>, :));</span><br><span class="line">            velocity(<span class="built_in">i</span>, :) = w * velocity(<span class="built_in">i</span>, :) + cognitive_velocity + social_velocity;</span><br><span class="line">            position(<span class="built_in">i</span>, :) = position(<span class="built_in">i</span>, :) + velocity(<span class="built_in">i</span>, :);</span><br><span class="line">            position(<span class="built_in">i</span>, :) = <span class="built_in">max</span>(<span class="built_in">min</span>(position(<span class="built_in">i</span>, :), bounds(<span class="number">2</span>, :)), bounds(<span class="number">1</span>, :));</span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> global_best_value &lt; <span class="number">1e-6</span></span><br><span class="line">            fprintf(<span class="string">&#x27;Converged at iteration %d\n&#x27;</span>, iter);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">    best_position = global_best_position;</span><br><span class="line">    best_value = global_best_value;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">dim = <span class="number">2</span>;</span><br><span class="line">bounds = [<span class="number">-10</span> <span class="number">10</span>; <span class="number">-10</span> <span class="number">10</span>];</span><br><span class="line">num_particles = <span class="number">30</span>;</span><br><span class="line">max_iter = <span class="number">100</span>;</span><br><span class="line">w = <span class="number">0.5</span>;</span><br><span class="line">c1 = <span class="number">1.5</span>;</span><br><span class="line">c2 = <span class="number">1.5</span>;</span><br><span class="line"></span><br><span class="line">objective_function = @(x) sum(x.^<span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">[best_position, best_value] = pso(objective_function, dim, bounds, num_particles, max_iter, w, c1, c2);</span><br><span class="line"></span><br><span class="line"><span class="built_in">disp</span>(<span class="string">&#x27;Best Position:&#x27;</span>);</span><br><span class="line"><span class="built_in">disp</span>(best_position);</span><br><span class="line"><span class="built_in">disp</span>(<span class="string">&#x27;Best Value:&#x27;</span>);</span><br><span class="line"><span class="built_in">disp</span>(best_value);</span><br></pre></td></tr></table></figure><p>以上分别是python和matlab代码，python代码运行后结果为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Converged at iteration 1544</span><br><span class="line">Best Position: [0.99989184 0.99978585 0.99957005 0.99913691 0.99827794]</span><br><span class="line">Best Value: 9.903569513275998e-07</span><br></pre></td></tr></table></figure><p>可以看到效果良好，非常接近于全局最优解。</p><h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><ul><li>通用性强。收敛速度快，更容易全局收敛。</li></ul><ul><li>易陷入局部最优</li><li>搜索速度不太稳定，有时会出现迭代次数较多的情况</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 智能优化算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>三大相关系数检验</title>
      <link href="/2024/08/02/%E4%B8%89%E5%A4%A7%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0%E6%A3%80%E9%AA%8C/"/>
      <url>/2024/08/02/%E4%B8%89%E5%A4%A7%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0%E6%A3%80%E9%AA%8C/</url>
      
        <content type="html"><![CDATA[<h2 id="三大相关系数"><a href="#三大相关系数" class="headerlink" title="三大相关系数"></a>三大相关系数</h2><p>三大相关系数反应的是两个变量之间变化的趋势方向及程度，取值范围在-1到-+1之间，0代表不相关，正值代表正相关，负值代表负相关，绝对值越大相关性越强,可用来衡量两个变量之间的相关性的大小。</p><p>相关系数只是用来来衡量两个变量线性相关程度的指标；即我必须<strong>先确认这两个变量是线性相关的</strong>，然后相关系数才能告诉数据的相关程度，可先通过数据可视化来确定。</p><h3 id="皮尔斯相关系数-Pearson-Correlation-Coefficient"><a href="#皮尔斯相关系数-Pearson-Correlation-Coefficient" class="headerlink" title="皮尔斯相关系数(Pearson Correlation Coefficient)"></a>皮尔斯相关系数(Pearson Correlation Coefficient)</h3><p>实验数据通常假设是成对的来自于正态分布的总体。得到皮尔逊相关性系数后，通常会用t检验等方法进行皮尔逊相关性系数检验。<br>实验数据间差距不能太大。皮尔逊相关性系数受异常值影响较大，每组样本之间是独立抽样的。</p><p><strong>零假设（H0）</strong>：变量之间没有线性关系，即皮尔斯相关系数 r=0。</p><p><strong>备择假设（H1）</strong>：变量之间有线性关系，即皮尔斯相关系数 r≠0。</p><p>公式为:</p><script type="math/tex; mode=display">r = \frac{\sum (X_i - \bar{X})(Y_i - \bar{Y})}{\sqrt{\sum (X_i - \bar{X})^2 \sum (Y_i - \bar{Y})^2}}</script><script type="math/tex; mode=display">t = r\sqrt{\frac{n-2}{1-r^2}}</script><p>根据自由度 df=n−2 查找 t 分布表确定临界值，或直接计算 p 值。如果 p 值小于显著性水平 α（如0.05），则拒绝零假设，认为变量之间存在显著的线性关系。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br><span class="line"></span><br><span class="line">x = [<span class="number">10</span>, <span class="number">20</span>, <span class="number">30</span>, <span class="number">40</span>, <span class="number">50</span>]</span><br><span class="line">y = [<span class="number">12</span>, <span class="number">24</span>, <span class="number">33</span>, <span class="number">45</span>, <span class="number">51</span>]</span><br><span class="line"><span class="comment"># 判断x,y是否是线性相关</span></span><br><span class="line">plt.scatter(x, y)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;X&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Y&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Scatter Plot&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">correlation_coefficient, p_value = stats.pearsonr(x, y)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;皮尔斯相关系数:&quot;</span>, correlation_coefficient)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;p值:&quot;</span>, p_value)</span><br><span class="line"></span><br><span class="line">alpha = <span class="number">0.05</span></span><br><span class="line"><span class="keyword">if</span> p_value &lt; alpha:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;拒绝零假设，变量之间存在显著的线性关系。&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;不拒绝零假设，变量之间没有显著的线性关系。&quot;</span>)</span><br></pre></td></tr></table></figure><p>只有当数据是连续数据，且符合正态分布与线性关系才可以用，先绘制散点图，当数据是线性时，再计算皮尔斯相关系数，经过正态分布检验后，再用假设检验判断显著性。</p><h3 id="正态分布检验"><a href="#正态分布检验" class="headerlink" title="正态分布检验"></a>正态分布检验</h3><h4 id="Jarque-Bera-检验-JB-检验"><a href="#Jarque-Bera-检验-JB-检验" class="headerlink" title="Jarque-Bera 检验 (JB 检验)"></a>Jarque-Bera 检验 (JB 检验)</h4><p><strong>适用条件</strong>：大样本(n&gt;30)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> jarque_bera</span><br><span class="line"></span><br><span class="line"><span class="comment"># 假设你的数据为 y</span></span><br><span class="line">statistic, p_value = jarque_bera(y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;JB 检验统计量:&#x27;</span>, statistic)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;p 值:&#x27;</span>, p_value)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> p_value &gt; <span class="number">0.05</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;数据符合正态分布&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;数据不符合正态分布&quot;</span>)</span><br></pre></td></tr></table></figure><h4 id="Shapiro-Wilk-检验"><a href="#Shapiro-Wilk-检验" class="headerlink" title="Shapiro-Wilk 检验"></a>Shapiro-Wilk 检验</h4><p><strong>适用条件</strong>：用于检验数据是否符合正态分布，适用于小样本数据（通常 n &lt; 50）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> shapiro</span><br><span class="line"></span><br><span class="line">statistic, p_value = shapiro(y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Shapiro-Wilk 检验统计量:&#x27;</span>, statistic)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;p 值:&#x27;</span>, p_value)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> p_value &gt; <span class="number">0.05</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;数据符合正态分布&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;数据不符合正态分布&quot;</span>)</span><br></pre></td></tr></table></figure><h4 id="Q-Q-图-Quantile-Quantile-Plot"><a href="#Q-Q-图-Quantile-Quantile-Plot" class="headerlink" title="Q-Q 图 (Quantile-Quantile Plot)"></a>Q-Q 图 (Quantile-Quantile Plot)</h4><p><strong>适用条件</strong>：数据量特别大</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> scipy.stats <span class="keyword">as</span> stats</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">stats.probplot(y, dist=<span class="string">&quot;norm&quot;</span>, plot=plt)</span><br><span class="line">plt.title(<span class="string">&#x27;Q-Q Plot&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h3 id="Spearman等级相关系数"><a href="#Spearman等级相关系数" class="headerlink" title="Spearman等级相关系数"></a>Spearman等级相关系数</h3><p>Spearman等级相关系数（Spearman’s rank correlation coefficient）是非参数统计的一种，用于测量两个变量的单调关系。它基于两个变量的排序，而不是原始数据。</p><p>小样本（n<30）:查临界值表，大样本情况（n > 30）: P值法</p><script type="math/tex; mode=display">r_s = 1 - \frac{6 \sum d_i^2}{n(n^2 - 1)}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br><span class="line"></span><br><span class="line">x = [<span class="number">10</span>, <span class="number">20</span>, <span class="number">30</span>, <span class="number">40</span>, <span class="number">50</span>, <span class="number">60</span>, <span class="number">70</span>, <span class="number">80</span>, <span class="number">90</span>, <span class="number">100</span>]</span><br><span class="line">y = [<span class="number">15</span>, <span class="number">30</span>, <span class="number">25</span>, <span class="number">35</span>, <span class="number">40</span>, <span class="number">60</span>, <span class="number">65</span>, <span class="number">70</span>, <span class="number">85</span>, <span class="number">95</span>]</span><br><span class="line"></span><br><span class="line">rho, p_value = stats.spearmanr(x, y)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Spearman相关系数:&quot;</span>, rho)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;p值:&quot;</span>, p_value)</span><br></pre></td></tr></table></figure><h3 id="Kendall等级相关系数"><a href="#Kendall等级相关系数" class="headerlink" title="Kendall等级相关系数"></a>Kendall等级相关系数</h3><p>Kendall等级相关系数（Kendall’s tau coefficient）也是一种非参数统计，用于测量两个变量之间的依赖关系。其计算公式如下：</p><script type="math/tex; mode=display">\tau = \frac{(C - D)}{\sqrt{(C + D + T) \cdot (C + D + U)}}</script><p>适用于：</p><ul><li>数据不符合正态分布</li><li>数据存在显著的异常值</li><li>变量之间的关系可能是非线性的</li><li>数据量较小的情况下，适用性较高</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br><span class="line"></span><br><span class="line">x = [<span class="number">10</span>, <span class="number">20</span>, <span class="number">30</span>, <span class="number">40</span>, <span class="number">50</span>, <span class="number">60</span>, <span class="number">70</span>, <span class="number">80</span>, <span class="number">90</span>, <span class="number">100</span>]</span><br><span class="line">y = [<span class="number">15</span>, <span class="number">30</span>, <span class="number">25</span>, <span class="number">35</span>, <span class="number">40</span>, <span class="number">60</span>, <span class="number">65</span>, <span class="number">70</span>, <span class="number">85</span>, <span class="number">95</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算Kendall相关系数和p值</span></span><br><span class="line">tau, p_value = stats.kendalltau(x, y)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Kendall相关系数:&quot;</span>, tau)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;p值:&quot;</span>, p_value)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 统计分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>t均值检验</title>
      <link href="/2024/08/02/t%E5%9D%87%E5%80%BC%E6%A3%80%E9%AA%8C/"/>
      <url>/2024/08/02/t%E5%9D%87%E5%80%BC%E6%A3%80%E9%AA%8C/</url>
      
        <content type="html"><![CDATA[<h1 id="t均值检验"><a href="#t均值检验" class="headerlink" title="t均值检验"></a>t均值检验</h1><h2 id="假设检验"><a href="#假设检验" class="headerlink" title="假设检验"></a>假设检验</h2><h3 id="1-假设检验"><a href="#1-假设检验" class="headerlink" title="1.假设检验"></a>1.假设检验</h3><p>假设检验(Hypothesis Testing)，又称统计假设检验，是用来判断样本与样本、样本与总体的差异是由抽样误差引起还是本质差别造成的统计推断方法。</p><p><strong>零假设(原假设）H0</strong>：指观察到的现象仅由随机抽样的误差所导致的，表示两个变量之间没有关系。</p><p><strong>备择假设H1</strong>：指原假设的否定，是我们想要通过样本数据来提供证据拒绝原假设，是我们想要的。</p><p><strong>P值</strong>：用来检验H0成立的概率。</p><div class="table-container"><table><thead><tr><th>P值</th><th>巧合概率</th><th>对无效假设</th><th>统计意义</th></tr></thead><tbody><tr><td>P&gt;0.05</td><td>巧合可能性大于5％</td><td>不能否定H0</td><td>两组数据差别无显著意义</td></tr><tr><td>P&lt;0.05</td><td>巧合可能性小于5％</td><td>可以否定H0</td><td>两组数据差别有显著意义</td></tr><tr><td>p&lt;0.01</td><td>巧合可能性小于1％</td><td>可以否定H0</td><td>两组数据差别有非常显著意义</td></tr></tbody></table></div><h3 id="2-两种错误"><a href="#2-两种错误" class="headerlink" title="2.两种错误"></a>2.两种错误</h3><p><strong>第一类错误</strong>：指原假设H0成立，却错误地拒绝了原假设。指即使小于显著性水平α来拒绝原假设，依旧有α的概率犯错，那么有1-α的概率正确，也称真阴性或特异性。</p><p><strong>第二类错误</strong>：指备择假设H1成立，不能拒绝原假设h0的错误概率，概率为β，则真正正确的概率为1-β，也称真阳性或灵敏度。</p><h3 id="3-三种检验"><a href="#3-三种检验" class="headerlink" title="3.三种检验"></a>3.三种检验</h3><p><strong>左尾检验</strong>：用于检验样本数据是否显著小于假设的总体参数值，如果计算得到的检验统计量小于临界值，则拒绝零假设，如果计算得到的检验统计量大于等于临界值，则不拒绝零假设。即原假设 H0:μ=0，备择假设H1:μ&lt;0。</p><p><strong>右尾检验</strong>：用于检验样本数据是否显著大于假设的总体参数值，如果计算得到的检验统计量大于临界值，则拒绝零假设，如果计算得到的检验统计量小于等于临界值，则不拒绝零假设。即原假设 H0:μ=0，备择假设H1:μ＞0。</p><p><strong>双尾检验</strong>：用于检验样本数据是否显著不同于假设的总体参数值，无论是显著大于还是显著小于，即原假设 H0:μ=0，备择假设H1:μ≠0。</p><h2 id="T检验"><a href="#T检验" class="headerlink" title="T检验"></a>T检验</h2><p><strong>t检验</strong>，又叫学生t检验，用于统计量服从正态分布，但方差未知的情况，前提是样本服从或近似服从正态分布（可利用数据变换，如取对，开根，倒数），如果不满足正态分布，则只能用非参数检验。</p><h3 id="1-单样本t检验-One-sample-t-test"><a href="#1-单样本t检验-One-sample-t-test" class="headerlink" title="1.单样本t检验(One-sample t-test)"></a>1.单样本t检验(One-sample t-test)</h3><p>检验单样本的均值与某一已知值是否有显著差异，只对一组样本进行检验。</p><p>要求总体方差未知，并且数据服从或近似服从正态分布。</p><p>比如从某高中抽几位近视学生，检验其近视度数是否高于全校学生近视平均水平。</p><p><strong>H0:样本均值与已知值相同，H1:样本均值与已知值不同</strong>，公式为：</p><script type="math/tex; mode=display">t = \frac{\overline x-μ_0}{s/\sqrt{n}}</script><p>假设我们想要检验某学校一组学生的考试成绩是否显著高于全国平均成绩。已知全国平均成绩μ0为 75 分。一组学生的考试成绩如下： 78,82,75,79,83,76,81,77,80,74。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br><span class="line"></span><br><span class="line">data = [<span class="number">78</span>, <span class="number">82</span>, <span class="number">75</span>, <span class="number">79</span>, <span class="number">83</span>, <span class="number">76</span>, <span class="number">81</span>, <span class="number">77</span>, <span class="number">80</span>, <span class="number">74</span>]</span><br><span class="line"></span><br><span class="line">sample_mean = np.mean(data)</span><br><span class="line">sample_std = np.std(data, ddof=<span class="number">1</span>)  <span class="comment"># ddof=1表示使用样本标准差</span></span><br><span class="line">n = <span class="built_in">len</span>(data)</span><br><span class="line">mu_0 = <span class="number">75</span>  <span class="comment"># 平均成绩</span></span><br><span class="line"></span><br><span class="line">t_statistic = (sample_mean - mu_0) / (sample_std / np.sqrt(n))</span><br><span class="line"></span><br><span class="line">p_value = stats.t.sf(np.<span class="built_in">abs</span>(t_statistic), df=n-<span class="number">1</span>) * <span class="number">2</span>  <span class="comment"># 双尾检验</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;样本平均值:&quot;</span>, sample_mean)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;样本标准差:&quot;</span>, sample_std)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;t值:&quot;</span>, t_statistic)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;p值:&quot;</span>, p_value)</span><br><span class="line"></span><br><span class="line">alpha = <span class="number">0.05</span></span><br><span class="line"><span class="keyword">if</span> p_value &lt; alpha:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;拒绝零假设，样本平均成绩显著不同于全国平均成绩。&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;不拒绝零假设，样本平均成绩与全国平均成绩没有显著差异。&quot;</span>)</span><br></pre></td></tr></table></figure><p>其中，<code>stats.t.sf</code> 是SciPy库中的函数，代表t分布的生存函数（survival function），也就是右尾概率。对于双尾检验，需要考虑t分布两端的概率。因此计算出右尾的概率后，将其乘以2以得到双尾的p值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">p_value = stats.t.cdf(t_statistic, df=n-<span class="number">1</span>)  <span class="comment"># 左尾检验</span></span><br><span class="line">p_value = stats.t.sf(t_statistic, df=n-<span class="number">1</span>)  <span class="comment"># 右尾检验</span></span><br></pre></td></tr></table></figure><h3 id="2-配对样本t检验（Paired-sample-t-test）"><a href="#2-配对样本t检验（Paired-sample-t-test）" class="headerlink" title="2.配对样本t检验（Paired-sample t-test）"></a>2.配对样本t检验（Paired-sample t-test）</h3><p>检验在两次不同条件下来自用一组观察对象的两组样本是否具有相同的均值,要求总体方差相等并且数据服从或近似服从正态分布，例如比较治疗前后的效果，或者比较两种不同测试方法的结果。</p><p>假设我们想要检验某种治疗方法在治疗前后是否对病人的血压有显著影响。我们有一组病人在治疗前后的血压数据。</p><p>病人治疗前后的血压数据如下：</p><ul><li>治疗前：[120, 130, 115, 140, 125, 135, 128, 150, 133, 145]</li><li>治疗后：[115, 128, 110, 138, 122, 130, 125, 145, 130, 140]</li></ul><p><strong>零假设（H0)</strong>：治疗前后的平均血压没有显著差异，即 $H_0:μ_d=0$（$μ_d$ 是差值的平均值）。</p><p><strong>备择假设（H1)</strong>：治疗前后的平均血压有显著差异，即 $H1:μ_d≠0 $</p><p>查找t分布表，使用显著性水平α/2=0.025和自由度df=n−1=9，得到临界值大约为 ±2.262。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br><span class="line"></span><br><span class="line">before_treatment = [<span class="number">120</span>, <span class="number">130</span>, <span class="number">115</span>, <span class="number">140</span>, <span class="number">125</span>, <span class="number">135</span>, <span class="number">128</span>, <span class="number">150</span>, <span class="number">133</span>, <span class="number">145</span>]</span><br><span class="line">after_treatment = [<span class="number">115</span>, <span class="number">128</span>, <span class="number">110</span>, <span class="number">138</span>, <span class="number">122</span>, <span class="number">130</span>, <span class="number">125</span>, <span class="number">145</span>, <span class="number">130</span>, <span class="number">140</span>]</span><br><span class="line"></span><br><span class="line">differences = np.array(before_treatment) - np.array(after_treatment)</span><br><span class="line"></span><br><span class="line">mean_diff = np.mean(differences)</span><br><span class="line">std_diff = np.std(differences, ddof=<span class="number">1</span>)</span><br><span class="line">n = <span class="built_in">len</span>(differences)</span><br><span class="line"></span><br><span class="line">t_statistic = mean_diff / (std_diff / np.sqrt(n))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算p值（双尾检验）</span></span><br><span class="line">p_value = stats.t.sf(np.<span class="built_in">abs</span>(t_statistic), df=n-<span class="number">1</span>) * <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;差值的平均值:&quot;</span>, mean_diff)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;差值的标准差:&quot;</span>, std_diff)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;t值:&quot;</span>, t_statistic)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;p值:&quot;</span>, p_value)</span><br><span class="line"></span><br><span class="line">alpha = <span class="number">0.05</span></span><br><span class="line"><span class="keyword">if</span> p_value &lt; alpha:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;拒绝零假设，治疗前后的平均血压有显著差异。&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;不拒绝零假设，治疗前后的平均血压没有显著差异。&quot;</span>)</span><br></pre></td></tr></table></figure><h3 id="3-独立双样本t检验-（Independent-two-sample-t-test）"><a href="#3-独立双样本t检验-（Independent-two-sample-t-test）" class="headerlink" title="3.独立双样本t检验 （Independent two-sample t-test）"></a>3.独立双样本t检验 （Independent two-sample t-test）</h3><p>检验两对独立的正态数据或近似正态的样本的均值是否相等，要求两样本独立且数据服从或近似服从正态分布。</p><p>进行独立双样本t检验之前，应该进行方差齐性检验（homogeneity of variance test），即检查两组样本的总体方差是否相同。方差齐性检验本身也是一种假设检验，通用的方法有Hartley检验、Bartlett检验和Leyene检验。</p><p>其中，合并标准差$S_p$与$t$计算公式为：</p><script type="math/tex; mode=display">S_p = \sqrt{\frac{(n_1-1)s_1^2+(n_2-1)s_2^2}{n_1+n_2-2}}\\t = \frac{\bar x_1-\bar x_2}{S_p\sqrt{1/n_1+1/n_2}}</script><p>假设检验两种不同教学方法对学生考试成绩的影响是否有显著差异。有两组学生的考试成绩数据，分别接受了两种不同的教学方法。两组学生的考试成绩如下：</p><ul><li>教学方法A组：85,90,88,92,85,87,91,89,90,86</li><li>教学方法B组：80,78,82,76,79,81,77,83,80,78</li></ul><p><strong>零假设（H0）</strong>：两组的平均成绩没有显著差异，即 $H_0:μ_1=μ_2$。</p><p><strong>备择假设（H1）</strong>：两组的平均成绩有显著差异，即 $H_0:μ_1≠μ_2$。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br><span class="line"></span><br><span class="line">group_a = [<span class="number">85</span>, <span class="number">90</span>, <span class="number">88</span>, <span class="number">92</span>, <span class="number">85</span>, <span class="number">87</span>, <span class="number">91</span>, <span class="number">89</span>, <span class="number">90</span>, <span class="number">86</span>]</span><br><span class="line">group_b = [<span class="number">80</span>, <span class="number">78</span>, <span class="number">82</span>, <span class="number">76</span>, <span class="number">79</span>, <span class="number">81</span>, <span class="number">77</span>, <span class="number">83</span>, <span class="number">80</span>, <span class="number">78</span>]</span><br><span class="line"></span><br><span class="line">mean_a = np.mean(group_a)</span><br><span class="line">mean_b = np.mean(group_b)</span><br><span class="line">std_a = np.std(group_a, ddof=<span class="number">1</span>)</span><br><span class="line">std_b = np.std(group_b, ddof=<span class="number">1</span>)</span><br><span class="line">n_a = <span class="built_in">len</span>(group_a)</span><br><span class="line">n_b = <span class="built_in">len</span>(group_b)</span><br><span class="line"></span><br><span class="line">t_statistic, p_value = stats.ttest_ind(group_a, group_b)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;组A平均值:&quot;</span>, mean_a)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;组B平均值:&quot;</span>, mean_b)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;组A标准差:&quot;</span>, std_a)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;组B标准差:&quot;</span>, std_b)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;t值:&quot;</span>, t_statistic)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;p值:&quot;</span>, p_value)</span><br><span class="line"></span><br><span class="line">alpha = <span class="number">0.05</span></span><br><span class="line"><span class="keyword">if</span> p_value &lt; alpha:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;拒绝零假设，两组的平均成绩有显著差异。&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;不拒绝零假设，两组的平均成绩没有显著差异。&quot;</span>)</span><br></pre></td></tr></table></figure><h3 id=""><a href="#" class="headerlink" title=" "></a> </h3>]]></content>
      
      
      
        <tags>
            
            <tag> 统计分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TOPSIS熵权法</title>
      <link href="/2024/07/30/TOPSIS%E7%86%B5%E6%9D%83%E6%B3%95/"/>
      <url>/2024/07/30/TOPSIS%E7%86%B5%E6%9D%83%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h1 id="TOPSIS法"><a href="#TOPSIS法" class="headerlink" title="TOPSIS法"></a>TOPSIS法</h1><p>TOPSIS（Technique for Order of Preference by Similarity to Ideal Solution，理想解逼近排序法）是一种用于多属性决策分析的排序方法。它用于评估和选择最优方案，尤其适用于当存在多个评价标准时。</p><p>TOPSIS方法通过计算各个方案与理想解和负理想解的距离来进行排序。理想解是所有标准下最好表现的方案，负理想解是所有标准下最差表现的方案。对每个方案，计算其与理想解和负理想解的欧几里得距离。然后，确定每个方案相对于这两个解的距离。通过比较方案到理想解和负理想解的距离，计算每个方案的相对接近度。相对接近度高的方案被认为更优。根据相对接近度对所有方案进行排序，选择接近理想解且远离负理想解的方案作为最优方案。</p><div class="table-container"><table><thead><tr><th style="text-align:center">姓名</th><th style="text-align:center">成绩</th><th style="text-align:center">排名</th><th style="text-align:center">SCORE</th></tr></thead><tbody><tr><td style="text-align:center">小李</td><td style="text-align:center">72</td><td style="text-align:center">2</td><td style="text-align:center">2 /10 = 0. 2</td></tr><tr><td style="text-align:center">小明</td><td style="text-align:center">56</td><td style="text-align:center">1</td><td style="text-align:center">1 / 10 = 0.1</td></tr><tr><td style="text-align:center">小华</td><td style="text-align:center">85</td><td style="text-align:center">3</td><td style="text-align:center">3 / 10 = 0.3</td></tr><tr><td style="text-align:center">小王</td><td style="text-align:center">96</td><td style="text-align:center">4</td><td style="text-align:center">4 / 10 = 0.4</td></tr></tbody></table></div><p>例如，如果按照每个人的排名来之间赋分的排名来决定<strong>SCORE</strong>值，这种方式仅考虑了排名的先后性，但却忽略了实际数值中的距离差异，比如如果小明考了20分，那他最后的SOCRE还是0.1，这就不太能满足我们实际的需求。我们需要的这个SCORE可以综合考虑多个特征值。</p><p>事实上，对于层次分析法而言，由于其主观性指标太强，有时候评价的模型很难有说服力，所以我们一般采用具有客观性指标的模型来进行评价，而TOPSIS法便能满足这一需求，TOPSIS不仅考虑了排名的先后性，也能比较数据的差异程度来进行综合评判。</p><h2 id="TOPSIS的步骤"><a href="#TOPSIS的步骤" class="headerlink" title="TOPSIS的步骤"></a>TOPSIS的步骤</h2><ul><li>将原始矩阵正向化。</li></ul><p>根据不同的数据类型，以及期望的指标类型，将进行评判的数据指标进行正向化处理，将所有指标类型统一变为极大型指标。</p><p>分为四种指标，分别是：<strong><em>极大型指标，较小型指标，中间型指标，区间型指标</em></strong>。</p><p><strong>极大型指标</strong>是指越大越好的指标，又叫效益型指标，比如经济效益，成绩等。</p><p><strong>较小型指标</strong>是指越小越好的指标。又叫成本型指标，比如污染值，成本等。</p><p><strong>中间型指标</strong>是指越贴近某个数值越好的指标，比如适合的PH值等。</p><p><strong>区间型指标</strong>是指在某个区间越好的指标，比如适合的温度区间等。</p><p>后三个指标转化成极大型指标的方法：</p><p><strong>较小型指标转换为极大型指标</strong>：</p><script type="math/tex; mode=display">\hat x_i  =max - xi \ or \ \ \frac{1}{xi}</script><p><strong>中间型指标转换为极大型指标</strong>：</p><p>假设$x_p$为最佳指标。</p><script type="math/tex; mode=display">\hat x_i = 1 - \frac{\mid x_i - x_p\mid}{max \{ \mid {x_i-x_p}\mid\}}</script><p><strong>区间型指标转换为极大型指标</strong>：</p><p>假设$[a,b]$为最佳区间。</p><script type="math/tex; mode=display">\hat x_i = \left\{\begin{align*}1 - \frac{a-x_i}{max \{ a-min(x_i),max(x_i)-b\} }  \ \ \ \ x_i\leq a\\ 1 - \frac{x_i-b}{max \{ a-min(x_i),max(x_i)-b\} }\ \ \ \ x_i>b\\ \end{align*}\right.</script><ul><li>将正向化矩阵标准化</li></ul><p>正向化矩阵用来消除不同量纲的影响。</p><script type="math/tex; mode=display">X = \begin{pmatrix}        x_{11} & x_{12} & \cdots & x_{1m}\\        x_{21} & x_{22} & \cdots & x_{2m}\\        \vdots & \vdots & \ddots & \vdots\\        x_{n1} & x_{n2} & \cdots & x_{nm}\\    \end{pmatrix}</script><p>标准化后的矩阵$Z$为：</p><script type="math/tex; mode=display">Z_{ij} = \frac{x_{ij}}{\sqrt{\sum_{i=1}^{n}x_{ij}^{2}}}</script><ul><li>计算得分并归一化</li></ul><script type="math/tex; mode=display">Z_{max} = (Z_{max}^{1},Z_{max}^{2},...,Z_{max}^{m})</script><script type="math/tex; mode=display">Z_{min} = (Z_{min}^{1},Z_{min}^{2},...,Z_{min}^{m})</script><script type="math/tex; mode=display">D_{max}^{i} = \sqrt{\sum_{j=1}^{m}\omega_{j}(Z_{max}^{j}-z_{ij})^{2}}</script><script type="math/tex; mode=display">D_{min}^{i} = \sqrt{\sum_{j=1}^{m}\omega_{j}(Z_{min}^{j}-z_{ij})^{2}}</script><p>得到每个指标的最大值$Z<em>{max}$和最小值$Z</em>{min}$后，计算$z<em>{ij}$与它们之间的距离，得到$D</em>{max}^{i}$与$D<em>{min}^{i}$，紧接着出第$i$个对象的指标评分$S_i$，其中$\omega</em>{j}$是权重。</p><script type="math/tex; mode=display">S_i = \frac{D_{min}^{i}}{D_{min}^{i}+D_{max}^{i}}</script><p>再进行归一化，得到$\hat S_{i{}}$:</p><script type="math/tex; mode=display">\hat S_i = \frac{S_i}{\sum_{i=1}^{n}S_i}</script><h2 id="权重计算：熵权法"><a href="#权重计算：熵权法" class="headerlink" title="权重计算：熵权法"></a>权重计算：熵权法</h2><p>权重的计算方式有很多，比如层次分析法，但其主观性太强，所以我们这里选择熵权法。</p><script type="math/tex; mode=display">p_{ij} = \frac{x_{ij}}{\sum_{i=1}^{m} x_{ij}}e_j = -k \sum_{i=1}^{m} p_{ij} \ln p_{ij}</script><p>$p_{ij}$ 表示第 $i$ 个方案在第 $j$ 个指标上的标准化值，是一个常数，$k = 1/ln \ m$用于保证 $e_j$ 的取值范围在 [0,1] 之间。 </p><h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 极小型转为极大型指标</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">dataDirection_1</span>(<span class="params">datas, offset=<span class="number">0</span></span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">normalization</span>(<span class="params">data</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span> / (data + offset)</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">list</span>(<span class="built_in">map</span>(normalization, datas))</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="comment"># 中间型指标转为极大型指标</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">dataDirection_2</span>(<span class="params">datas, x_min, x_max</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">normalization</span>(<span class="params">data</span>):</span><br><span class="line">        <span class="keyword">if</span> data &lt;= x_min <span class="keyword">or</span> data &gt;= x_max:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="keyword">elif</span> data &gt; x_min <span class="keyword">and</span> data &lt; (x_min + x_max) / <span class="number">2</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">2</span> * (data - x_min) / (x_max - x_min)</span><br><span class="line">        <span class="keyword">elif</span> data &lt; x_max <span class="keyword">and</span> data &gt;= (x_min + x_max) / <span class="number">2</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">2</span> * (x_max - data) / (x_max - x_min)</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">list</span>(<span class="built_in">map</span>(normalization, datas))</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 区间型指标转为极大型指标</span></span><br><span class="line"><span class="comment"># [x_min, x_max]最佳稳定区间, [x_minimum, x_maximum]容忍区间</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">dataDirection_3</span>(<span class="params">datas, x_min, x_max, x_minimum, x_maximum</span>):  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">normalization</span>(<span class="params">data</span>):</span><br><span class="line">        <span class="keyword">if</span> data &gt;= x_min <span class="keyword">and</span> data &lt;= x_max:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">        <span class="keyword">elif</span> data &lt;= x_minimum <span class="keyword">or</span> data &gt;= x_maximum:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="keyword">elif</span> data &gt; x_max <span class="keyword">and</span> data &lt; x_maximum:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span> - (data - x_max) / (x_maximum - x_max)</span><br><span class="line">        <span class="keyword">elif</span> data &lt; x_min <span class="keyword">and</span> data &gt; x_minimum:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span> - (x_min - data) / (x_min - x_minimum)</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">list</span>(<span class="built_in">map</span>(normalization, datas))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">entropyWeight</span>(<span class="params">data</span>):</span><br><span class="line">    data = np.array(data)</span><br><span class="line">    <span class="comment"># 计算第j个指标下第i个样本所占的比重，相对熵计算中用到的概率</span></span><br><span class="line">    P = data / data.<span class="built_in">sum</span>(axis=<span class="number">0</span>)  <span class="comment"># 压缩行</span></span><br><span class="line">    <span class="comment"># 计算熵值</span></span><br><span class="line">    E = np.nansum(-P * np.log(P) / np.log(<span class="built_in">len</span>(data)), axis=<span class="number">0</span>)</span><br><span class="line">    <span class="comment"># 信息效用值</span></span><br><span class="line">    d = (<span class="number">1</span> - E)</span><br><span class="line">    <span class="comment"># 计算权系数</span></span><br><span class="line">    W = d / d.<span class="built_in">sum</span>()</span><br><span class="line">    <span class="keyword">return</span> W</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 综合评价 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>决策树与随机森林</title>
      <link href="/2024/07/27/%E5%86%B3%E7%AD%96%E6%A0%91%E4%B8%8E%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/"/>
      <url>/2024/07/27/%E5%86%B3%E7%AD%96%E6%A0%91%E4%B8%8E%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/</url>
      
        <content type="html"><![CDATA[<h1 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h1><p>决策树(decision tree)是有监督学习下的一种基本的分类与回归算法，其根据特征来对实际进行if-then条件的判断来进行分类。决策树的学习包括三个步骤：特征选择，决策树的生成和裁剪。</p><h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>决策树由结点(node)和有向边(directed edge)组成，结点有两种类型：内部结点(internal node)和叶结点(leaf node)，内部结点表示一个特征或属性，叶标点表示一个类。</p><h3 id="if-then规则"><a href="#if-then规则" class="headerlink" title="if-then规则"></a>if-then规则</h3><p>if-then规则的性质是：互斥且完备，这意味着每一个实例都被一条路径或一条规则所覆盖，且只能被一条路径或一条规则所覆盖。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">         [Feature 1]</span><br><span class="line">        /           \</span><br><span class="line">   [Value A]      [Value B]</span><br><span class="line">     /               \</span><br><span class="line">[Leaf 1]         [Feature 2]</span><br><span class="line">                    /       \</span><br><span class="line">             [Value X]   [Value Y]</span><br><span class="line">               /            \</span><br><span class="line">          [Leaf 2]       [Leaf 3]</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>决策树的树概念可以以kd树为基础进行理解，在特征空间下，根据不同的特征定义不同的划分来划分为不同的单元或区域，假设$X$为表示特征的随机变量，$Y$为表示类的随机变量，那么条件概率分布表示为$P(Y\mid X)$，$X$取值于给定划分下单元的集合，$Y$取值于类的集合，各叶结点上的条件概率往往偏向于某一个类，决策树分类时将该结点的实例强行划分到条件概率大的那一类去。</p><p>与训练数据集不相矛盾的决策树可能有多个，也可能一个都没有，一般我们选择与训练数据矛盾较小且具有很好泛化能力的决策树。</p><p>决策树学习的算法通常是一个递归地选择最优特征，并根据特征来自对训练数据进行分割。</p><ul><li>构建根结点，将所有训练数据都放在根节点。</li><li>选择一个最优特征，根据特征来将训练数据划分为子集，使得每个子集有一个在当前条件下最好的分类。</li><li>如果这些子集已经能够被基本正确分类，那么构建叶结点，并将子集划分到叶节点中，如果不能被基本正确分类，那么就继续选择最优特征进行分割，直至能基本分类正确，进行递归。</li></ul><p>这样的树会有很好的分类能力，但是会出现过拟合现象，所以要剪枝来使其具有更好的泛化能力。</p><p>决策树的生成只考虑局部最优，而剪枝考虑全局最优。</p><h3 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h3><p>选取对训练数据具有分类能力的特征，而不是没有作用的特征可以提高决策树的学习效率，决策树选用信息增益准则来选择特征。</p><h4 id="信息增益准则"><a href="#信息增益准则" class="headerlink" title="信息增益准则"></a>信息增益准则</h4><p><strong>熵</strong>（entropy) 是表示随机变量不确定性的度量，设$X$是一个取有限个值的离散随机变量，其概率分布为:$P(X=x<em>i)=p_i$，则随机变量$X$的熵定义为:$H(X)=-\sum</em>{i=1}^{n}p_ilogp_i$。一般对数以2或$e$为底，此时单位分布为比特(bit)或纳特(nat)，所以熵只依赖于$X$的分布而与$X$的取值无关，记作$H(p)$。熵越大，随机变量的不确定性越大，有$0\leq H(p)\leq log\ n$。</p><p>例如，当随机变量只有0，1时，$P(X=1)=p,P(X=0)=1-p$，此时$H(p)$的图像呈现向下的二次函数形式，当时$p=0$或$p=1$时，随机变量完全没有不确定性，当$p=0.5$时，$H(p)=1$，熵值最大。</p><p>设随机变量$(X,Y)$，其概率分布为$P(X=x<em>i,Y=y_i)=p</em>{ij}$，条件熵$H(Y\mid X)$表示在已知随机变量X的条件下随机变量$Y$的不确定性。其中：</p><script type="math/tex; mode=display">H(Y\mid X) = \sum_{i=1}^{n}p_iH(Y\mid X=x_i)</script><p>这里的$p_i=P(X=x_i)$。</p><p>当熵和条件熵中的概率由数据估计（特别是极大似然估计）得到的时候，所对应的值分布称为经验熵（empirical entropy)和经验条件熵(empirical conditional entropy)。</p><p><strong>信息增益</strong>表示得知特征$X$的信息而使类$Y$的信息不确定性减少的程度，定义为$g(D, A)$</p><script type="math/tex; mode=display">g(D,A)=H(D)-H(D\mid A)</script><p>一般地，熵$H(Y)$与条件熵$H(Y\mid X)$之差称为互信息，信息增益越大越好。</p><h2 id="信息增益算法"><a href="#信息增益算法" class="headerlink" title="信息增益算法"></a>信息增益算法</h2><p>假设训练数据集为$D$，$\mid D \mid$表示其样本容量，即样本个数，设有$K$个类$C<em>k,k=0,1,2,…$，$\mid C_k \mid$为属于类$C_k$的样本个数，$\sum</em>{k=1}^K \mid C<em>k\mid = \mid D \mid$。设有特征$A$有$n$个不同的取值${a_1,a_2,…,a_n}$，根据特征$A$的取值将$D$划分为$n$个子集$D_1,D_2,…,D_n$，$\mid D_i \mid$为$D_i$的个样本个数，$\sum</em>{i=1}^n \mid D<em>i\mid =\mid D \mid$，记子集$D_i$中属于类$C_k$的样本集合为$D</em>{ik}$，即$D<em>{ik}=Di\cap C_k$，$\mid D</em>{ik}\mid$为$D_ik$的样本个数。</p><p>首先输入训练数据集$D$和特征$A$，来输出特征$A$对$D$的信息增益$g(D,A)$。</p><ul><li><p>计算经验熵$H(D)$，有$H(D)=-\sum_{k=1}^K \frac{\mid C_k \mid}{\mid D \mid}log_2\frac{\mid C_k\mid}{\mid D\mid}$</p></li><li><p>$H(D\mid A)=\sum<em>{i=1}^{n}\frac{\mid D_i\mid}{\mid D\mid}H(D_i)=-\sum</em>{i=1}^{n}\frac{\mid D<em>i\mid}{\mid D\mid}\sum</em>{k=1}^K \frac{\mid C_k \mid}{\mid D \mid}log_2\frac{\mid C_k\mid}{\mid D\mid}$​</p></li><li>计算信息增益$g(D,A)=H(D)-H(D\mid A)$​</li></ul><p>此外，还有<strong>信息增益比</strong>的概念</p><h2 id="决策树的生成"><a href="#决策树的生成" class="headerlink" title="决策树的生成"></a>决策树的生成</h2><h3 id="ID3算法"><a href="#ID3算法" class="headerlink" title="ID3算法"></a>ID3算法</h3><h3 id="ID4-5算法"><a href="#ID4-5算法" class="headerlink" title="ID4.5算法"></a>ID4.5算法</h3><h2 id="CART树"><a href="#CART树" class="headerlink" title="CART树"></a>CART树</h2><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier, export_text</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> tree</span><br><span class="line"></span><br><span class="line">data = load_iris()</span><br><span class="line">X = data.data</span><br><span class="line">y = data.target</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.3</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">clf = DecisionTreeClassifier()</span><br><span class="line"></span><br><span class="line">clf.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">tree_rules = export_text(clf, feature_names=data.feature_names)</span><br><span class="line"><span class="built_in">print</span>(tree_rules)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>,<span class="number">8</span>))</span><br><span class="line">tree.plot_tree(clf, feature_names=data.feature_names, class_names=data.target_names, filled=<span class="literal">True</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h1><h2 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score, classification_report, confusion_matrix</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line">data = load_iris()</span><br><span class="line"></span><br><span class="line">X = data.data</span><br><span class="line">y = data.target</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.3</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">clf = RandomForestClassifier(n_estimators=<span class="number">100</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">clf.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">y_pred = clf.predict(X_test)</span><br><span class="line"></span><br><span class="line">accuracy = accuracy_score(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Accuracy: <span class="subst">&#123;accuracy:<span class="number">.2</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印分类报告和混淆矩阵</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\nClassification Report:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Confusion Matrix:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(confusion_matrix(y_test, y_pred))</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>朴素贝叶斯算法及实现</title>
      <link href="/2024/07/27/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%AE%97%E6%B3%95%E5%8F%8A%E5%AE%9E%E7%8E%B0/"/>
      <url>/2024/07/27/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%AE%97%E6%B3%95%E5%8F%8A%E5%AE%9E%E7%8E%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="朴素贝叶斯"><a href="#朴素贝叶斯" class="headerlink" title="朴素贝叶斯"></a>朴素贝叶斯</h1><p>朴素贝叶斯(naive Bayes)法是基于贝叶斯定理与特征条件独立假设的分类方法，对于给定训练数据集，基于特征条件独立假设学习输入输出的联合概率分布，然后基于此模型对给定的输入 x ，利用贝叶斯定理求出后验概率最大的输出 y 。</p><h2 id="贝叶斯定理"><a href="#贝叶斯定理" class="headerlink" title="贝叶斯定理"></a>贝叶斯定理</h2><p>贝叶斯定理（Bayes’ Theorem）是概率论中的一个重要公式，用于计算在已知某些事件发生的情况下，另一事件发生的概率。它建立了后验概率（posterior probability）和先验概率（prior probability）、条件概率（conditional probability）之间的关系。</p><script type="math/tex; mode=display">\begin{align*}P(A \mid B) = \frac{P(B \mid A) \, P(A)}{P(B)}\end{align*}</script><p>其中，P(A∣B) 是在事件 B 发生后事件 A 发生的后验概率，P(A) 是事件 A 的先验概率，P(B∣A) 是在事件 A 发生的情况下事件 B 发生的条件概率，P(B) 是事件 B 的边缘概率。</p><h2 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h2><p>我们将类别设为C，输入特征向量为 x = {x1,x2,…,xn}，那么根据贝叶斯定理：</p><script type="math/tex; mode=display">\begin{equation}P(C \mid \mathbf{x}) = \frac{P(\mathbf{x} \mid C) P(C)}{P(\mathbf{x})}\end{equation}</script><p>其中，P(x) 是特征向量 x 的边缘概率， P(C) 是类别的先验概率，P(x∣C) 是似然函数，即在给定类别 C 的情况下，观察到特征向量 x 的概率，P(C∣x) 是后验概率，即在给定特征向量 x 的情况下，类别 C 的概率。</p><p>在朴素贝叶斯模型中，假设特征是条件独立的,故P(C|x)正比于这些单独条件概率的乘积。</p><script type="math/tex; mode=display">\begin{equation}P(C \mid \mathbf{x}) \propto P(C) \prod_{i=1}^{n} P(x_i \mid C)\end{equation}</script><p>为了分类，我们选择具有最大后验概率的类别 CMAP,将其作为x的类输出，后验概率计算：</p><script type="math/tex; mode=display">\begin{equation}C_{\text{MAP}} = \arg\max_C P(C \mid \mathbf{x}) = \arg\max_C P(C) \prod_{i=1}^{n} P(x_i \mid C)\end{equation}</script><h2 id="后验概率最大化"><a href="#后验概率最大化" class="headerlink" title="后验概率最大化"></a>后验概率最大化</h2><p>可以看到，朴素贝叶斯将实例分到了后验概率最大的类中，其等于期望风险最小化。</p><p>定义0-1损失函数:</p><script type="math/tex; mode=display">L(Y,f(X)) = \left\{\begin{align*}1,Y≠f(X)\\0,Y=f(X)\end{align*}\right.</script><p>其中，f(X)是分类决策函数，此时的期望风险函数为:$R_{exp}(f) = E[L(Y,f(X))]$，这里如果f(X)的类和 Y 不同，那么则定为1，这样不同的类数越多，损失函数越大。期望是对联合分布$P(X,Y)$​取的，所以条件期望变为：</p><script type="math/tex; mode=display">\begin{equation}R_{exp}(f) = E_{X}\sum_{k=1}^{K} [L(c_{k},f(X))]P(c_{k}|X)\end{equation}</script><p>为了使期望风险最小化，只需对X=x逐个极小化。</p><script type="math/tex; mode=display">f(x) = argmin_{y∈Y}\sum_{k=1}^{K} L(c_{k},y)P(c_{k}|X=x)\\=argmin_{y∈Y}(1-\sum_{k=1}^{K}P(y≠c_{k}|X=x))\\=argmax_{y∈Y}P(y=c_{k}|X=x)</script><p>这样，期望风险最小化准则就变成了后验概率最大化准则，即朴素贝叶斯采用的原理。</p><h2 id="参数估计"><a href="#参数估计" class="headerlink" title="参数估计"></a>参数估计</h2><h3 id="极大似然估计"><a href="#极大似然估计" class="headerlink" title="极大似然估计"></a>极大似然估计</h3><script type="math/tex; mode=display">P(Y = C_{k}) = \frac{ \sum_{i=1}^{N} I(y_i=C_k)}{N}</script><p>其中，$I(y_i=c_k)$判断是否属于$C_k$类，求和后除以总数N便是类别$C_k$的先验概率。</p><p>紧接着计算条件概率:</p><script type="math/tex; mode=display">P(X^{j}=a_{jl} \mid Y = c_k) = \frac{\sum_{i=1}^{N}I(x_i^{(j)}=a_{jl},y_i=c_k)}{\sum_{i=1}^{N}I(y_i=c_k)}</script><p>其中，$x<em>i$ 是数据集，而 $x_i^{(j)}$ 是指第 $i$ 个样本的第 $j$ 个特征，$a</em>{jl}$ 是第 $ j$ 个特征可能取的第 $l$ 个值。</p><p>这样来计算：</p><script type="math/tex; mode=display">P(Y=c_k)\prod_{j=1}^{n}P(X^{(j)}=x^{(j)} \mid Y = c_k)</script><p>最后在取后验概率最大值就可以了。</p><h3 id="贝叶斯估计"><a href="#贝叶斯估计" class="headerlink" title="贝叶斯估计"></a>贝叶斯估计</h3><p>用极大似然估计可能会出现概率值为0的情况，所以为了解决这一问题，引入一个正数 $\lambda$，变为</p><script type="math/tex; mode=display">P(X^{j}=a_{jl} \mid Y = c_k) = \frac{\sum_{i=1}^{N}I(x_i^{(j)}=a_{jl},y_i=c_k)+\lambda}{\sum_{i=1}^{N}I(y_i=c_k)+S_j\lambda}</script><p>当$\lambda$ = 1时，称为拉普拉斯平滑(Laplacian smoothing)，一般也取为1。</p><h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p>工具箱一般有MultinomialNB，BernoulliNB()，其中alpha参数便是上述的$\lambda$，一般取<code>α=1.0</code>。GaussianNB()，其自动通过高斯分布来估计。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> MultinomialNB</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里选择经典的iris数据集</span></span><br><span class="line">data = load_iris()</span><br><span class="line">X = data.data</span><br><span class="line">y = data.target</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.3</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">model = MultinomialNB()</span><br><span class="line"></span><br><span class="line">model.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">y_pred = model.predict(X_test)</span><br><span class="line"></span><br><span class="line">accuracy = accuracy_score(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Accuracy: <span class="subst">&#123;accuracy:<span class="number">.2</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>最后准确率为0.96，还是比较高的。</p><h2 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h2><p>当特征在给定类别的条件下近似独立时，朴素贝叶斯分类器的假设较为合理，如果特征之间有很强的相关性，存在强依赖关系或交互作用，朴素贝叶斯的假设可能会导致性能下降。</p><p>如果数据特征非常复杂且不能被简单的条件独立假设捕捉，则需要考虑其他更复杂的模型（如决策树、随机森林），朴素贝叶斯分类器最适合高维、稀疏的离散数据。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>KNN算法及其实现</title>
      <link href="/2024/07/27/KNN%E7%AE%97%E6%B3%95%E5%8F%8A%E5%85%B6%E5%AE%9E%E7%8E%B0/"/>
      <url>/2024/07/27/KNN%E7%AE%97%E6%B3%95%E5%8F%8A%E5%85%B6%E5%AE%9E%E7%8E%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="KNN算法"><a href="#KNN算法" class="headerlink" title="KNN算法"></a>KNN算法</h1><p>K近邻算法 (K-nearest neighbor, K-NN)，是一种基本的分类与回归算法，其不具有显式的学习过程，利用训练数据集对特征向量空间进行划分，并作为分类的模型。</p><h2 id="算法实现"><a href="#算法实现" class="headerlink" title="算法实现"></a>算法实现</h2><p>KNN通过给定一个训练数据集，对新的输入实例，在训练数据集中找到与其最邻近的k个实例，如果这k个实例的多数属于某个类，那么就把这个新输入的实例划分为这个类。</p><p>通过给定输入训练数据集:<em>T = {( (X1,Y1),(X2,Y2),(Xn,Yn) )}</em>，来输出实例x所属的类y。</p><ul><li>根据给定的距离量度，在训练数据集T中找出与x最近邻的k个点，涵盖这k个点的x邻域称为Nk(x)</li><li>在Nk(x)中根据分类决策规则来决定x的类别y</li></ul><p>当 k=1 时，称为最近邻算法。</p><h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>本质上是对训练的特征空间进行划分，定义每个训练点<em>x_{i}</em>，距离该点比其他点更近的所有点组成的一个区域叫做单元(cell)。对于给定新的输入实例点，kNN都能根据规则和模型来唯一确定这个点所属的类。</p><h2 id="距离量度"><a href="#距离量度" class="headerlink" title="距离量度"></a>距离量度</h2><p>那么如何区分两个实例点之间的相似程度呢？这里可以用多个方法，比如Lp（Lp distance)距离与Minkowski距离，以下是Lp距离的公式：</p><script type="math/tex; mode=display">\begin{align*}L_p(\mathbf{x}, \mathbf{y}) = \left( \sum_{i=1}^n \left| x_i - y_i \right|^p \right)^{\frac{1}{p}}\end{align*}</script><ul><li>p = 2时，称为欧氏距离(Euclidean distance)，常用于一般情况下分析两点之间的相似程度。</li><li><p>p = 1时，称为曼哈顿距离(Manhatten distance)，一般用于城市规划等。</p></li><li><p>p = ∞时，它是各个坐标距离的最大值。</p></li></ul><p>k值的选择会对结果产生重大影响，当k值选择的较小，其近似误差会减小，但是估计误差会增大，其会导致对近邻点敏感，所以如果数据集中存在噪声点，会对输出结果造成极大影响，模型会变得复杂与过拟合。</p><p>如果k值选择较大，那么近似误差会增大，估计误差会减小，此时模型会变得简单，较远的点也会对分类造成影响，</p><p>一般来说，k值选择较小的数值。用交叉验证法来选取最优的值。</p><h2 id="分类决策规则"><a href="#分类决策规则" class="headerlink" title="分类决策规则"></a>分类决策规则</h2><p>k近邻一般采用多数表决策略，多数表决规则等价于经验风险最小化。</p><h2 id="kd树"><a href="#kd树" class="headerlink" title="kd树"></a>kd树</h2><p>一般来说，训练数据可能过大，而又不可能对每一个点进行距离的计算，那样计算量会特别大，为了减少计算量，可以采用特殊的存储结构来存储训练的数据，其中之一便是kd树 (kd tree) 方法。</p><h4 id="kd树的构建"><a href="#kd树的构建" class="headerlink" title="kd树的构建"></a>kd树的构建</h4><ul><li>首先，选择轴，如果是二维平面，那么第一层使用X轴来进行数据点的分割，第二层使用Y轴，然后再回到X轴，以此类推。</li><li>其次，在每一曾上选择一个点作为分割点，并将其他点分为两个子集，这里有点类似于二分查找的思想，即为了保证树的平衡性，我们一般选择这一层上的中位点作为数据分割点。</li><li>然后，对每个子集进行重复上述操作，不断分割递归，直至每个子集只包含一个点或达到某个停止条件。</li></ul><h4 id="kd树的查找"><a href="#kd树的查找" class="headerlink" title="kd树的查找"></a>kd树的查找</h4><ul><li>先从根节点开始，检查分割点与查询点的距离。如果查询点在分割点的左侧，我们首先搜索左子树，否则搜索右子树。</li><li>在搜索过程中，我们递归地访问子树，并计算每个点到查询点的距离。每次访问一个节点时，我们会检查是否有可能存在比当前找到的最近邻更接近的点。</li><li>在搜索过程剪枝掉不必要的部分。如果某个子树的分割超球体与查询点的距离大于当前已知的最近邻距离，便可以跳过这个子树的搜索，以此加速查找过程。</li></ul><figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">    <span class="built_in">D</span>(<span class="number">7</span>, <span class="number">7</span>)</span><br><span class="line">   / </span><br><span class="line">  <span class="selector-tag">B</span>(<span class="number">3</span>, <span class="number">5</span>)</span><br><span class="line"> / \</span><br><span class="line"><span class="selector-tag">A</span>(<span class="number">1</span>, <span class="number">2</span>) <span class="built_in">C</span>(<span class="number">4</span>, <span class="number">2</span>)</span><br></pre></td></tr></table></figure><p>比如，我们有一个输入点E (5,5)，然后选择D (7,7)作为起始根结点，发现B点更接近E点，此时将最近点更新为B，这时发现B点生成的叶结点就只剩A与C，再将A,C分别与D对比，最后判断D的类,更新最近邻为 C，因为 C 比 B更接近 (5, 5)。</p><h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p>我们可以使用Sklearn工具箱来调用knn算法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"></span><br><span class="line">X = np.array([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">2</span>, <span class="number">3</span>], [<span class="number">3</span>, <span class="number">4</span>], [<span class="number">5</span>, <span class="number">5</span>], [<span class="number">6</span>, <span class="number">6</span>]])</span><br><span class="line">y = np.array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># k=3</span></span><br><span class="line">knn = KNeighborsClassifier(n_neighbors=<span class="number">3</span>)</span><br><span class="line">knn.fit(X, y)</span><br><span class="line"></span><br><span class="line">test_points = np.array([[<span class="number">4</span>, <span class="number">4</span>]])</span><br><span class="line">predictions = knn.predict(test_points)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, point <span class="keyword">in</span> <span class="built_in">enumerate</span>(X):</span><br><span class="line">    plt.scatter(point[<span class="number">0</span>], point[<span class="number">1</span>], c=<span class="string">&#x27;red&#x27;</span> <span class="keyword">if</span> y[i] == <span class="number">0</span> <span class="keyword">else</span> <span class="string">&#x27;blue&#x27;</span>, label=<span class="string">f&#x27;Class <span class="subst">&#123;y[i]&#125;</span>&#x27;</span> <span class="keyword">if</span> i == <span class="number">0</span> <span class="keyword">else</span> <span class="string">&quot;&quot;</span>)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">for</span> i, point <span class="keyword">in</span> <span class="built_in">enumerate</span>(test_points):</span><br><span class="line">    plt.scatter(point[<span class="number">0</span>], point[<span class="number">1</span>], c=<span class="string">&#x27;green&#x27;</span>, marker=<span class="string">&#x27;x&#x27;</span>, s=<span class="number">100</span>, label=<span class="string">&#x27;Test Point&#x27;</span> <span class="keyword">if</span> i == <span class="number">0</span> <span class="keyword">else</span> <span class="string">&quot;&quot;</span>)</span><br><span class="line">    plt.text(point[<span class="number">0</span>] + <span class="number">0.1</span>, point[<span class="number">1</span>], <span class="string">f&#x27;Prediction: <span class="subst">&#123;predictions[i]&#125;</span>&#x27;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line">plt.xlabel(<span class="string">&#x27;Feature 1&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Feature 2&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.title(<span class="string">&#x27;kNN Classification with scikit-learn&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>我们也可以根据原理来写一下内部代码是什么样的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算欧氏距离</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">euclidean_distance</span>(<span class="params">point1, point2</span>):</span><br><span class="line">    <span class="keyword">return</span> np.sqrt(np.<span class="built_in">sum</span>((point1 - point2) ** <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">k_nearest_neighbors</span>(<span class="params">X, y, test_point, k=<span class="number">3</span></span>):</span><br><span class="line">    distances = [euclidean_distance(x, test_point) <span class="keyword">for</span> x <span class="keyword">in</span> X]</span><br><span class="line">    k_indices = np.argsort(distances)[:k]</span><br><span class="line">    k_nearest_labels = [y[i] <span class="keyword">for</span> i <span class="keyword">in</span> k_indices]</span><br><span class="line">    most_common = Counter(k_nearest_labels).most_common(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> most_common[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">X = np.array([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">2</span>, <span class="number">3</span>], [<span class="number">3</span>, <span class="number">4</span>], [<span class="number">5</span>, <span class="number">5</span>], [<span class="number">6</span>, <span class="number">6</span>]])</span><br><span class="line">y = np.array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">test_points = np.array([[<span class="number">4</span>, <span class="number">4</span>]])</span><br><span class="line">predictions = [k_nearest_neighbors(X, y, tp, k=<span class="number">3</span>) <span class="keyword">for</span> tp <span class="keyword">in</span> test_points]</span><br></pre></td></tr></table></figure><h2 id="可改进点"><a href="#可改进点" class="headerlink" title="可改进点"></a>可改进点</h2><p>比如进行具体的距离规划，而不是统一的简单的欧式距离。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RNN与LSTM原理及代码实现</title>
      <link href="/2024/07/08/RNN-%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/"/>
      <url>/2024/07/08/RNN-%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="RNN与LSTM"><a href="#RNN与LSTM" class="headerlink" title="RNN与LSTM"></a>RNN与LSTM</h1><h2 id="一个关于RNN由来的例子"><a href="#一个关于RNN由来的例子" class="headerlink" title="一个关于RNN由来的例子"></a>一个关于RNN由来的例子</h2><p><img src="imgs\image-20240708212505196.png" alt="image-20240708212505196"></p><p>如果想解决词汇编码的问题，可以通过Word hashing来表示。</p><p><img src="imgs\image-20240708212659170.png" alt="image-20240708212659170"></p><p>对于简单的这种网络，只能简单识别出Taipei是目的地或是出发地，而不是精准的判断Taipei到底是出发地还是目的地，对于leave和arrive这两个词被划分到了’other’维度，所以想要解决这个问题，就需要一个有记忆力的神经网络，这就是Recurrent Neural Network(RNN)。</p><h2 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h2><p><img src="imgs\image-20240708213056663.png" alt="image-20240708213056663"></p><p>那么，需要创建新的a1与a2，来分别存储hidden layer的output，并且，下一次hidden layer的input不光是x1和x2的输入，还包括a1和a2的输入。</p><p><img src="imgs\image-20240708213531877.png" alt="image-20240708213531877"></p><p>这样的话，就可以实现一整个语句的输入了。</p><p><img src="imgs\image-20240708213742365.png" alt="image-20240708213742365"></p><p>当然也可以实现更深的RNN。</p><p><img src="imgs\image-20240708213814636.png" alt="image-20240708213814636"></p><p>另外还有两种Network，一个是Elman Network和Jordan Network，Jordan Network是根据前一个的最后输出来进行存储。</p><p><img src="imgs\image-20240708214010297.png" alt="image-20240708214010297"></p><p>此外还有双向的RNN，即考虑了正向和反向，并将两者的output输出，得到Yt,这样的话范围更广。</p><p><img src="imgs\image-20240708214359660.png" alt="image-20240708214359660"></p><p>LSTM（Long short-term Memory）则是一个更加复杂的RNN，其中有四个input和一个output，分别有输出门，输入门和遗忘门来控制信号是否输入。</p><p><img src="imgs\image-20240708215757390.png" alt="image-20240708215757390"></p><p>对于上面的流程，先对z信息输入，经过simoid function得到g(z)，然后与Input Gate输出的f(zi)相乘，得到g(z)f(zi)，中间Cell存储的初值为c，再经过Forget Gate的输出后，相乘得到cf(zf)，这样与前面的值相加，得到c`，接着再通过sigmoid function，输出结果与Output Gate的输出相乘，得到α。</p><p><img src="imgs\image-20240708220212126.png" alt="image-20240708220212126"></p><p>这是一个简短的举例，如果x2=1，那么将x1的值添加到Memory中，若x2=-1，则释放掉Memory，如果x3=1，那么将Memory中储存的值输出出来，可以看到3+4=7。</p><h2 id="具体计算过程"><a href="#具体计算过程" class="headerlink" title="具体计算过程"></a>具体计算过程</h2><p><img src="imgs\image-20240708220653433.png" alt="image-20240708220653433"></p><p>这个是LSTM一个Cell的最初形态，即x1,x2,x3和bias为1的输入，那么对于右下角的序列输入，可具体展示为以下过程：</p><p><img src="imgs\image-20240708222500230.png" alt="image-20240708222500230"></p><p>首先输入序列为3，1，0，计算过程如图所示，Input Gate的信号最后输出为1，这样的话与3相乘后结果依旧为3，实现了输入门的使能功能，接着，Forget Gate也输出1，代表没有遗忘，最后与原cell中的值相加后，得到3，最后的Output Gate为0，代表输出信号禁止选通，最后实际输出0，但是cell的值已经从0变化到了3，后面的步骤依次类推。</p><p><img src="imgs\image-20240708222947885.png" alt="image-20240708222947885"></p><p><img src="imgs\image-20240708223017862.png" alt="image-20240708223017862"></p><p><img src="imgs\image-20240708223035398.png" alt="image-20240708223035398"></p><p><img src="imgs\image-20240708223056973.png" alt="image-20240708223056973"></p><h2 id="总体展示"><a href="#总体展示" class="headerlink" title="总体展示"></a>总体展示</h2><p><img src="imgs\image-20240708221858291.png" alt="image-20240708221858291"></p><p><img src="imgs\image-20240708221935324.png" alt="image-20240708221935324"></p><p>这样的话就可以实现LSTM，将上一个的输出接到下一个的输入，同时考虑Xt信息中的门控信号和锁存信号，类似于时序逻辑电路。</p><p><img src="imgs\image-20240708222110442.png" alt="image-20240708222110442"></p><p><img src="imgs\image-20240708222221308.png" alt="image-20240708222221308"></p><p>以上是LSTM并联的完整体，即输入信息还额外包括了C与H信息，也叫peephole。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>自注意力机制(Self-Attention)</title>
      <link href="/2024/07/08/%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6-Self-Attention/"/>
      <url>/2024/07/08/%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6-Self-Attention/</url>
      
        <content type="html"><![CDATA[<h1 id="自注意力机制-Self-Attention"><a href="#自注意力机制-Self-Attention" class="headerlink" title="自注意力机制(Self-Attention)"></a>自注意力机制(Self-Attention)</h1><p>该笔记的资料与图片来源于台湾大学李宏毅教授的机器学习课程。</p><h2 id="原理讲解"><a href="#原理讲解" class="headerlink" title="原理讲解"></a>原理讲解</h2><p>自注意力机制应用于多个向量输入并输出信息。</p><p><img src="D:\BlogFile\source\_posts\自注意力机制-Self-Attention.assets\b252ecea4d2f109cef89a77069faf61d.png" alt="b252ecea4d2f109cef89a77069faf61d"></p><p>比如有语音辨识场景，文字聊天，Graph图等场景，一般来说对于词义表示有One-Hot Encoding（独热编码)或是Word Embedding，对于语音辨识则有frame滑动。</p><p>对于输出而言，则有以下几种场景：</p><ul><li>输入的input数量和输出的output数量相同，比如说POS tagging(词性标注)，Social Network等</li></ul><p><img src="D:\BlogFile\source\_posts\自注意力机制-Self-Attention.assets\bfda8ed45180b27278da3bac1be3e5ec.png" alt="bfda8ed45180b27278da3bac1be3e5ec"></p><ul><li>Model仅输出一个label，比如Sentiment Analysis(情感分析)</li></ul><p><img src="D:\BlogFile\source\_posts\自注意力机制-Self-Attention.assets\519dc35935218cfa1aab2922b9c1d566.png" alt="519dc35935218cfa1aab2922b9c1d566"></p><ul><li><p>机器自己决定输出的output数量，又叫Seq2Seq任务</p><p><img src="D:\BlogFile\source\_posts\自注意力机制-Self-Attention.assets\fc0e73b3b63ab324047ee54838ffa6b8.png" alt="fc0e73b3b63ab324047ee54838ffa6b8"></p></li></ul><p>对于以往的情况，若是直接运用Fully connected network，则会出现输入信息无顺序性的情况，这种情况就不能运用有顺序的信息，如语句、时序信息等，</p><p><img src="D:\BlogFile\source\_posts\自注意力机制-Self-Attention.assets\image-20240708203700532.png" alt="image-20240708203700532"></p><p>为了解决这个问题，在Fully connected network前面加入一个Self-attention机制，这样就可以考虑输入信号的Sequence连贯性，不是信息的局部性而是整体性。而且Self-attention模块并不仅仅只能加入到整个模型的最前方，在FC与FC之间也可以添加。</p><p><img src="D:\BlogFile\source\_posts\自注意力机制-Self-Attention.assets\image-20240708204027574.png" alt="image-20240708204027574"></p><p>如图，这是Self-attention内部的简单实现，这样就可以考虑整个Sequence来输出一个Sequence。</p><p><img src="D:\BlogFile\source\_posts\自注意力机制-Self-Attention.assets\image-20240708204208371.png" alt="image-20240708204208371"></p><p>若想得到输出的信息，如b1向量，需要找出a1和其他哪些信息是相关的，相关的程度α大小是多少。</p><p>计算相关度的方法，可以由以下模块来实现</p><p><img src="D:\BlogFile\source\_posts\自注意力机制-Self-Attention.assets\image-20240708204430516.png" alt="image-20240708204430516"></p><p>左面是最常用的方法，对于两个输入信息，分别进行Wq与Wk的矩阵相乘，得到q与k，再进行点乘，得到α，右边则将两个矩阵相乘的结果进行相加后放入到tanh函数中，来与W矩阵相乘得到α。</p><p><img src="D:\BlogFile\source\_posts\自注意力机制-Self-Attention.assets\image-20240708204818516.png" alt="image-20240708204818516"></p><p>dot-product中的query和key是通过将a1和Wq相乘，得到q1，Wk和a2相乘得到k2，再让q1和k2点乘得到α1,2（叫做attention score），最后再接一个softmax模块来标准化得到α`，但是softmax模块并不是必须的，也可以接Relu等。</p><p><img src="D:\BlogFile\source\_posts\自注意力机制-Self-Attention.assets\image-20240708205229517.png" alt="image-20240708205229517"></p><p>为了提取出相关性，再将a与Wv相乘，得到v信息，然后再将v与α相乘再相加，得到b信息。</p><p><img src="D:\BlogFile\source\_posts\自注意力机制-Self-Attention.assets\image-20240708205419310.png" alt="image-20240708205419310"></p><p>对于b1，b2，b3等信息，它们是并行输出的，故没有先后的顺序性。</p><p><img src="D:\BlogFile\source\_posts\自注意力机制-Self-Attention.assets\image-20240708205850709.png" alt="image-20240708205850709"></p><p>根据q，k，v的计算公式，将其整合为一个矩阵，得到Q，K，V矩阵，</p><p><img src="D:\BlogFile\source\_posts\自注意力机制-Self-Attention.assets\image-20240708210101186.png" alt="image-20240708210101186"></p><p>接着将K矩阵转置后与Q相乘，得到分数矩阵A，再进行softmax得到A`。</p><p><img src="D:\BlogFile\source\_posts\自注意力机制-Self-Attention.assets\image-20240708210238361.png" alt="image-20240708210238361"></p><p>再将V矩阵和A`矩阵相乘，最后得到O矩阵，这样就得到了b信息的输出了，这个过程中的W矩阵是模型训练得到的。</p><p><img src="D:\BlogFile\source\_posts\自注意力机制-Self-Attention.assets\image-20240708210557402.png" alt="image-20240708210557402"></p><p>对于Multi-head Self-attention的话，则需要更多的qkv来表示新的种类。</p><p>但是以上这种方式也缺少了位置信息，故采用Postional Encoding方法来解决这个问题，即向a信息上添加e信息。</p><p><img src="D:\BlogFile\source\_posts\自注意力机制-Self-Attention.assets\image-20240708211233152.png" alt="image-20240708211233152"></p><p>对于语音辨识时，可能有时候不需要考虑整个声音信号，只需要考虑一部分，这样可以减少计算量，叫做Truncated Self-attention，一般来说Self-attention广泛应用在Transformer和Bert上。</p><p>Self-attention和CNN之间也有一些区别，CNN的receptive field是部分范围的，而Self-attention是整体的，可以说CNN是简化版的Self-attention，或者说Self-attention是复杂版的CNN。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CNN卷积神经网络</title>
      <link href="/2024/07/05/CNN%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
      <url>/2024/07/05/CNN%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
      
        <content type="html"><![CDATA[<h1 id="CNN神经网络"><a href="#CNN神经网络" class="headerlink" title="CNN神经网络"></a>CNN神经网络</h1><h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><h3 id="相关包的导入"><a href="#相关包的导入" class="headerlink" title="相关包的导入"></a>相关包的导入</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> ConcatDataset, DataLoader, Subset, Dataset</span><br><span class="line"><span class="keyword">from</span> torchvision.datasets <span class="keyword">import</span> DatasetFolder, VisionDataset</span><br><span class="line"><span class="keyword">from</span> tqdm.auto <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line">myseed = <span class="number">6666</span></span><br></pre></td></tr></table></figure><p>导入经典的数据分析包。torch包的整体导入，并且导入nn模块与优化器，导入data类，并设置种子。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">test_tfm = transforms.Compose([</span><br><span class="line">    transforms.Resize((<span class="number">128</span>, <span class="number">128</span>)),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">])</span><br></pre></td></tr></table></figure><p>构建<code>test_tfm()</code>，其是一个transform的组合结构，包括将图片大小强制转换为128*128，同时将图像的通道顺序从 HWC（高度、宽度、通道）转换为 CHW（通道、高度、宽度），变为tensor张量类型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">train_tfm = transforms.Compose([</span><br><span class="line">    transforms.Resize((<span class="number">128</span>, <span class="number">128</span>)),</span><br><span class="line">     transforms.RandomChoice(transforms=[</span><br><span class="line">        transforms.TrivialAugmentWide(),</span><br><span class="line">        transforms.Lambda(<span class="keyword">lambda</span> x: x),</span><br><span class="line">    ],</span><br><span class="line">                            p=[<span class="number">0.9</span>, <span class="number">0.1</span>]),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">])</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><code>transforms.TrivialAugmentWide()</code>：使用 TrivialAugmentWide 方法对图像进行数据增强。这种方法会随机应用各种图像增强操作，如旋转、翻转、颜色调整等。<code>transforms.Lambda(lambda x: x)</code>：返回原始图像，即不做任何变换。概率分别为0.9和0.1。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">FoodDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,path,tfm=test_tfm,files = <span class="literal">None</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(FoodDataset).__init__()</span><br><span class="line">        self.path = path</span><br><span class="line">        self.files = <span class="built_in">sorted</span>([os.path.join(path,x) <span class="keyword">for</span> x <span class="keyword">in</span> os.listdir(path) <span class="keyword">if</span> x.endswith(<span class="string">&quot;.jpg&quot;</span>)])</span><br><span class="line">        <span class="keyword">if</span> files != <span class="literal">None</span>:</span><br><span class="line">            self.files = files</span><br><span class="line">            </span><br><span class="line">        self.transform = tfm</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.files)</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self,idx</span>):</span><br><span class="line">        fname = self.files[idx]</span><br><span class="line">        im = Image.<span class="built_in">open</span>(fname)</span><br><span class="line">        im = self.transform(im)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            label = <span class="built_in">int</span>(fname.split(<span class="string">&quot;/&quot;</span>)[-<span class="number">1</span>].split(<span class="string">&quot;_&quot;</span>)[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            label = -<span class="number">1</span> </span><br><span class="line">            </span><br><span class="line">        <span class="keyword">return</span> im,label</span><br></pre></td></tr></table></figure><p>定义<code>FoodDataset</code>类，<code>__init__()</code>析构函数用来初始化数据，<code>__len__()</code>用来获得数据集的整个大小，<code>__getitem__()</code>用来获得具体index下的数据文件，并返回transform后的图像。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Classifier</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Classifier, self).__init__()</span><br><span class="line">        <span class="comment"># torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)</span></span><br><span class="line">        <span class="comment"># torch.nn.MaxPool2d(kernel_size, stride, padding)</span></span><br><span class="line">        <span class="comment"># input 維度 [3, 128, 128]</span></span><br><span class="line">        self.cnn = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">3</span>, <span class="number">64</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>),  <span class="comment"># [64, 128, 128]</span></span><br><span class="line">            nn.BatchNorm2d(<span class="number">64</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>),      <span class="comment"># [64, 64, 64]</span></span><br><span class="line"></span><br><span class="line">            nn.Conv2d(<span class="number">64</span>, <span class="number">128</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>), <span class="comment"># [128, 64, 64]</span></span><br><span class="line">            nn.BatchNorm2d(<span class="number">128</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>),      <span class="comment"># [128, 32, 32]</span></span><br><span class="line"></span><br><span class="line">            nn.Conv2d(<span class="number">128</span>, <span class="number">256</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>), <span class="comment"># [256, 32, 32]</span></span><br><span class="line">            nn.BatchNorm2d(<span class="number">256</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>),      <span class="comment"># [256, 16, 16]</span></span><br><span class="line"></span><br><span class="line">            nn.Conv2d(<span class="number">256</span>, <span class="number">512</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>), <span class="comment"># [512, 16, 16]</span></span><br><span class="line">            nn.BatchNorm2d(<span class="number">512</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>),       <span class="comment"># [512, 8, 8]</span></span><br><span class="line">            </span><br><span class="line">            nn.Conv2d(<span class="number">512</span>, <span class="number">512</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>), <span class="comment"># [512, 8, 8]</span></span><br><span class="line">            nn.BatchNorm2d(<span class="number">512</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>),       <span class="comment"># [512, 4, 4]</span></span><br><span class="line">        )</span><br><span class="line">        self.fc = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">512</span>*<span class="number">4</span>*<span class="number">4</span>, <span class="number">1024</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">1024</span>, <span class="number">512</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">11</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        out = self.cnn(x)</span><br><span class="line">        out = out.view(out.size()[<span class="number">0</span>], -<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> self.fc(out)</span><br></pre></td></tr></table></figure><p>定义CNN的model</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">device = <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span></span><br><span class="line">model = Classifier().to(device)</span><br><span class="line">batch_size = <span class="number">64</span></span><br><span class="line">n_epochs = <span class="number">24</span> </span><br><span class="line">patience = <span class="number">300</span></span><br><span class="line">loss_fn = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=<span class="number">0.0003</span>, weight_decay=<span class="number">1e-5</span>)</span><br></pre></td></tr></table></figure><p>如果电脑有cuda，那么用cuda来训练，否则用cpu，同时定义model对象，batch_size，n_epoches与patience，定义Adam优化器来优化，其中学习率为0.0003，传播率为0.00001，patience为耐心轮数，loss_fn为损失函数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train_set = FoodDataset(<span class="string">&quot;.../train&quot;</span>, tfm=train_tfm)</span><br><span class="line">train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=<span class="literal">True</span>, num_workers=<span class="number">0</span>, pin_memory=<span class="literal">True</span>)</span><br><span class="line">valid_set = FoodDataset(<span class="string">&quot;.../valid&quot;</span>, tfm=test_tfm)</span><br><span class="line">valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=<span class="literal">True</span>, num_workers=<span class="number">0</span>, pin_memory=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>定义train_set和loader，valid_set和loader，分别为训练集和验证集。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line">stale = <span class="number">0</span></span><br><span class="line">best_acc = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(n_epochs):</span><br><span class="line"></span><br><span class="line">    model.train()</span><br><span class="line"></span><br><span class="line">    train_loss = []</span><br><span class="line">    train_accs = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> batch <span class="keyword">in</span> tqdm(train_loader):</span><br><span class="line"></span><br><span class="line">        imgs, labels = batch</span><br><span class="line"></span><br><span class="line">        logits = model(imgs.to(device))</span><br><span class="line"></span><br><span class="line">        loss = criterion(logits, labels.to(device))</span><br><span class="line"></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line"></span><br><span class="line">        grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=<span class="number">10</span>)</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        acc = (logits.argmax(dim=-<span class="number">1</span>) == labels.to(device)).<span class="built_in">float</span>().mean()</span><br><span class="line"></span><br><span class="line">        train_loss.append(loss.item())</span><br><span class="line">        train_accs.append(acc)</span><br><span class="line">        </span><br><span class="line">    train_loss = <span class="built_in">sum</span>(train_loss) / <span class="built_in">len</span>(train_loss)</span><br><span class="line">    train_acc = <span class="built_in">sum</span>(train_accs) / <span class="built_in">len</span>(train_accs)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;[ Train | <span class="subst">&#123;epoch + <span class="number">1</span>:03d&#125;</span>/<span class="subst">&#123;n_epochs:03d&#125;</span> ] loss = <span class="subst">&#123;train_loss:<span class="number">.5</span>f&#125;</span>, acc = <span class="subst">&#123;train_acc:<span class="number">.5</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    valid_loss = []</span><br><span class="line">    valid_accs = []</span><br><span class="line">    <span class="keyword">for</span> imgs, labels <span class="keyword">in</span> tqdm(valid_loader):</span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            logits = model(imgs.to(device))</span><br><span class="line">        loss = loss_fn(logits, labels.to(device))</span><br><span class="line">        acc = (logits.argmax(dim=-<span class="number">1</span>) == labels.to(device)).<span class="built_in">float</span>().mean()</span><br><span class="line"></span><br><span class="line">        valid_loss.append(loss.item())</span><br><span class="line">        valid_accs.append(acc)</span><br><span class="line"></span><br><span class="line">    valid_loss = <span class="built_in">sum</span>(valid_loss) / <span class="built_in">len</span>(valid_loss)</span><br><span class="line">    valid_acc = <span class="built_in">sum</span>(valid_accs) / <span class="built_in">len</span>(valid_accs)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;[ Valid | <span class="subst">&#123;epoch + <span class="number">1</span>:03d&#125;</span>/<span class="subst">&#123;n_epochs:03d&#125;</span> ] loss = <span class="subst">&#123;valid_loss:<span class="number">.5</span>f&#125;</span>, acc = <span class="subst">&#123;valid_acc:<span class="number">.5</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> valid_acc &gt; best_acc:</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">f&quot;./<span class="subst">&#123;_exp_name&#125;</span>_log.txt&quot;</span>,<span class="string">&quot;a&quot;</span>):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;[ Valid | <span class="subst">&#123;epoch + <span class="number">1</span>:03d&#125;</span>/<span class="subst">&#123;n_epochs:03d&#125;</span> ] loss = <span class="subst">&#123;valid_loss:<span class="number">.5</span>f&#125;</span>, acc = <span class="subst">&#123;valid_acc:<span class="number">.5</span>f&#125;</span> -&gt; best&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">f&quot;./<span class="subst">&#123;_exp_name&#125;</span>_log.txt&quot;</span>,<span class="string">&quot;a&quot;</span>):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;[ Valid | <span class="subst">&#123;epoch + <span class="number">1</span>:03d&#125;</span>/<span class="subst">&#123;n_epochs:03d&#125;</span> ] loss = <span class="subst">&#123;valid_loss:<span class="number">.5</span>f&#125;</span>, acc = <span class="subst">&#123;valid_acc:<span class="number">.5</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> valid_acc &gt; best_acc:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Best model found at epoch <span class="subst">&#123;epoch&#125;</span>, saving model&quot;</span>)</span><br><span class="line">        torch.save(model.state_dict(), <span class="string">f&quot;<span class="subst">&#123;_exp_name&#125;</span>_best.ckpt&quot;</span>)</span><br><span class="line">        best_acc = valid_acc</span><br><span class="line">        stale = <span class="number">0</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        stale += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> stale &gt; patience:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;No improvment <span class="subst">&#123;patience&#125;</span> consecutive epochs, early stopping&quot;</span>)</span><br><span class="line">            <span class="keyword">break</span></span><br></pre></td></tr></table></figure><p>开始训练,<code>stale</code>：记录连续未改善的epoch次数，用于早停机制。<code>best_acc</code>用于记录最佳验证集准确率,使用 <code>nn.utils.clip_grad_norm_</code> 可以有效防止梯度爆炸问题，确保训练过程更加稳定和收敛。这个函数通过限制梯度的最大范数，使得每次参数更新不会因为过大的梯度而发生剧烈变化。如果停滞轮数大于耐心轮数，那么终止训练，否则保存模型。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>动态数组</title>
      <link href="/2024/06/28/%E5%8A%A8%E6%80%81%E6%95%B0%E7%BB%84/"/>
      <url>/2024/06/28/%E5%8A%A8%E6%80%81%E6%95%B0%E7%BB%84/</url>
      
        <content type="html"><![CDATA[<h1 id="动态数组"><a href="#动态数组" class="headerlink" title="动态数组"></a>动态数组</h1><p>数组是一组元素组成的数据结构，每个元素至少有一个index或key来标识。</p><p>数组的元素是连续存储，所以地址可以通过index索引来计算出来。</p><p>通过数组的起始地址<em>BaseAddress</em>，我们可以通过公式<em>BaseAddress</em> + i*size来计算出索引i元素的地址，其中i位索引，size为每个元素所占字节大小。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span>[] array = &#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>&#125;;</span><br></pre></td></tr></table></figure><h1 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h1><h2 id="空间占用"><a href="#空间占用" class="headerlink" title="空间占用"></a>空间占用</h2><p>Java中数组结构有8字节的markword，4字节的class指针，4字节的数组大小（Java中所有对象大小都是8字节的整数倍，不足的话要对齐字节补足）</p><p>例如</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span>[] array = &#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>&#125;;</span><br></pre></td></tr></table></figure><p>那么其大小为40字节，8 + 4 + 4 + 5*4 + 4(alignment)，其中的alignment是用补充整体为8的倍数的。</p><h2 id="随机访问"><a href="#随机访问" class="headerlink" title="随机访问"></a>随机访问</h2><p>根据索引查找元素，时间复杂度为O(1)。</p><h1 id="基础代码实现"><a href="#基础代码实现" class="headerlink" title="基础代码实现"></a>基础代码实现</h1><p>如果想实现一个最基本的动态数组，那么其中要有的属性有：这个动态数组的容量大小与实际逻辑大小，而静态数组往往是已经设定好，且不可以扩容的，为此我们若想用静态数组为根本来实现动态数组，我们需要判断如果逻辑大小大于容量大小，则需要创建一个新的静态数组，且这个新的静态数组的容量大小要大于所需数组的逻辑大小，其中我们用到的一个方法叫做<em>arraycopy( )</em>，使用用法为：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">System.arraycopy(ori_array, ori_index, new_array, new_index, size);</span><br></pre></td></tr></table></figure><p>其中<code>ori_array</code>为源数组，<code>ori_index</code>为复制的起始index，<code>new_array</code>为目标数组，<code>new_index</code>为要复制到的目标index，<code>size</code>为要复制的大小。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">DynamicArray</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> <span class="variable">size</span> <span class="operator">=</span> <span class="number">0</span>; <span class="comment">// 逻辑大小</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> <span class="variable">capacity</span> <span class="operator">=</span> <span class="number">8</span>; <span class="comment">// 容量</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span>[] array = <span class="keyword">new</span> <span class="title class_">int</span>[capacity];</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">addLast</span><span class="params">(<span class="type">int</span> element)</span>&#123;</span><br><span class="line">        add(size,element);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">add</span><span class="params">(<span class="type">int</span> index,<span class="type">int</span> element)</span>&#123; <span class="comment">// index为要插入的位置</span></span><br><span class="line">        <span class="keyword">if</span>(index &gt;= <span class="number">0</span> &amp;&amp; index &lt; size) &#123;</span><br><span class="line">            System.arraycopy(array, index, array, index + <span class="number">1</span>, size - index); </span><br><span class="line">        &#125; <span class="comment">// 这里的add方法包括了addLast方法</span></span><br><span class="line">        array[index] = element;</span><br><span class="line">        size++;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>arraycopy方法从index开始拷贝，目标数组还是array，拷贝到目标数组的起始位置为index + 1，拷贝的元素为index后面的元素均右移一位，故size - index个数，这样实现了要插入的数组的初始化，即从原来的(1,2,3,4,5,6)变为了(1,2,3,3,4,5,6)，这里假设index为2，然后在index=2处插入你想要的元素。</p><h2 id="功能拓展"><a href="#功能拓展" class="headerlink" title="功能拓展"></a>功能拓展</h2><p>为了想看明白这个数组的实现情况，我们想知道内部究竟发生了什么，但又不能直接将私有属性capacity与size展示出来，为此我们提供两种方法来对外展示，一种是遍历循环，另一种是索引查找。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="type">int</span> <span class="title function_">get</span><span class="params">(<span class="type">int</span> index)</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> array[index];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">forEach</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; size; i++) &#123;</span><br><span class="line">            System.out.println(array[i]);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>get方法用来实现特定index的元素查询，而forEach方法实现所有元素的查看</p>]]></content>
      
      
      
        <tags>
            
            <tag> 数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习的一般框架（鸟与飞机举例）</title>
      <link href="/2024/06/04/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%B8%80%E8%88%AC%E6%A1%86%E6%9E%B6%EF%BC%88%E9%B8%9F%E4%B8%8E%E9%A3%9E%E6%9C%BA%E4%B8%BE%E4%BE%8B%EF%BC%89/"/>
      <url>/2024/06/04/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%B8%80%E8%88%AC%E6%A1%86%E6%9E%B6%EF%BC%88%E9%B8%9F%E4%B8%8E%E9%A3%9E%E6%9C%BA%E4%B8%BE%E4%BE%8B%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h1 id="深度学习"><a href="#深度学习" class="headerlink" title="深度学习"></a>深度学习</h1><h2 id="相关包的导入与种子设置"><a href="#相关包的导入与种子设置" class="headerlink" title="相关包的导入与种子设置"></a>相关包的导入与种子设置</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> collections</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line">torch.set_printoptions(edgeitems=<span class="number">2</span>)</span><br><span class="line">torch.manual_seed(<span class="number">123</span>)</span><br></pre></td></tr></table></figure><h2 id="类名规定"><a href="#类名规定" class="headerlink" title="类名规定"></a>类名规定</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">class_names = [<span class="string">&#x27;airplane&#x27;</span>,<span class="string">&#x27;automobile&#x27;</span>,<span class="string">&#x27;bird&#x27;</span>,<span class="string">&#x27;cat&#x27;</span>,<span class="string">&#x27;deer&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;dog&#x27;</span>,<span class="string">&#x27;frog&#x27;</span>,<span class="string">&#x27;horse&#x27;</span>,<span class="string">&#x27;ship&#x27;</span>,<span class="string">&#x27;truck&#x27;</span>]</span><br></pre></td></tr></table></figure><h2 id="构建训练集与测试集"><a href="#构建训练集与测试集" class="headerlink" title="构建训练集与测试集"></a>构建训练集与测试集</h2><p>这里为了简化，将tranform提供的转换张量与标准化直接放在数据集cifar10中，其为训练集，若地址中没有该数据则Pytorch自动下载。划分两种集合类别的参数为train是否为False或True。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, transforms</span><br><span class="line">data_path = <span class="string">&#x27;../data/&#x27;</span></span><br><span class="line">cifar10 = datasets.CIFAR10(</span><br><span class="line">    data_path, train=<span class="literal">True</span>, download=<span class="literal">True</span>,</span><br><span class="line">    transform=transforms.Compose([</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize((<span class="number">0.4915</span>, <span class="number">0.4823</span>, <span class="number">0.4468</span>),</span><br><span class="line">                             (<span class="number">0.2470</span>, <span class="number">0.2435</span>, <span class="number">0.2616</span>))</span><br><span class="line">    ]))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cifar10_val = datasets.CIFAR10(</span><br><span class="line">    data_path, train=<span class="literal">False</span>, download=<span class="literal">True</span>,</span><br><span class="line">    transform=transforms.Compose([</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize((<span class="number">0.4915</span>, <span class="number">0.4823</span>, <span class="number">0.4468</span>),</span><br><span class="line">                             (<span class="number">0.2470</span>, <span class="number">0.2435</span>, <span class="number">0.2616</span>))</span><br><span class="line">    ]))</span><br></pre></td></tr></table></figure><p>因为这里仅仅是鸟与飞机的划分，而cifar10是一个包含很多种类的数据集，故进行切割</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">label_map = &#123;<span class="number">0</span>: <span class="number">0</span>, <span class="number">2</span>: <span class="number">1</span>&#125;</span><br><span class="line">class_names = [<span class="string">&#x27;airplane&#x27;</span>, <span class="string">&#x27;bird&#x27;</span>]</span><br><span class="line">cifar2 = [(img, label_map[label])</span><br><span class="line">          <span class="keyword">for</span> img, label <span class="keyword">in</span> cifar10</span><br><span class="line">          <span class="keyword">if</span> label <span class="keyword">in</span> [<span class="number">0</span>, <span class="number">2</span>]]</span><br><span class="line">cifar2_val = [(img, label_map[label])</span><br><span class="line">              <span class="keyword">for</span> img, label <span class="keyword">in</span> cifar10_val</span><br><span class="line">              <span class="keyword">if</span> label <span class="keyword">in</span> [<span class="number">0</span>, <span class="number">2</span>]]</span><br></pre></td></tr></table></figure><p>以下是自定义一个自己的模块</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Net</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">16</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">16</span>, <span class="number">8</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">8</span> * <span class="number">8</span> * <span class="number">8</span>, <span class="number">32</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">32</span>, <span class="number">2</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        out = F.max_pool2d(torch.tanh(self.conv1(x)), <span class="number">2</span>)</span><br><span class="line">        out = F.max_pool2d(torch.tanh(self.conv2(out)), <span class="number">2</span>)</span><br><span class="line">        out = out.view(-<span class="number">1</span>, <span class="number">8</span> * <span class="number">8</span> * <span class="number">8</span>)</span><br><span class="line">        out = torch.tanh(self.fc1(out))</span><br><span class="line">        out = self.fc2(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure><p>以下代码为核心循环步骤</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">model = Net()</span><br><span class="line"><span class="keyword">import</span> datetime  </span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">training_loop</span>(<span class="params">n_epochs, optimizer, model, loss_fn, train_loader</span>):</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n_epochs + <span class="number">1</span>): </span><br><span class="line">        loss_train = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> imgs, labels <span class="keyword">in</span> train_loader:  </span><br><span class="line">            </span><br><span class="line">            outputs = model(imgs) </span><br><span class="line">            loss = loss_fn(outputs, labels)  </span><br><span class="line">            optimizer.zero_grad()  </span><br><span class="line">            loss.backward()  </span><br><span class="line">            optimizer.step()  </span><br><span class="line">            loss_train += loss.item()  </span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> epoch == <span class="number">1</span> <span class="keyword">or</span> epoch % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;&#123;&#125; Epoch &#123;&#125;, Training loss &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">                datetime.datetime.now(), epoch,</span><br><span class="line">                loss_train / <span class="built_in">len</span>(train_loader))) </span><br><span class="line">            </span><br><span class="line">train_loader = torch.utils.data.DataLoader(cifar2, batch_size=<span class="number">64</span>,</span><br><span class="line">                                           shuffle=<span class="literal">True</span>) </span><br><span class="line"></span><br><span class="line">model = Net()  </span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="number">1e-2</span>)  </span><br><span class="line">loss_fn = nn.CrossEntropyLoss()  </span><br><span class="line"></span><br><span class="line">training_loop(  </span><br><span class="line">    n_epochs = <span class="number">100</span>,</span><br><span class="line">    optimizer = optimizer,</span><br><span class="line">    model = model,</span><br><span class="line">    loss_fn = loss_fn,</span><br><span class="line">    train_loader = train_loader,</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>验证函数代码为</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">train_loader = torch.utils.data.DataLoader(cifar2, batch_size=<span class="number">64</span>,</span><br><span class="line">                                           shuffle=<span class="literal">False</span>)</span><br><span class="line">val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=<span class="number">64</span>,</span><br><span class="line">                                         shuffle=<span class="literal">False</span>)</span><br><span class="line">all_acc_dict = collections.OrderedDict()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">validate</span>(<span class="params">model, train_loader, val_loader</span>):</span><br><span class="line">    accdict = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> name, loader <span class="keyword">in</span> [(<span class="string">&quot;train&quot;</span>, train_loader), (<span class="string">&quot;val&quot;</span>, val_loader)]:</span><br><span class="line">        correct = <span class="number">0</span></span><br><span class="line">        total = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            <span class="keyword">for</span> imgs, labels <span class="keyword">in</span> loader:</span><br><span class="line">                imgs = imgs.to(device=device)</span><br><span class="line">                labels = labels.to(device=device)</span><br><span class="line">                outputs = model(imgs)</span><br><span class="line">                _, predicted = torch.<span class="built_in">max</span>(outputs, dim=<span class="number">1</span>) <span class="comment"># &lt;1&gt;</span></span><br><span class="line">                total += labels.shape[<span class="number">0</span>]</span><br><span class="line">                correct += <span class="built_in">int</span>((predicted == labels).<span class="built_in">sum</span>())</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Accuracy &#123;&#125;: &#123;:.2f&#125;&quot;</span>.<span class="built_in">format</span>(name , correct / total))</span><br><span class="line">        accdict[name] = correct / total</span><br><span class="line">    <span class="keyword">return</span> accdict</span><br><span class="line"></span><br><span class="line">all_acc_dict[<span class="string">&quot;baseline&quot;</span>] = validate(model, train_loader, val_loader)</span><br></pre></td></tr></table></figure><p>这是另一个自定义模块</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">NetResDeep</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, n_chans1=<span class="number">32</span>, n_blocks=<span class="number">10</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.n_chans1 = n_chans1</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>, n_chans1, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.resblocks = nn.Sequential(</span><br><span class="line">            *(n_blocks * [ResBlock(n_chans=n_chans1)]))</span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">8</span> * <span class="number">8</span> * n_chans1, <span class="number">32</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">32</span>, <span class="number">2</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        out = F.max_pool2d(torch.relu(self.conv1(x)), <span class="number">2</span>)</span><br><span class="line">        out = self.resblocks(out)</span><br><span class="line">        out = F.max_pool2d(out, <span class="number">2</span>)</span><br><span class="line">        out = out.view(-<span class="number">1</span>, <span class="number">8</span> * <span class="number">8</span> * self.n_chans1)</span><br><span class="line">        out = torch.relu(self.fc1(out))</span><br><span class="line">        out = self.fc2(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">model = NetResDeep(n_chans1=<span class="number">32</span>, n_blocks=<span class="number">100</span>).to(device=device)</span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="number">3e-3</span>)</span><br><span class="line">loss_fn = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line">training_loop(</span><br><span class="line">    n_epochs = <span class="number">100</span>,</span><br><span class="line">    optimizer = optimizer,</span><br><span class="line">    model = model,</span><br><span class="line">    loss_fn = loss_fn,</span><br><span class="line">    train_loader = train_loader,</span><br><span class="line">)</span><br><span class="line">all_acc_dict[<span class="string">&quot;res deep&quot;</span>] = validate(model, train_loader, val_loader)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于Python的推箱子小游戏实现</title>
      <link href="/2024/05/30/%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E6%8E%A8%E7%AE%B1%E5%AD%90%E5%B0%8F%E6%B8%B8%E6%88%8F%E5%AE%9E%E7%8E%B0/"/>
      <url>/2024/05/30/%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E6%8E%A8%E7%AE%B1%E5%AD%90%E5%B0%8F%E6%B8%B8%E6%88%8F%E5%AE%9E%E7%8E%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="推箱子小游戏项目的实现"><a href="#推箱子小游戏项目的实现" class="headerlink" title="推箱子小游戏项目的实现"></a>推箱子小游戏项目的实现</h1><p>项目来源：四川大学2023-2024年Python程序设计基础的期末大作业，素材均为学校提供。</p><h3 id="观前提醒：请勿直接用于期末作业的撰写！！！文章内容均为个人原创，均为实践报告的原内容，可以借鉴思路，但请勿照搬源代码与报告阐述！"><a href="#观前提醒：请勿直接用于期末作业的撰写！！！文章内容均为个人原创，均为实践报告的原内容，可以借鉴思路，但请勿照搬源代码与报告阐述！" class="headerlink" title="观前提醒：请勿直接用于期末作业的撰写！！！文章内容均为个人原创，均为实践报告的原内容，可以借鉴思路，但请勿照搬源代码与报告阐述！"></a>观前提醒：请勿直接用于期末作业的撰写！！！文章内容均为个人原创，均为实践报告的原内容，可以借鉴思路，但请勿照搬源代码与报告阐述！</h3><h4 id="代码："><a href="#代码：" class="headerlink" title="代码："></a>代码：</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> pygame</span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">pygame.init()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 常量定义</span></span><br><span class="line">SUM = <span class="number">0</span></span><br><span class="line">TILE_SIZE = <span class="number">33</span></span><br><span class="line">SCREEN_WIDTH = <span class="number">462</span>  <span class="comment"># 14个横格</span></span><br><span class="line">WIDTH_NUM = SCREEN_WIDTH // TILE_SIZE</span><br><span class="line">SCREEN_HEIGHT = <span class="number">330</span>  <span class="comment"># 10个竖格</span></span><br><span class="line">HEIGHT_NUM = SCREEN_HEIGHT // TILE_SIZE</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取对象</span></span><br><span class="line">player_image = pygame.transform.scale(pygame.image.load(<span class="string">r&#x27;C:\Users\赵洪锐\Downloads\bmp\bmp\Bmp14.gif&#x27;</span>),</span><br><span class="line">                                      (TILE_SIZE, TILE_SIZE))</span><br><span class="line">box_image = pygame.transform.scale(pygame.image.load(<span class="string">r&#x27;C:\Users\赵洪锐\Downloads\bmp\bmp\Bmp3.gif&#x27;</span>),</span><br><span class="line">                                   (TILE_SIZE, TILE_SIZE))</span><br><span class="line">target_image = pygame.transform.scale(pygame.image.load(<span class="string">r&#x27;C:\Users\赵洪锐\Downloads\bmp\bmp\Bmp5.gif&#x27;</span>),</span><br><span class="line">                                      (TILE_SIZE, TILE_SIZE))</span><br><span class="line">wall_image = pygame.transform.scale(pygame.image.load(<span class="string">r&#x27;C:\Users\赵洪锐\Downloads\bmp\bmp\Bmp1.gif&#x27;</span>),</span><br><span class="line">                                    (TILE_SIZE, TILE_SIZE))</span><br><span class="line">floor_image = pygame.transform.scale(pygame.image.load(<span class="string">r&#x27;C:\Users\赵洪锐\Downloads\bmp\bmp\Bmp2.gif&#x27;</span>),</span><br><span class="line">                                     (TILE_SIZE, TILE_SIZE))</span><br><span class="line">background_image = pygame.transform.scale(pygame.image.load(<span class="string">r&#x27;C:\Users\赵洪锐\Downloads\bmp\bmp\Bmp0.gif&#x27;</span>),</span><br><span class="line">                                          (TILE_SIZE, TILE_SIZE))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 窗口展示</span></span><br><span class="line">screen = pygame.display.set_mode((SCREEN_WIDTH, SCREEN_HEIGHT))</span><br><span class="line">pygame.display.set_caption(<span class="string">&#x27;推箱子の小游戏&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 关卡变量  0表示地板 1表示墙 2表示目标 3表示箱子 4表示玩家 5表示背景</span></span><br><span class="line">levels = [</span><br><span class="line">    [[<span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>]],</span><br><span class="line"></span><br><span class="line">    [[<span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>]],</span><br><span class="line"></span><br><span class="line">    [[<span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>,<span class="number">5</span>]],</span><br><span class="line"></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 当前关卡</span></span><br><span class="line">current_level = <span class="number">0</span></span><br><span class="line"><span class="built_in">map</span> = copy.deepcopy(levels[current_level])</span><br></pre></td></tr></table></figure><p>引入Python的标准库sys、copy和time，以及第三方库pygame。这些库提供了如系统退出、对象深拷贝和时间记录的功能，并且初始化Pygame库，准备使用其功能。</p><p>1.1定义常量：</p><p>TILE_SIZE表示每个图块的尺寸。</p><p>SCREEN_WIDTH和SCREEN_HEIGHT表示窗口的宽和高。</p><p>WIDTH_NUM和HEIGHT_NUM通过屏幕尺寸除以图块尺寸计算出屏幕可以容纳的横向和纵向图块数。</p><p>1.2 导入图片：</p><p>使用Pygame的pygame.image.load函数加载游戏所需的图像资源。</p><p>使用pygame.transform.scale函数将这些图像缩放到合适的大小（即图块大小TILE_SIZE）。</p><p>1.3 备注说明：</p><p>由于Bmp图片中大多数格式的像素为33x33，而少部分图片的像素尺寸不统一，比如有34x37，为统一格式，便在导入图片的时候进行图片裁剪，使所有导入的图片均为33x33，这样在设定屏幕长度与宽度时可以更方便的计算图块，避免出现白边的情况发生。并且文件夹中存在重复的图片，故从中任意选择一个。</p><p>pygame.display.set_mode创建一个窗口，大小SCREEN_WIDTH与SCREEN_HEIGHT。</p><p>pygame.display.set_caption是设置窗口的标题，命名为”推箱子の小游戏”。</p><p>定义多个关卡，每个关卡使用一个二维列表表示，其中数字表示不同类型的地块。使用copy.deepcopy复制选定的关卡数据，防止后续修改影响原始数据。这里设置初始的三关，后续可在其中进行拓展添加。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 物体替换</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">movePlayer</span>(<span class="params">dx, dy</span>):</span><br><span class="line">    <span class="keyword">global</span> player_pos</span><br><span class="line">    new_x = player_pos[<span class="number">1</span>] + dx</span><br><span class="line">    new_y = player_pos[<span class="number">0</span>] + dy</span><br><span class="line">    <span class="keyword">if</span> new_x &lt; <span class="number">0</span> <span class="keyword">or</span> new_x &gt;= WIDTH_NUM <span class="keyword">or</span> new_y &lt; <span class="number">0</span> <span class="keyword">or</span> new_y &gt;= HEIGHT_NUM:</span><br><span class="line">        <span class="keyword">return</span>  <span class="comment"># 边界检查</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">map</span>[new_y][new_x] == <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span>  <span class="comment"># 遇到墙，停止移动</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">map</span>[new_y][new_x] == <span class="number">3</span>:  <span class="comment"># 遇到箱子</span></span><br><span class="line">        box_new_x = new_x + dx</span><br><span class="line">        box_new_y = new_y + dy</span><br><span class="line">        <span class="keyword">if</span> box_new_x &lt; <span class="number">0</span> <span class="keyword">or</span> box_new_x &gt;= WIDTH_NUM <span class="keyword">or</span> box_new_y &lt; <span class="number">0</span> <span class="keyword">or</span> box_new_y &gt;= HEIGHT_NUM:</span><br><span class="line">            <span class="keyword">return</span>  <span class="comment"># 边界检查</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">map</span>[box_new_y][box_new_x] <span class="keyword">in</span> [<span class="number">0</span>, <span class="number">2</span>]:  <span class="comment"># 箱子前面是地板或目标</span></span><br><span class="line">            <span class="built_in">map</span>[box_new_y][box_new_x] = <span class="number">3</span></span><br><span class="line">            <span class="built_in">map</span>[new_y][new_x] = <span class="number">0</span> <span class="keyword">if</span> levels[current_level][new_y][new_x] != <span class="number">2</span> <span class="keyword">else</span> <span class="number">2</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span>  <span class="comment"># 箱子前面是墙或另一个箱子，停止移动</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">map</span>[player_pos[<span class="number">0</span>]][player_pos[<span class="number">1</span>]] = <span class="number">0</span> <span class="keyword">if</span> levels[current_level][player_pos[<span class="number">0</span>]][player_pos[<span class="number">1</span>]] != <span class="number">2</span> <span class="keyword">else</span> <span class="number">2</span>  <span class="comment"># 恢复地板或目标</span></span><br><span class="line">    player_pos = [new_y, new_x]</span><br><span class="line">    <span class="built_in">map</span>[player_pos[<span class="number">0</span>]][player_pos[<span class="number">1</span>]] = <span class="number">4</span>  <span class="comment"># 更新玩家新位置</span></span><br></pre></td></tr></table></figure><p>movePlayer（）是实现玩家的移动逻辑的函数，其职责是实现玩家角色的移动逻辑，包括边界检查、碰撞检测和更新地图状态。函数接受两个参数 dx 和 dy，分别表示玩家在x轴和y轴上的移动距离。</p><p>1.1参数定义和初始位置计算：</p><p>函数接受两个参数 dx 和 dy，分别表示玩家在x轴和y轴上的移动距离。通过这两个参数，函数计算出玩家的新位置 new_x 和 new_y。</p><p>1.2 边界检查与碰撞检测（墙壁）：</p><p>首先，函数检查玩家的新位置是否超出地图边界。如果新位置超出边界，函数立即返回，停止移动。接着，函数检查玩家的新位置是否遇到墙壁（值为1）。如果新位置是墙壁，函数 返回，停止移动。</p><p>1.3 碰撞检测（箱子）与地图更新：</p><p>如果玩家的新位置是箱子（值为3），函数需要进一步检查箱子的前方位置是否为空地或目标点（值为0或2）。如果箱子前方位置有效，则移动箱子，否则停止移动。如果玩家的新位置是空地或目标点，函数会更新当前地图状态，将玩家的当前位置从地图上移除，恢复为原地图上的地板或目标点。然后更新玩家的新位置。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获得玩家初始位置</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getPlayerPosition</span>():</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> <span class="built_in">range</span>(HEIGHT_NUM):</span><br><span class="line">        <span class="keyword">for</span> col <span class="keyword">in</span> <span class="built_in">range</span>(WIDTH_NUM):</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">map</span>[row][col] == <span class="number">4</span>:</span><br><span class="line">                <span class="keyword">return</span> [row, col]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">player_pos = getPlayerPosition()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获得关卡目标数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">targetNum</span>():</span><br><span class="line">    targetNums = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> <span class="built_in">range</span>(HEIGHT_NUM):</span><br><span class="line">        <span class="keyword">for</span> col <span class="keyword">in</span> <span class="built_in">range</span>(WIDTH_NUM):</span><br><span class="line">            <span class="keyword">if</span> levels[current_level][row][col] == <span class="number">2</span>:</span><br><span class="line">                targetNums += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> targetNums</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>   getPlayerPosition ( )函数是用来负责实时获得玩家坐标的函数，通过嵌套循环遍历map来得到具体玩家位置，调用后返回具体坐标。</p><p>   targetNum ( )函数是负责遍历整个levels来得到目标点位置的函数，如果发现元素中的目标点后，targetNums会自增，调用后返回目标点或箱子的总数量。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">isAllGet</span>():</span><br><span class="line">    SUM = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> <span class="built_in">range</span>(HEIGHT_NUM):</span><br><span class="line">        <span class="keyword">for</span> col <span class="keyword">in</span> <span class="built_in">range</span>(WIDTH_NUM):</span><br><span class="line">            <span class="keyword">if</span> levels[current_level][row][col] == <span class="number">2</span> <span class="keyword">and</span> <span class="built_in">map</span>[row][col] == <span class="number">3</span>:</span><br><span class="line">                SUM += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> SUM == targetNum()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 背景替换</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">backGround</span>():</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, SCREEN_HEIGHT, TILE_SIZE):</span><br><span class="line">        <span class="keyword">for</span> col <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, SCREEN_WIDTH, TILE_SIZE):</span><br><span class="line">            screen.blit(background_image, (col, row))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印玩家</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">drawPlayer</span>():</span><br><span class="line">    screen.blit(player_image, (player_pos[<span class="number">1</span>] * TILE_SIZE, player_pos[<span class="number">0</span>] * TILE_SIZE))</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 地图布局</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mapSet</span>():</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> <span class="built_in">range</span>(HEIGHT_NUM):</span><br><span class="line">        <span class="keyword">for</span> col <span class="keyword">in</span> <span class="built_in">range</span>(WIDTH_NUM):</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">map</span>[row][col] == <span class="number">0</span>:</span><br><span class="line">                screen.blit(floor_image, (col * TILE_SIZE, row * TILE_SIZE))</span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">map</span>[row][col] == <span class="number">1</span>:</span><br><span class="line">                screen.blit(wall_image, (col * TILE_SIZE, row * TILE_SIZE))</span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">map</span>[row][col] == <span class="number">2</span>:</span><br><span class="line">                screen.blit(target_image, (col * TILE_SIZE, row * TILE_SIZE))</span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">map</span>[row][col] == <span class="number">3</span>:</span><br><span class="line">                screen.blit(box_image, (col * TILE_SIZE, row * TILE_SIZE))</span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">map</span>[row][col] == <span class="number">4</span>:</span><br><span class="line">                screen.blit(player_image, (col * TILE_SIZE, row * TILE_SIZE))</span><br></pre></td></tr></table></figure><p>mapSet ( )函数是负责实现地图元素的摆放，先通过col与row的嵌套循环（Nested Loop）实现二维数组map的遍历，得到map每个元素是多少，其次再根据if,elif 选择语句来判断不同的数字兵插入相应不同的图片，通过screen.blit ( image , ( x , y ) )来实现。x,y是在整个窗口上的坐标位置，而不是Level的位置，故要在x,y本身的基础上乘以TILE_SIZE实现元素铺垫。</p><p>backGround ( )函数是负责整体背景的铺垫的，先通过嵌套循环使用background_image进行整体窗口的摆放，之后MapSet ( )函数在其上进行细节元素的布置。</p><p>drawPlayer ( )函数是玩家绘制函数，因为本项目的逻辑是玩家的地址单独抽离出来保存在player_pos中，所以每次循环后要实时更新玩家的图像位置，这时就要调用drawPlayer ( )函数来进行更新。</p><p>isAllGet ( )_函数是用来判断游戏成功条件的，首先分别整体遍历Map副本地图与原地图Levels，这样得到原地图的目标点位置，如果在相互对应的位置上Map副本是箱子元素，Levels是目标点元素，则证明箱子推到了目标点，SUM初值为0，是用来计算箱子推到目标点的数量，推到目标点后SUM自增1，如果SUM与targetNum ( )函数返回值相同，即地图上所有的目标点都被推到了，那么游戏成功。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 游戏主循环</span></span><br><span class="line">running = <span class="literal">True</span></span><br><span class="line">paused = <span class="literal">False</span></span><br><span class="line">start_time = time.time()</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> running:</span><br><span class="line">    <span class="keyword">for</span> event <span class="keyword">in</span> pygame.event.get():</span><br><span class="line">        <span class="keyword">if</span> event.<span class="built_in">type</span> == pygame.QUIT:</span><br><span class="line">            running = <span class="literal">False</span></span><br><span class="line">        <span class="keyword">elif</span> event.<span class="built_in">type</span> == pygame.KEYDOWN:</span><br><span class="line">            <span class="keyword">if</span> event.key == pygame.K_UP:</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> paused:</span><br><span class="line">                    movePlayer(<span class="number">0</span>, -<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">elif</span> event.key == pygame.K_DOWN:</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> paused:</span><br><span class="line">                    movePlayer(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">            <span class="keyword">elif</span> event.key == pygame.K_LEFT:</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> paused:</span><br><span class="line">                    movePlayer(-<span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">elif</span> event.key == pygame.K_RIGHT:</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> paused:</span><br><span class="line">                    movePlayer(<span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">elif</span> event.key == pygame.K_r:</span><br><span class="line">                resetLevel()</span><br><span class="line">            <span class="keyword">elif</span> event.key == pygame.K_p:</span><br><span class="line">                paused = <span class="keyword">not</span> paused</span><br><span class="line">            <span class="keyword">elif</span> event.key == pygame.K_1:</span><br><span class="line">                current_level = <span class="number">0</span></span><br><span class="line">                resetLevel()</span><br><span class="line">            <span class="keyword">elif</span> event.key == pygame.K_2:</span><br><span class="line">                current_level = <span class="number">1</span></span><br><span class="line">                resetLevel()</span><br><span class="line">            <span class="keyword">elif</span> event.key == pygame.K_3:</span><br><span class="line">                current_level = <span class="number">2</span></span><br><span class="line">                resetLevel()</span><br><span class="line"></span><br><span class="line">    screen.fill((<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>))</span><br><span class="line">    backGround()</span><br><span class="line">    mapSet()</span><br><span class="line">    drawPlayer()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 显示时间和评分</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> paused:</span><br><span class="line">        elapsed_time = time.time() - start_time</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        elapsed_time = elapsed_time  <span class="comment"># 暂停时保持时间不变</span></span><br><span class="line"></span><br><span class="line">    font = pygame.font.Font(<span class="literal">None</span>, <span class="number">36</span>)</span><br><span class="line">    time_text = font.render(<span class="string">f&quot;Time: <span class="subst">&#123;<span class="built_in">int</span>(elapsed_time)&#125;</span>s&quot;</span>, <span class="literal">True</span>, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>))</span><br><span class="line">    screen.blit(time_text, (<span class="number">10</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">    rank = score(elapsed_time)</span><br><span class="line">    rank_text = font.render(<span class="string">f&quot;Rank: <span class="subst">&#123;rank&#125;</span>&quot;</span>, <span class="literal">True</span>, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>))</span><br><span class="line">    screen.blit(rank_text, (<span class="number">10</span>, <span class="number">50</span>))</span><br><span class="line"></span><br><span class="line">    pygame.display.flip()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> isAllGet():</span><br><span class="line">        current_level += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> current_level &lt; <span class="built_in">len</span>(levels):</span><br><span class="line">            resetLevel()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            running = <span class="literal">False</span>  <span class="comment"># 所有关卡完成，退出游戏</span></span><br></pre></td></tr></table></figure><p>本项目在原有基本的推箱子基础上，添加了暂停，选关，计时与评分功能</p><p>事件监听：使用 pygame.event.get() 获取当前发生的所有事件。遍历事件列表，判断事件类型。如果事件类型是 pygame.QUIT，表示用户关闭了游戏窗口，则设置 running 变量为 False，终止主循环，游戏结束。如果事件类型是 pygame.KEYDOWN，表示用户按下了键盘按键，根据按键的不同触发相应的操作。</p><p>处理键盘事件：根据用户按下的键盘按键，调用相应的移动函数。如果按下的是上、下、左、右键，则调用 movePlayer() 函数进行玩家移动。如果按下的是其他键，可以添加额外的功能，如关卡选择等。</p><p>更新游戏状态：根据用户的操作更新游戏状态，包括玩家位置、箱子位置等。调用相关的更新函数，如更新玩家位置、更新箱子位置等。</p><p>绘制游戏画面：使用 screen.fill() 方法清空屏幕。调用绘制函数 backGround() 绘制游戏背景。调用绘制函数 mapSet() 绘制游戏地图。调用绘制函数 drawPlayer() 绘制玩家。</p><p>更新屏幕：使用 pygame.display.flip() 更新屏幕显示，将绘制的画面呈现在屏幕上。</p><p>检查游戏是否结束：调用函数 isAllGet() 检查游戏是否胜利，即是否完成了所有目标。如果游戏胜利，则结束主循环，游戏结束。如果游戏尚未结束，则继续等待事件。</p><h1 id="个人创新点"><a href="#个人创新点" class="headerlink" title="个人创新点"></a>个人创新点</h1><p>​        本项目采用双地图设计，即游戏地图分为实际游戏地图和状态记录地图两部分。在游戏进行过程中，实际游戏地图用于绘制游戏画面和控制玩家操作，而状态记录地图用于记录游戏状态和判断游戏胜利条件。这种设计使得游戏逻辑更加清晰，代码结构更加模块化。</p><p>​        同时加有计时功能与选关等按键操作，在一定时间范围内可以得到该关卡目前的评分等级是多少，按下数字键1，2，3可以实现关卡1，2，3的选择，每完成一关后将自动进入下一个。后续的地图更新可以添加到Level中，与最后的选关设计，代码的可维护性强。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Py语言 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LC 34</title>
      <link href="/2024/05/27/LC-34%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/"/>
      <url>/2024/05/27/LC-34%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/</url>
      
        <content type="html"><![CDATA[<h1 id="在排序数组中查找元素的第一个和最后一个位置"><a href="#在排序数组中查找元素的第一个和最后一个位置" class="headerlink" title="在排序数组中查找元素的第一个和最后一个位置"></a>在排序数组中查找元素的第一个和最后一个位置</h1><p>题目描述:给你一个按照非递减顺序排列的整数数组 <code>nums</code>，和一个目标值 <code>target</code>。请你找出给定目标值在数组中的开始位置和结束位置。</p><p>如果数组中不存在目标值 <code>target</code>，返回 <code>[-1, -1]</code>。</p><p>你必须设计并实现时间复杂度为 <code>O(log n)</code> 的算法解决此问题。</p><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入：nums = [5,7,7,8,8,10], target = 8</span><br><span class="line">输出：[3,4]</span><br></pre></td></tr></table></figure></blockquote><p>答案:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span>[] searchRange(<span class="type">int</span>[] nums, <span class="type">int</span> target) &#123;</span><br><span class="line">        <span class="type">int</span> <span class="variable">len</span> <span class="operator">=</span> nums.length;</span><br><span class="line">        <span class="type">int</span> <span class="variable">left</span> <span class="operator">=</span> <span class="number">0</span>, right = len - <span class="number">1</span>;</span><br><span class="line">        <span class="type">int</span> <span class="variable">start</span> <span class="operator">=</span> -<span class="number">1</span>, end = -<span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (left &lt;= right) &#123;</span><br><span class="line">            <span class="type">int</span> <span class="variable">mid</span> <span class="operator">=</span> (left + right) &gt;&gt; <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">if</span> (nums[mid] &lt; target) &#123;</span><br><span class="line">                left = mid + <span class="number">1</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (nums[mid] &gt; target) &#123;</span><br><span class="line">                right = mid - <span class="number">1</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                start = mid;</span><br><span class="line">                end = mid;</span><br><span class="line">                <span class="keyword">while</span> (start &gt; left &amp;&amp; nums[start - <span class="number">1</span>] == target) &#123;</span><br><span class="line">                    start--;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">while</span> (end &lt; right &amp;&amp; nums[end + <span class="number">1</span>] == target) &#123;</span><br><span class="line">                    end++;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">int</span>[]&#123;start, end&#125;;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">int</span>[]&#123;-<span class="number">1</span>, -<span class="number">1</span>&#125;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>​    题目的关键在于当数组的中间值等于target后要怎么处理，首先应当初始化start与end,紧接着分别排查，如果说start值大于最左边值的话，并且start值左边的值也等于target，那么start应该减少，直至边界left，右边也是同理，所以得到以下代码:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 找到目标值后，向左扩展以找到起始位置</span></span><br><span class="line"><span class="keyword">while</span> (start &gt; left &amp;&amp; nums[start - <span class="number">1</span>] == target) &#123;</span><br><span class="line">    start--;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 找到目标值后，向右扩展以找到结束位置</span></span><br><span class="line"><span class="keyword">while</span> (end &lt; right &amp;&amp; nums[end + <span class="number">1</span>] == target) &#123;</span><br><span class="line">    end++;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以发现这个算法是极其优秀的</p><p><img src="D:\BlogFile\source\_posts\LC-34二分查找.assets\092115caaf721652fce1cb5426d0ac22.png" alt="092115caaf721652fce1cb5426d0ac22"></p>]]></content>
      
      
      
        <tags>
            
            <tag> LeetCode刷题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>查找算法</title>
      <link href="/2024/05/27/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE%E7%AE%97%E6%B3%95/"/>
      <url>/2024/05/27/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h1 id="线性查找算法-Linear-Search"><a href="#线性查找算法-Linear-Search" class="headerlink" title="线性查找算法(Linear Search)"></a>线性查找算法(Linear Search)</h1><p>这是一种最简单最暴力的查找算法，要求：线性表必须采用顺序存储结构，而且表中元素按关键字有序排列。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> BinarySearch;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">BinarySearchBasic</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">int</span> b[] = &#123;<span class="number">1</span>, <span class="number">3</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">12</span>, <span class="number">14</span>, <span class="number">16</span>, <span class="number">45</span>&#125;;</span><br><span class="line">        <span class="type">int</span> <span class="variable">result</span> <span class="operator">=</span> linearSearch(b, <span class="number">7</span>);</span><br><span class="line">        System.out.println(result);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="type">int</span> <span class="title function_">linearSearch</span><span class="params">(<span class="type">int</span>[] a,<span class="type">int</span> target)</span>&#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>;i&lt;a.length;i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(a[i] == target)&#123;</span><br><span class="line">                <span class="keyword">return</span> i;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">    线性查找；</span></span><br><span class="line"><span class="comment">    数据元素个数n</span></span><br><span class="line"><span class="comment">    int i = 0;       1</span></span><br><span class="line"><span class="comment">    i&lt;a.length;    n+1</span></span><br><span class="line"><span class="comment">    i++;             n</span></span><br><span class="line"><span class="comment">    a[i] == target   n</span></span><br><span class="line"><span class="comment">    return -1        1</span></span><br><span class="line"><span class="comment">    总次数：3*n +3</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="二分查找算法-Binary-Search"><a href="#二分查找算法-Binary-Search" class="headerlink" title="二分查找算法(Binary Search)"></a>二分查找算法(Binary Search)</h1><p>要求与线性查找算法一样。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> BinarySearch;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">BinarySearchBasic</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">int</span> b[] = &#123;<span class="number">1</span>, <span class="number">3</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">12</span>, <span class="number">14</span>, <span class="number">16</span>, <span class="number">45</span>&#125;;</span><br><span class="line">        <span class="type">int</span> <span class="variable">result</span> <span class="operator">=</span> binarySearchBasic(b, <span class="number">7</span>);</span><br><span class="line">        System.out.println(result);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="type">int</span> <span class="title function_">binarySearchBasic</span><span class="params">(<span class="type">int</span>[] a, <span class="type">int</span> target)</span> &#123;</span><br><span class="line">        <span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>, j = a.length - <span class="number">1</span>;<span class="comment">//改进 :j = a.length;</span></span><br><span class="line">        <span class="keyword">while</span> (i &lt;= j) &#123;<span class="comment">// 范围内有数值 改进 :i&lt;j</span></span><br><span class="line">            <span class="type">int</span> <span class="variable">m</span> <span class="operator">=</span> (i + j) &gt;&gt;&gt; <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">if</span> (target &lt; a[m]) &#123; <span class="comment">//目标在左边</span></span><br><span class="line">                j = m - <span class="number">1</span>; <span class="comment">//改进 :j=m;</span></span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (a[m] &lt; target) &#123; <span class="comment">//目标在右边</span></span><br><span class="line">                i = m + <span class="number">1</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">return</span> m;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/* 问题1：while循环里面为什么是i&lt;=j，而不是i&lt;j?</span></span><br><span class="line"><span class="comment">     在位置0处，i与j共同指向的元素也是要找的元素，但是循环条件是i&lt;j，故少了一次比较</span></span><br><span class="line"><span class="comment">     i = j : 它们指向的元素也会参与比较</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/* 问题2：(i+j)/2 有没有问题？</span></span><br><span class="line"><span class="comment">    若 j = Integer.MAX_VALUE - 1;第二次后i要变为m+1,m = (i + j)/2 其中(i+j)超出了最大范围，输出结果为负数</span></span><br><span class="line"><span class="comment">    0100 0000 0000 0000 0000 0000 0000 0000</span></span><br><span class="line"><span class="comment">    0111 1111 1111 1111 1111 1111 1111 1111</span></span><br><span class="line"><span class="comment">    相加后溢出</span></span><br><span class="line"><span class="comment">    使用无符号右移 &gt;&gt;&gt;</span></span><br><span class="line"><span class="comment">    0000 0111 &gt;&gt;&gt; 1 : 0000 0011 使得二进制结果变为除以二后的最小整数 右移一位相对于/2</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">    二分查找:</span></span><br><span class="line"><span class="comment">    int i = 0,j = a.length-1;   2</span></span><br><span class="line"><span class="comment">    return -1                   1</span></span><br><span class="line"><span class="comment">    循环次数L = floor(log_2(n)) + 1</span></span><br><span class="line"><span class="comment">    i&lt;=j                      L+1</span></span><br><span class="line"><span class="comment">    int m = (i + j) &gt;&gt;&gt;1 ;     L</span></span><br><span class="line"><span class="comment">    target &lt; a[m]              L</span></span><br><span class="line"><span class="comment">    a[m] &gt; target              L</span></span><br><span class="line"><span class="comment">    总次数:(floor(log_2(n))+1)*5 + 4</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">    二分查找的空间复杂度是O(1)  i,j,m三个常数指针</span></span><br><span class="line"><span class="comment">    时间复杂度最差是O(log(n))</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>额外的算法变式，如寻找右边最大，左边最小等等。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> BinarySearch;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">BinarySearchLeftmost</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[]args)</span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="type">int</span> <span class="title function_">binarySearchLeft1</span><span class="params">(<span class="type">int</span>[] a, <span class="type">int</span> target)</span> &#123;<span class="comment">//返回值无用</span></span><br><span class="line">        <span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>, j = a.length - <span class="number">1</span>;</span><br><span class="line">        <span class="type">int</span> <span class="variable">candidate</span> <span class="operator">=</span> -<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span> (i &lt;= j) &#123;<span class="comment">// 范围内有数值 改进 :i&lt;j</span></span><br><span class="line">            <span class="type">int</span> <span class="variable">m</span> <span class="operator">=</span> (i + j) &gt;&gt;&gt; <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">if</span> (target &lt; a[m]) &#123; <span class="comment">//目标在左边</span></span><br><span class="line">                j = m - <span class="number">1</span>; <span class="comment">//改进 :j=m;</span></span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (a[m] &lt; target) &#123; <span class="comment">//目标在右边</span></span><br><span class="line">                i = m + <span class="number">1</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="comment">//记录候选位置</span></span><br><span class="line">                candidate = m;</span><br><span class="line">                j = m - <span class="number">1</span>;<span class="comment">// i = m + 1; RightMost</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> candidate;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="type">int</span> <span class="title function_">binarySearchLeft2</span><span class="params">(<span class="type">int</span>[] a, <span class="type">int</span> target)</span> &#123;<span class="comment">//返回值无用</span></span><br><span class="line">        <span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>, j = a.length - <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span> (i &lt;= j) &#123;<span class="comment">// 范围内有数值 改进 :i&lt;j</span></span><br><span class="line">            <span class="type">int</span> <span class="variable">m</span> <span class="operator">=</span> (i + j) &gt;&gt;&gt; <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">if</span> (target &lt;= a[m]) &#123; <span class="comment">//目标在左边</span></span><br><span class="line">                j = m - <span class="number">1</span>; <span class="comment">//改进 :j=m;</span></span><br><span class="line">            &#125; <span class="keyword">else</span>&#123; <span class="comment">//目标在右边</span></span><br><span class="line">                i = m + <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> i;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="type">int</span> <span class="title function_">binarySearchRight</span><span class="params">(<span class="type">int</span>[] a, <span class="type">int</span> target)</span> &#123;<span class="comment">//返回值无用</span></span><br><span class="line">        <span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>, j = a.length - <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span> (i &lt;= j) &#123;<span class="comment">// 范围内有数值 改进 :i&lt;j</span></span><br><span class="line">            <span class="type">int</span> <span class="variable">m</span> <span class="operator">=</span> (i + j) &gt;&gt;&gt; <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">if</span> (target &lt; a[m]) &#123; <span class="comment">//目标在左边</span></span><br><span class="line">                j = m - <span class="number">1</span>; <span class="comment">//改进 :j=m;</span></span><br><span class="line">            &#125; <span class="keyword">else</span>&#123; <span class="comment">//目标在右边</span></span><br><span class="line">                i = m + <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> i - <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//求排名 leftmost_result + 1</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 数据结构与算法分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LC 1</title>
      <link href="/2024/05/26/LC-1-4/"/>
      <url>/2024/05/26/LC-1-4/</url>
      
        <content type="html"><![CDATA[<h1 id="LeetCode算法题练习笔记"><a href="#LeetCode算法题练习笔记" class="headerlink" title="LeetCode算法题练习笔记"></a>LeetCode算法题练习笔记</h1><h2 id="1-两数相加"><a href="#1-两数相加" class="headerlink" title="1.两数相加"></a>1.两数相加</h2><blockquote><p>给定一个整数数组 <code>nums</code> 和一个整数目标值 <code>target</code>，请你在该数组中找出 <strong>和为目标值</strong> <em><code>target</code></em> 的那 <strong>两个</strong> 整数，并返回它们的数组下标。</p><p>你可以假设每种输入只会对应一个答案。但是，数组中同一个元素在答案里不能重复出现。</p><p>你可以按任意顺序返回答案。</p><p><strong>示例 1：</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">输入：nums = [<span class="number">2</span>,<span class="number">7</span>,<span class="number">11</span>,<span class="number">15</span>], target = <span class="number">9</span></span><br><span class="line">输出：[<span class="number">0</span>,<span class="number">1</span>]</span><br><span class="line">解释：因为 nums[<span class="number">0</span>] + nums[<span class="number">1</span>] == <span class="number">9</span> ，返回 [<span class="number">0</span>, <span class="number">1</span>] 。</span><br></pre></td></tr></table></figure></blockquote><p>我的代码:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span>[] twoSum(<span class="type">int</span>[] nums, <span class="type">int</span> target) &#123;</span><br><span class="line">        <span class="type">int</span> <span class="variable">length</span> <span class="operator">=</span> nums.length;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; length; i++) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">j</span> <span class="operator">=</span> i + <span class="number">1</span>; j &lt; length; j++) &#123;</span><br><span class="line">                <span class="keyword">if</span> (nums[i] + nums[j] == target) &#123;</span><br><span class="line">                    <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">int</span>[]&#123;i, j&#125;;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">int</span>[<span class="number">0</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>显而易见，这是一个很粗糙的暴力算法，通过双指针，每次循环下i变量和j变量相加来判断是否有满足题意的条件，如果有则返回[i,j]，否则返回[0]。这个算法用时仅击败30.79％的java用户，内存占用击败了67.13％的用户，可见这个方案的效率很低，时间较长。</p><p>优秀的算法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span>[] twoSum(<span class="type">int</span>[] nums, <span class="type">int</span> target) &#123;</span><br><span class="line">        Map&lt;Integer, Integer&gt; hashtable = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;Integer, Integer&gt;();</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; nums.length; ++i) &#123;</span><br><span class="line">            <span class="keyword">if</span> (hashtable.containsKey(target - nums[i])) &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">int</span>[]&#123;hashtable.get(target - nums[i]), i&#125;;</span><br><span class="line">            &#125;</span><br><span class="line">            hashtable.put(nums[i], i);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">int</span>[<span class="number">0</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个方案用到了哈希表，用空间来换时间，因此这个方案的时间异常的少，超过了99.57％的用户，但是在内存方面却仅击败了21.59％的用户。</p>]]></content>
      
      
      
        <tags>
            
            <tag> LeetCode刷题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>单链表与双链表</title>
      <link href="/2024/05/25/%E5%8D%95%E9%93%BE%E8%A1%A8%E4%B8%8E%E5%8F%8C%E9%93%BE%E8%A1%A8/"/>
      <url>/2024/05/25/%E5%8D%95%E9%93%BE%E8%A1%A8%E4%B8%8E%E5%8F%8C%E9%93%BE%E8%A1%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="单链表"><a href="#单链表" class="headerlink" title="单链表"></a>单链表</h1><h3 id="内存结构"><a href="#内存结构" class="headerlink" title="内存结构"></a>内存结构</h3><ul><li><strong>数组</strong>：数组在内存中是一块连续的区域。这意味着所有元素在内存中是连续存储的，并且每个元素都可以通过计算基地址和索引来直接访问。</li><li><strong>链表</strong>：链表由一系列节点组成，每个节点包含数据和一个指向下一个节点的引用。节点在内存中不一定是连续的，它们可以分布在内存的任意位置。</li></ul><h3 id="查询速度"><a href="#查询速度" class="headerlink" title="查询速度"></a>查询速度</h3><ul><li><p>数组查询</p><p>由于数组在内存中是连续存储的，任何位置的元素都可以通过索引直接访问，时间复杂度是 O(1)。</p></li><li><p>链表查询</p><p>链表的查询需要从头节点开始，逐个访问节点，直到找到所需的节点，时间复杂度是 O(n)。</p></li></ul><h3 id="添加和删除速度"><a href="#添加和删除速度" class="headerlink" title="添加和删除速度"></a>添加和删除速度</h3><p><strong>数组添加和删除</strong></p><ul><li><strong>添加</strong>：如果在数组中间添加元素，需要将该位置之后的所有元素向后移动，以腾出空间，时间复杂度是 O(n)。</li><li><strong>删除</strong>：如果在数组中间删除元素，需要将该位置之后的所有元素向前移动，以填补空缺，时间复杂度是 O(n)。</li></ul><p><strong>链表添加和删除</strong></p><ul><li><strong>添加</strong>：在链表的任意位置添加元素只需调整前一个节点的指针指向新节点，时间复杂度是 O(1)。</li><li><strong>删除</strong>：在链表的任意位置删除元素只需调整前一个节点的指针绕过被删除的节点，时间复杂度是 O(1)。</li></ul><h3 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h3><p>单链表一般有头指针，即整个链表开始的地址，并且每个节点有其存储的元素与next域，next域中存储着下一个节点的地址。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 数据结构 基础 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>栈与线性结构</title>
      <link href="/2024/05/24/%E6%A0%88%E4%B8%8E%E7%BA%BF%E6%80%A7%E7%BB%93%E6%9E%84/"/>
      <url>/2024/05/24/%E6%A0%88%E4%B8%8E%E7%BA%BF%E6%80%A7%E7%BB%93%E6%9E%84/</url>
      
        <content type="html"><![CDATA[<h1 id="数据结构与算法分析笔记"><a href="#数据结构与算法分析笔记" class="headerlink" title="数据结构与算法分析笔记"></a>数据结构与算法分析笔记</h1><p>​       数据结构与算法分析的学习对于提高编程技能和解决复杂问题至关重要。在实际应用中，选择合适的数据结构和算法可以大大提高程序的运行效率和内存使用效率。</p><h2 id="线性结构与非线性结构"><a href="#线性结构与非线性结构" class="headerlink" title="线性结构与非线性结构"></a>线性结构与非线性结构</h2><p>​       线性结构分为两种不同的存储结构，分别是顺序存储结构与链式存储结构，顺序存储的线性表称为顺序表，顺序表内的存储元素是连续的，链式存储的线性表称为链表，其存储元素不一定是连续的，元素节点存放数据元素与相邻元素的地址信息。</p><p>​       一对一线性的存储结构称为线性存储结构（分为连续与不连续），比如数组，链表，队列等。例如(1,2,3,4)与(1,?,?,2,3,?,?,?,4)。</p><p>​       对于非线性结构，常见的有：二维数组，广义表，树结构，图结构等</p><h2 id="栈"><a href="#栈" class="headerlink" title="栈"></a>栈</h2><p>​       基础概念微机原理与接口技术中已讲，故略。</p><p>​       栈是一个表，所以任何可以实现表的方法都可以用来实现栈，主要是链表实现与数组实现。</p><h4 id="1-链表实现栈"><a href="#1-链表实现栈" class="headerlink" title="1.链表实现栈"></a>1.链表实现栈</h4><p>​       单链表实现栈，通过在链表顶端插入一个元素来实现<strong>PUSH入栈</strong>，通过删除链表的顶端元素来实现<strong>POP出栈</strong>，使用链表方式实现的栈叫做动态栈，动态栈有链表的部分特性，元素与元素之间在物理存储上可以不连续，功能受限，只能在栈顶进行PUSH和POP，而不是在栈中或栈尾实现插入与删除。</p><h4 id="2-数组实现栈"><a href="#2-数组实现栈" class="headerlink" title="2.数组实现栈"></a>2.数组实现栈</h4><p>数组实现的栈又叫静态栈。</p><p>基础的代码实现如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ArrayStack</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> maxSize;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span>[] stack;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> <span class="variable">top</span> <span class="operator">=</span> -<span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">ArrayStack</span><span class="params">(<span class="type">int</span> size)</span> &#123;</span><br><span class="line">        maxSize = size;</span><br><span class="line">        stack = <span class="keyword">new</span> <span class="title class_">int</span>[maxSize];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">isEmpty</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> top == -<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">isFull</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> top == maxSize - <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">push</span><span class="params">(<span class="type">int</span> value)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (isFull()) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(<span class="string">&quot;Stack is full&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        stack[++top] = value;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">pop</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (isEmpty()) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(<span class="string">&quot;Stack is empty&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> stack[top--];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">peek</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (isEmpty()) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(<span class="string">&quot;Stack is empty&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> stack[top];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">isOper</span><span class="params">(<span class="type">char</span> val)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> val == <span class="string">&#x27;+&#x27;</span> || val == <span class="string">&#x27;-&#x27;</span> || val == <span class="string">&#x27;*&#x27;</span> || val == <span class="string">&#x27;/&#x27;</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">priority</span><span class="params">(<span class="type">int</span> oper)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (oper == <span class="string">&#x27;*&#x27;</span> || oper == <span class="string">&#x27;/&#x27;</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (oper == <span class="string">&#x27;+&#x27;</span> || oper == <span class="string">&#x27;-&#x27;</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">length</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> stack.length+<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">calculate</span><span class="params">(<span class="type">int</span> num1, <span class="type">int</span> num2, <span class="type">int</span> oper)</span> &#123;</span><br><span class="line">        <span class="type">int</span> <span class="variable">result</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">switch</span> (oper) &#123;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&#x27;+&#x27;</span>:</span><br><span class="line">                result = num1 + num2;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&#x27;-&#x27;</span>:</span><br><span class="line">                result = num2 - num1;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&#x27;*&#x27;</span>:</span><br><span class="line">                result = num1 * num2;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&#x27;/&#x27;</span>:</span><br><span class="line">                <span class="keyword">if</span> (num1 == <span class="number">0</span>) &#123;</span><br><span class="line">                    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">ArithmeticException</span>(<span class="string">&quot;/ by zero&quot;</span>);</span><br><span class="line">                &#125;</span><br><span class="line">                result = num2 / num1;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="stack的实例1-回文数"><a href="#stack的实例1-回文数" class="headerlink" title="stack的实例1:回文数"></a>stack的实例1:回文数</h3><blockquote><p>使用stack数组来判断一个字符串是否是回文数，回文数比如:abcdcba</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ArrayStack</span> &#123;</span><br><span class="line">    <span class="comment">// 定义栈的大小</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> maxStack;</span><br><span class="line">    <span class="comment">// 定义数组来模拟栈</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span>[] stack;</span><br><span class="line">    <span class="comment">// 定义栈顶位置，默认情况如果没有数据，则定义为-1</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> <span class="variable">top</span> <span class="operator">=</span> -<span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">ArrayStack</span><span class="params">(<span class="type">int</span> maxStack)</span>&#123;</span><br><span class="line">        <span class="built_in">this</span>.maxStack = maxStack;</span><br><span class="line">        stack = <span class="keyword">new</span> <span class="title class_">int</span>[maxStack];</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 判断是否满栈</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">isFull</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">this</span>.top == <span class="built_in">this</span>.maxStack - <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 是否为空</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">isEmpty</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">this</span>.top == -<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">push</span><span class="params">(<span class="type">int</span> value)</span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(isFull())&#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(<span class="string">&quot;此栈已满&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        top++;</span><br><span class="line">        stack[top] = value;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">pop</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(isEmpty())&#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(<span class="string">&quot;次栈为空&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="type">int</span> <span class="variable">value</span> <span class="operator">=</span> stack[top];</span><br><span class="line"></span><br><span class="line">        top--;</span><br><span class="line">        <span class="keyword">return</span> value;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">list</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(isEmpty())&#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(<span class="string">&quot;无数据&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>;i&lt;stack.length;i++)&#123;</span><br><span class="line">            System.out.printf(<span class="string">&quot;Stack[%d]=%d&quot;</span>,i,stack[i]);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">length</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">this</span>.top + <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 判断是否为运算符 + - * %</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">isOper</span><span class="params">(<span class="type">char</span> v)</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> v==<span class="string">&#x27;+&#x27;</span>||v==<span class="string">&#x27;-&#x27;</span>||v==<span class="string">&#x27;*&#x27;</span>||v==<span class="string">&#x27;%&#x27;</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//获取栈的容量</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">stackLength</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">this</span>.stack.length;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//获取栈顶数据</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">peek</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">this</span>.stack[top];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 判断运算符优先级</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">priority</span><span class="params">(<span class="type">int</span> oper)</span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(oper == <span class="string">&#x27;*&#x27;</span>||oper == <span class="string">&#x27;%&#x27;</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span>(oper == <span class="string">&#x27;+&#x27;</span>||oper == <span class="string">&#x27;-&#x27;</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">            <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 计算函数</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">calculate</span><span class="params">(<span class="type">int</span> num1,<span class="type">int</span> num2,<span class="type">int</span> oper)</span>&#123;</span><br><span class="line">        <span class="type">int</span> <span class="variable">result</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">switch</span> (oper)&#123;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&#x27;+&#x27;</span>:</span><br><span class="line">                result = num1 + num2;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&#x27;-&#x27;</span>:</span><br><span class="line">                result = num2 - num1;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&#x27;*&#x27;</span>:</span><br><span class="line">                result = num1 * num2;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&#x27;/&#x27;</span>:</span><br><span class="line">                result = num2/num1;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="stack的实例2：完成表达式的计算"><a href="#stack的实例2：完成表达式的计算" class="headerlink" title="stack的实例2：完成表达式的计算"></a>stack的实例2：完成表达式的计算</h3><blockquote><p>String val = “4 + 3 + 2 + 1*5”的结果</p></blockquote><p>大致思路；循环遍历字符串中的每一个数字，并且按照元素的种类分别压入数字栈或符号栈，若符号栈为空，压入的符号则直接入栈，若不为空则先比较栈中符号的优先级别，如果优先级小于等于栈中的符号，则需要计算原来数字栈的数据，再压入数字栈，再把符号压入到符号栈中，如果优先级大于原来栈中符号，则符号直接入栈即可。</p><p>设计的原因：</p><ul><li><strong>保持顺序</strong>：通过使用两个栈，能够按照表达式中出现的顺序处理数字和操作符。</li><li><strong>处理优先级</strong>：通过比较优先级并决定是否计算，可以确保更高优先级的操作符在较低优先级的操作符之前被处理，保证计算的正确性。</li><li><strong>计算简化</strong>：这种方法使得每次计算都比较简单，只需要关注栈顶的两个数字和一个操作符，而不是整个表达式。</li></ul><p>代码如下:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TestStack</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line"></span><br><span class="line">        <span class="type">String</span> <span class="variable">str</span> <span class="operator">=</span> <span class="string">&quot;4+3+2*3-5&quot;</span>;</span><br><span class="line">        <span class="type">ArrayStack</span> <span class="variable">numStack</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ArrayStack</span>(<span class="number">10</span>);</span><br><span class="line">        <span class="type">ArrayStack</span> <span class="variable">symbolStack</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ArrayStack</span>(<span class="number">10</span>);</span><br><span class="line"></span><br><span class="line">        <span class="type">int</span> <span class="variable">temp1</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">        <span class="type">int</span> <span class="variable">temp2</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">        <span class="type">int</span> <span class="variable">symbolChar</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">        <span class="type">int</span> <span class="variable">result</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">        <span class="type">String</span> <span class="variable">values</span> <span class="operator">=</span> <span class="string">&quot;&quot;</span>;</span><br><span class="line">        <span class="type">int</span> <span class="variable">length</span> <span class="operator">=</span> str.length();</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; length; i++) &#123;</span><br><span class="line">            <span class="type">char</span> <span class="variable">c</span> <span class="operator">=</span> str.charAt(i);</span><br><span class="line">            <span class="keyword">if</span> (symbolStack.isOper(c)) &#123;</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> (!symbolStack.isEmpty()) &#123;</span><br><span class="line">                    <span class="comment">// 比较优先级</span></span><br><span class="line">                    <span class="keyword">while</span> (!symbolStack.isEmpty() &amp;&amp; symbolStack.priority(c) &lt;= symbolStack.priority(symbolStack.peek())) &#123;</span><br><span class="line">                        <span class="comment">// 符号栈获取栈顶符号</span></span><br><span class="line">                        <span class="comment">// 数字栈获取两个数字</span></span><br><span class="line">                        temp1 = numStack.pop();</span><br><span class="line">                        temp2 = numStack.pop();</span><br><span class="line">                        symbolChar = symbolStack.pop();</span><br><span class="line">                        result = numStack.calculate(temp1, temp2, symbolChar);</span><br><span class="line">                        <span class="comment">// 运算结果入栈</span></span><br><span class="line">                        numStack.push(result);</span><br><span class="line">                    &#125;</span><br><span class="line">                    symbolStack.push(c);</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    <span class="comment">// 如果空符号栈，则直接压栈</span></span><br><span class="line">                    symbolStack.push(c);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                values += c;</span><br><span class="line">                <span class="keyword">if</span> (i == length - <span class="number">1</span> || symbolStack.isOper(str.charAt(i + <span class="number">1</span>))) &#123;</span><br><span class="line">                    numStack.push(Integer.parseInt(values));</span><br><span class="line">                    values = <span class="string">&quot;&quot;</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (!symbolStack.isEmpty()) &#123;</span><br><span class="line">            temp1 = numStack.pop();</span><br><span class="line">            temp2 = numStack.pop();</span><br><span class="line">            symbolChar = symbolStack.pop();</span><br><span class="line">            result = numStack.calculate(temp1, temp2, symbolChar);</span><br><span class="line">            numStack.push(result);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="type">int</span> <span class="variable">res</span> <span class="operator">=</span> numStack.pop();</span><br><span class="line">        System.out.println(<span class="string">&quot;结果是: &quot;</span> + res);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 数据结构 基础 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
    
  
</search>
